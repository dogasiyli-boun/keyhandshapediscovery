{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:  1.1.0\n",
      "torch:  1.6.0\n",
      "numpy:  1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "import pandas as pd\n",
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"torch: \", torch.__version__)\n",
    "print(\"numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsubuntu_khs_dir = /home/wsubuntu/GitHub/keyhandshapediscovery\n",
      "wsubuntu_data_path = /media/wsubuntu/SSD_Data/DataPath\n",
      "wsubuntu_experiment_path = /media/wsubuntu/SSD_Data/vaesae_experiments\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "def get_var_by_comp_name(variableName):\n",
    "    curCompName = socket.gethostname()\n",
    "    retVal = None\n",
    "    if variableName == 'khs_dir':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/home/wsubuntu/GitHub/keyhandshapediscovery'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'data_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/Datasets'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/DataPath'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'experiment_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/SPARSE_TORCH'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/vaesae_experiments'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "        \n",
    "    print(curCompName + '_' + variableName, '=',  retVal)\n",
    "    if retVal is None:\n",
    "        os.error(5)\n",
    "    return retVal\n",
    "\n",
    "khs_dir = get_var_by_comp_name('khs_dir')\n",
    "data_path = get_var_by_comp_name('data_path')\n",
    "experiment_path = get_var_by_comp_name('experiment_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, khs_dir)\n",
    "import helperFuncs as funcH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 21\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'batchmean','sum'\n",
    "SIGMOID_ACT=False\n",
    "APPLY_LOG_SOFTMAX=False\n",
    "MSE_PLUS_MINUS='+'\n",
    "APPLY_SPARSITY_TO='bottleneck' #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 100  # args['epochs']\n",
    "reg_param = 0.001  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": data_path,\n",
    "    \"experiment\": os.path.join(experiment_path, 'sparse_torch_ae_' + str(EXPERIMENT_ID).zfill(3)),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseAutoencoder - loss_type(cre), device(cpu)\n"
     ]
    }
   ],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=32)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    "        print(\"SparseAutoencoder - loss_type(\" + loss_type +\"), device(\" + self.device + \")\")\n",
    "\n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        if self.loss_type=='cre':\n",
    "            bottleneck = self.enc5(x) \n",
    "        else:\n",
    "            bottleneck = F.relu(self.enc5(x))  \n",
    "        \n",
    "        return bottleneck\n",
    "        \n",
    "    def decode(self, bottleneck):\n",
    "        # decoding\n",
    "        if self.loss_type=='cre':\n",
    "            x = F.relu(self.dec1(F.relu(bottleneck)))\n",
    "        else:\n",
    "            x = F.relu(self.dec1(bottleneck))\n",
    "        \n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x)) \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encode(x)\n",
    "        x = self.decode(bottleneck)\n",
    "        return x, bottleneck\n",
    "\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    rho_val = 1/bt.size(1)\n",
    "    rho_mat = torch.tensor([rho_val] * np.ones(bt.size()), dtype=torch.float32).to(device)\n",
    "    #https://discuss.pytorch.org/t/kl-divergence-produces-negative-values/16791/13\n",
    "    #KLDLoss(p, q), sum(q) needs to equal one\n",
    "    #p = log_softmax(tensor)\n",
    "    loss_ret_1 = F.kl_div(F.log_softmax(bt, dim=1).to(device), rho_mat, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct and apply_log_softmax:  \n",
    "        if print_info:\n",
    "            print(\"1-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    elif sigmoidAct and not apply_log_softmax:     \n",
    "        if print_info:\n",
    "            print(\"2-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(bt.to(device), preds)    \n",
    "    elif not sigmoidAct and apply_log_softmax:\n",
    "        if print_info:\n",
    "            print(\"3-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bottleneck, dim=1).to(device), preds)    \n",
    "    else:#nothing\n",
    "        if print_info:\n",
    "            print(\"4-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(bottleneck.to(device), preds)\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy_old(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct:\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    else:\n",
    "        bt = bottleneck    \n",
    "    _, preds = torch.max(bt, 1)\n",
    "    loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss\n",
    "\n",
    "def sparse_loss_bottleneck(bottleneck, print_info, loss_type):\n",
    "    loss = 0\n",
    "    #if print_info:\n",
    "        #print(i, ' shape=', values.shape)\n",
    "    if loss_type=='l1':\n",
    "        loss += loss_l1(bottleneck)\n",
    "    if loss_type=='l2':\n",
    "        loss += loss_l2(bottleneck)\n",
    "    if loss_type=='kl':\n",
    "        loss += kl_divergence(bottleneck, reduction=LOSS_REDUCTION)\n",
    "    if loss_type=='cre':\n",
    "        loss += loss_crossentropy(bottleneck, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "    if print_info:\n",
    "        print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            if APPLY_SPARSITY_TO=='all':\n",
    "                sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            elif APPLY_SPARSITY_TO=='bottleneck': #all\n",
    "                sp_loss = sparse_loss_bottleneck(bottleneck, print_losses_fit, model.loss_type)\n",
    "            else:\n",
    "                os.exit(4)\n",
    "                \n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            \n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "                \n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_ws :: \n",
      "EXPERIMENT_ID:  21\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  False\n",
      "APPLY_LOG_SOFTMAX :  False\n",
      "APPLY_SPARSITY_TO :  bottleneck\n",
      "total loss = mse_loss + reg_param(0.001) * sp_loss\n",
      "*****\n",
      " Epoch 0 of 100\n",
      "TrEpoch(000) - 4- False False\n",
      "cre tensor(3.2903, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.2902610301971436\n",
      "\n",
      "     acc     bmx     bmn      mse      spr      run\n",
      "0  10.0  80.527 -53.899  157.392  264.846  157.657\n",
      "ValEpoch(000) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  80.172 -53.565  19.758\n",
      "*****\n",
      " Epoch 1 of 100\n",
      "TrEpoch(001) - \n",
      "     acc     bmx     bmn      mse    spr     run\n",
      "0  10.0  91.663 -64.775  108.378  1.887  108.38\n",
      "ValEpoch(001) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  88.761 -63.006  16.353\n",
      "*****\n",
      " Epoch 2 of 100\n",
      "TrEpoch(002) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  91.999 -64.206  91.743  1.464  91.745\n",
      "ValEpoch(002) - \n",
      "     acc     bmx    bmn     run\n",
      "0  10.0  83.957 -60.55  14.611\n",
      "*****\n",
      " Epoch 3 of 100\n",
      "TrEpoch(003) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  87.224 -63.514  85.476  1.604  85.477\n",
      "ValEpoch(003) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  82.775 -61.209  13.631\n",
      "*****\n",
      " Epoch 4 of 100\n",
      "TrEpoch(004) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  86.037 -65.097  76.592  1.482  76.594\n",
      "ValEpoch(004) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  84.997 -63.511  12.023\n",
      "*****\n",
      " Epoch 5 of 100\n",
      "TrEpoch(005) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  87.518 -67.354  70.778  1.093  70.779\n",
      "ValEpoch(005) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  87.676 -65.159  11.724\n",
      "*****\n",
      " Epoch 6 of 100\n",
      "TrEpoch(006) - 4- False False\n",
      "cre tensor(7.2248e-05, grad_fn=<AddBackward0>)\n",
      "sp_loss: 7.224762521218508e-05\n",
      "\n",
      "     acc    bmx     bmn     mse  spr     run\n",
      "0  10.0  91.61 -67.911  69.227  0.9  69.228\n",
      "ValEpoch(006) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  90.196 -66.591  11.421\n",
      "*****\n",
      " Epoch 7 of 100\n",
      "TrEpoch(007) - \n",
      "     acc    bmx     bmn     mse    spr     run\n",
      "0  10.0  95.08 -69.683  66.828  0.774  66.829\n",
      "ValEpoch(007) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  93.371 -69.002  10.814\n",
      "*****\n",
      " Epoch 8 of 100\n",
      "TrEpoch(008) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  98.837 -71.715  62.713  0.677  62.713\n",
      "ValEpoch(008) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  95.367 -70.486  10.337\n",
      "*****\n",
      " Epoch 9 of 100\n",
      "TrEpoch(009) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  101.288 -73.847  60.394  0.649  60.394\n",
      "ValEpoch(009) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  96.453 -71.677  9.995\n",
      "*****\n",
      " Epoch 10 of 100\n",
      "TrEpoch(010) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  100.329 -74.716  59.244  0.717  59.245\n",
      "ValEpoch(010) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  96.655 -72.225  9.805\n",
      "*****\n",
      " Epoch 11 of 100\n",
      "TrEpoch(011) - 4- False False\n",
      "cre tensor(8.9627e-06, grad_fn=<AddBackward0>)\n",
      "sp_loss: 8.962659194367006e-06\n",
      "\n",
      "     acc     bmx     bmn     mse   spr    run\n",
      "0  10.0  99.475 -74.308  58.189  0.82  58.19\n",
      "ValEpoch(011) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  95.926 -71.696  9.712\n",
      "*****\n",
      " Epoch 12 of 100\n",
      "TrEpoch(012) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  99.352 -73.725  57.381  0.897  57.382\n",
      "ValEpoch(012) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  95.086 -71.065  9.516\n",
      "*****\n",
      " Epoch 13 of 100\n",
      "TrEpoch(013) - \n",
      "     acc     bmx    bmn     mse    spr     run\n",
      "0  10.0  98.379 -73.73  56.668  0.993  56.669\n",
      "ValEpoch(013) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  94.539 -70.567  9.496\n",
      "*****\n",
      " Epoch 14 of 100\n",
      "TrEpoch(014) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  97.901 -72.792  55.431  1.085  55.432\n",
      "ValEpoch(014) - \n",
      "     acc    bmx     bmn    run\n",
      "0  10.0  93.72 -69.601  9.147\n",
      "*****\n",
      " Epoch 15 of 100\n",
      "TrEpoch(015) - \n",
      "     acc     bmx     bmn     mse    spr    run\n",
      "0  10.0  98.195 -72.066  53.869  1.123  53.87\n",
      "ValEpoch(015) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  93.497 -69.436  8.962\n",
      "*****\n",
      " Epoch 16 of 100\n",
      "TrEpoch(016) - 4- False False\n",
      "cre tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.00038875386235304177\n",
      "\n",
      "     acc     bmx    bmn     mse    spr     run\n",
      "0  10.0  97.877 -71.84  52.667  1.157  52.669\n",
      "ValEpoch(016) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  93.496 -69.352  8.684\n",
      "*****\n",
      " Epoch 17 of 100\n",
      "TrEpoch(017) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  98.583 -72.142  51.017  1.162  51.018\n",
      "ValEpoch(017) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  93.373 -69.487  8.408\n",
      "*****\n",
      " Epoch 18 of 100\n",
      "TrEpoch(018) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  97.553 -72.003  49.454  1.201  49.455\n",
      "ValEpoch(018) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  92.925 -69.437  8.228\n",
      "*****\n",
      " Epoch 19 of 100\n",
      "TrEpoch(019) - \n",
      "     acc    bmx    bmn     mse    spr     run\n",
      "0  10.0  97.49 -72.18  48.497  1.241  48.498\n",
      "ValEpoch(019) - \n",
      "     acc     bmx    bmn    run\n",
      "0  10.0  92.333 -69.34  8.077\n",
      "*****\n",
      " Epoch 20 of 100\n",
      "TrEpoch(020) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  98.551 -71.567  47.794  1.278  47.795\n",
      "ValEpoch(020) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  91.996 -69.221  8.009\n",
      "*****\n",
      " Epoch 21 of 100\n",
      "TrEpoch(021) - 4- False False\n",
      "cre tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.00033073994563892484\n",
      "\n",
      "     acc     bmx     bmn     mse    spr    run\n",
      "0  10.0  98.306 -71.388  47.509  1.333  47.51\n",
      "ValEpoch(021) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  91.001 -68.254  7.961\n",
      "*****\n",
      " Epoch 22 of 100\n",
      "TrEpoch(022) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  97.237 -70.837  47.251  1.383  47.252\n",
      "ValEpoch(022) - "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-537f58b86215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"*****\\n Epoch {epoch} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mresult_df_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mresult_df_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint_losses_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mresult_df_tr_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_df_tr_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_df_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-6ffe69b5044f>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dataloader, epoch, print_losses_fit)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mbottleneck_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-dac7d038fb00>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mbottleneck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-dac7d038fb00>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, bottleneck)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1672\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1674\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1675\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_ws :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"APPLY_LOG_SOFTMAX : \", APPLY_LOG_SOFTMAX)\n",
    "print(\"APPLY_SPARSITY_TO : \", APPLY_SPARSITY_TO)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param(\"+ str(reg_param) +\") * sp_loss\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc      bmx     bmn      mse      spr      run\n",
      "0   10.0   80.527 -53.899  157.392  264.846  157.657\n",
      "1   10.0   91.663 -64.775  108.378    1.887  108.380\n",
      "2   10.0   91.999 -64.206   91.743    1.464   91.745\n",
      "3   10.0   87.224 -63.514   85.476    1.604   85.477\n",
      "4   10.0   86.037 -65.097   76.592    1.482   76.594\n",
      "5   10.0   87.518 -67.354   70.778    1.093   70.779\n",
      "6   10.0   91.610 -67.911   69.227    0.900   69.228\n",
      "7   10.0   95.080 -69.683   66.828    0.774   66.829\n",
      "8   10.0   98.837 -71.715   62.713    0.677   62.713\n",
      "9   10.0  101.288 -73.847   60.394    0.649   60.394\n",
      "10  10.0  100.329 -74.716   59.244    0.717   59.245\n",
      "11  10.0   99.475 -74.308   58.189    0.820   58.190\n",
      "12  10.0   99.352 -73.725   57.381    0.897   57.382\n",
      "13  10.0   98.379 -73.730   56.668    0.993   56.669\n",
      "14  10.0   97.901 -72.792   55.431    1.085   55.432\n",
      "15  10.0   98.195 -72.066   53.869    1.123   53.870\n",
      "16  10.0   97.877 -71.840   52.667    1.157   52.669\n",
      "17  10.0   98.583 -72.142   51.017    1.162   51.018\n",
      "18  10.0   97.553 -72.003   49.454    1.201   49.455\n",
      "19  10.0   97.490 -72.180   48.497    1.241   48.498\n",
      "20  10.0   98.551 -71.567   47.794    1.278   47.795\n",
      "21  10.0   98.306 -71.388   47.509    1.333   47.510\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc     bmx     bmn     run\n",
      "0   10.0  80.172 -53.565  19.758\n",
      "1   10.0  88.761 -63.006  16.353\n",
      "2   10.0  83.957 -60.550  14.611\n",
      "3   10.0  82.775 -61.209  13.631\n",
      "4   10.0  84.997 -63.511  12.023\n",
      "5   10.0  87.676 -65.159  11.724\n",
      "6   10.0  90.196 -66.591  11.421\n",
      "7   10.0  93.371 -69.002  10.814\n",
      "8   10.0  95.367 -70.486  10.337\n",
      "9   10.0  96.453 -71.677   9.995\n",
      "10  10.0  96.655 -72.225   9.805\n",
      "11  10.0  95.926 -71.696   9.712\n",
      "12  10.0  95.086 -71.065   9.516\n",
      "13  10.0  94.539 -70.567   9.496\n",
      "14  10.0  93.720 -69.601   9.147\n",
      "15  10.0  93.497 -69.436   8.962\n",
      "16  10.0  93.496 -69.352   8.684\n",
      "17  10.0  93.373 -69.487   8.408\n",
      "18  10.0  92.925 -69.437   8.228\n",
      "19  10.0  92.333 -69.340   8.077\n",
      "20  10.0  91.996 -69.221   8.009\n",
      "21  10.0  91.001 -68.254   7.961\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tr acc =  10.0\n",
      "Max va acc =  10.0\n"
     ]
    }
   ],
   "source": [
    "tr_acc = result_df_tr_all.values[:,0].squeeze()\n",
    "va_acc = result_df_va_all.values[:,0].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_acc, color='orange', label='train acc')\n",
    "plt.plot(va_acc, color='red', label='validataion acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Max tr acc = \", np.max(tr_acc))\n",
    "print(\"Max va acc = \", np.max(va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKIAAAGsCAYAAADuVg9dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdf5CcdYEn/nd3TyAJISGTIYRAkmcwQSXiJRDklwKGoHfEUmoPl6VOV1g48Lu73AVYKRHROzkknpvgIlBWUbrIlbXrsrfkQEUkmwNuzXEGXRZBFw4ZIiEJIZkhJOZn9/T3j5A5YxI2gZnumenX6690P/30vJ+mPvzxrs+PUr1erwcAAAAABli52QEAAAAAaA2KKAAAAAAaQhEFAAAAQEMoogAAAABoCEUUAAAAAA2hiAIAAACgIdqaHaDZVq9e3ewI/aKjoyPr169vdgzgLTKGYegzjmFoM4Zh6DOOB4/Jkyfv95oZUQAAAAA0hCIKAAAAgIZQRAEAAADQEC2/RxQAAAAwvNXr9Wzbti29vb0plUrNjjMs1Ov1lMvljBw58qB+U0UUAAAAMKxt27YtI0aMSFubGqQ/VavVbNu2LaNGjTrgeyzNAwAAAIa13t5eJdQAaGtrS29v70Hdo4gCAAAAhjXL8QbOwf62iigAAAAAGkIRBQAAADCANm7cmLvvvvst3fvJT34yGzdu7N9ATaSIAgAAABhAr7/+eu655559XqvVam9673/7b/8t48aNG4hYTWGnLgAAAIAB9OUvfzkrV67Meeedl7POOivnnntuFi9enKOOOirPPPNMHnnkkfzRH/1RVq9ene3bt+eyyy7LJz7xiSTJqaeemgcffDC/+c1v8olPfCLve9/78sQTT2TSpEn51re+tdeJdQsWLMjIkSPz/PPP5+WXX87ixYtz77335qc//Wlmz56dr33ta6nVarn22mvz1FNPpVQq5aKLLsoVV1yRF198MTfccEM2bNiQUaNG5atf/WqmT5/er7+FIgoAAABoGWP/7xcyYvMv+vU7d445Ia/P+NJ+r3/uc5/Ls88+m4cffjhJsnz58jz55JNZtmxZpk6dmiRZtGhRxo8fn61bt2b+/Pk5//zz097evsf3dHV15Y477shXv/rVXHnllfnBD36Qf/tv/+1ef2/jxo25995786Mf/SiXXHJJlixZkj//8z/P+eefn6effjq9vb1Zu3Ztli1b1vf5JLnuuuuycOHCHHfccfnZz36W66+/Pvfee2+//Ea7KaIAAAAAGmzWrFl9JVSSfOtb38qDDz6YJFm9enW6urr2KqKmTJmS97znPUmS9773vXnppZf2+d3nnXdeSqVS3vWud6WjoyPvfve7kyTHH398Vq1aldNOOy2//vWv8/nPfz7nnntuzj777PzmN7/JT3/601x55ZV937Njx45+feZEEQUAAAC0kDebudRIo0eP7vv38uXL87/+1//KAw88kFGjRuXCCy/M9u3b97rn0EMP7ft3pVLJtm3b9vndhxxySJKkXC7vcU+5XE61Ws0RRxyRhx9+OI888kjuvvvuPPDAA/nP//k/Z+zYsX2ztgaKzcqHuno9la6uZD8tKAAAANBchx12WDZv3rzf65s2bcq4ceMyatSoPP/88/nZz342oHm6u7vT29ub+fPn5zOf+Ux+/vOf5/DDD8+UKVPywAMPJEnq9XqeeeaZfv/biqihrl7PkfPmpXL77c1OAgAAAOxDe3t7TjnllMydOzc33XTTXtfPOeec1Gq1zJs3L//1v/7XnHTSSQOaZ82aNbnwwgtz3nnn5eqrr87111+fJLn99tvz13/915k3b14++MEP5kc/+lG//+1SvV6v9/u3DiGrV69udoS37chzz01lxoys/cY3mh0FeIs6Ojqyfv36ZscA3gbjGIY2YxiGvjcbx1u2bNljKRz9Z1+/7eTJk/f7eTOihoFqUSS/+lWzYwAAAAC8KUXUMFAripReeCHp7W12FAAAAID9UkQNA9WiSGnbtpTXrm12FAAAAID9UkQNA9Vp05IkbS++2NwgAAAAAG9CETUM1Do7kyiiAAAAgMFNETUM1CZPTn3EiFQUUQAAAMAgpogaDiqVpLMzbV1dzU4CAAAA/I6NGzfm7rvvbsjfqtfrSZJFixb1ve7u7s6FF16YGTNm5IYbbtjj80899VTOPffcnHnmmbnxxhv77t++fXs+/elP58wzz8xHPvKRvPTSS/2STxE1TNTf8Q5L8wAAAGAQev3113PPPffs81qtVuu3v1OtVrNw4cI89NBD6enpyY033phnnnkmI0eOzHXXXZcbb7xxr3uuv/76fOUrX8k//MM/pKurK//zf/7PJMlf/dVfZdy4cfnxj3+cf//v/31uvvnmfsnY1i/fQtPV3/GOVB59NKnXk1Kp2XEAAACAN3z5y1/OypUrc9555+Wss87Kueeem8WLF+eoo47KM888k0ceeaTvs7VaLddee22eeuqplEqlXHTRRbniiity4YUX5oQTTsiTTz6ZzZs3Z9GiRZk9e3YWLVqUV155JS+99FLa29tzxx135LOf/Wzuv//+3H///Zk+fXqS5H3ve1+6fmcl1SuvvJJNmzZlzpw5SZILL7wwP/zhDzN37tz86Ec/yjXXXJMkmT9/fm644YbU6/WU3mbnoIgaJurveEcqW7ak/Oqr6Z04sdlxAAAAYFAa+4UvZMQvftGv37nzhBPy+pe+tN/rn/vc5/Lss8/m4YcfTpIsX748Tz75ZJYtW5apU6fu8dlnnnkma9euzbJly5LsWta329atW3P//ffn8ccfz7XXXtv3maeeeir33XdfRo0ala985Ss555xz0tbWlm9/+9v5gz/4g8ycOXOfudauXZujjz667/XRRx+dtWvX9l2bPHlykqStrS1jx45NT09P2tvbD/bn2YMiapiov+MdSXadnLdDEQUAAACD2qxZs/YqoZJk6tSp+fWvf53Pf/7zOffcc3P22Wf3XfvYxz6WJDnttNOyadOmvpLqQx/6UEaNGpUkue6661IqlfLMM8/k2muv7dvzaV/2dW33jKc3u+/tUEQNE7uLqEpXV/K+9zU5DQAAAAxObzZzqZFGjx69z/ePOOKIPPzww3nkkUdy991354EHHsjixYuTZK9lcbtf//Z37X7v2muv3ec9v+3oo4/OmjVr+l6vWbMmRx11VN+11atXZ/LkyalWq3n99dczfvz4g33MvdisfLiYNi31SsWG5QAAADDIHHbYYdm8efMBfba7uzu9vb2ZP39+PvOZz+TnP/9537X7778/SfKTn/wkY8eOzdixY99WrqOOOipjxozJT3/609Tr9fzt3/5tPvzhDyfZNcvq3nvvTZJ8//vfz5lnnvm294dKzIgaPkaMSG3KlFRWrmx2EgAAAOC3tLe355RTTsncuXPzwQ9+MOeee+5+P7tmzZpcc8016e3tTbLrVLvdjjjiiHz0ox/t26z8YJx66qnZvHlzduzYkR/+8If5q7/6qxx//PG55ZZbcvXVV2fbtm354Ac/mLlz5yZJ/uAP/iD/4T/8h5x55pk54ogjcuedd76FJ99bqT5Qi/6GiNWrVzc7Qr/o6OhI74c/nHJPT9b/4AfNjgMcpI6Ojqxfv77ZMYC3wTiGoc0YhqHvzcbxli1b9rsUbqi48MILc+ONN+Zf/at/1ewoe9jXb7t7k/N9aciMqPXr1+eOO+7Ia6+9llKplHnz5uX888/P3/zN3+Tv//7v+6aSXXzxxTnppJOSJPfdd1+WLVuWcrmcSy+9NLNmzUqSvPDCC7njjjuyY8eOzJ49O5deemlKpVJ27tyZ22+/PS+88EIOP/zwLFiwIBNbbNPuWlHkkJ/9LKnXk36YLgcAAADQnxpSRFUqlXzyk5/Mcccdl61bt+azn/1s3vve9yZJ5s+fn49+9KN7fH7VqlVZvnx5Fi9enJ6entx00035i7/4i5TL5dx111258sorM2PGjNxyyy158sknM3v27CxbtiyHHXZYvv71r+fHP/5xvvOd7+Tqq69uxOMNGtWiSPn111Pq6Un9bR6nCAAAAAwef/u3f9vsCP2iIZuVjx8/Pscdd1ySZNSoUTnmmGPS3d2938+vWLEiZ5xxRkaMGJGJEydm0qRJef7559PT05OtW7fm+OOPT6lUyllnnZUVK1YkSZ544omcc845SXYdY/j0008P2FGDg1W1KJLEhuUAAADAoNTwzcrXrVuXrq6uTJ8+Pf/8z/+chx56KI899liOO+64/OEf/mHGjBmT7u7uzJgxo++e9vb2dHd3p1KpZMKECX3vT5gwoa/Q6u7u7rtWqVQyevTobNq0aa8d5JcuXZqlS5cmSRYuXJiOjo6BfuSGaGtry+GzZydJxm/YkN5h8lzQKtra2obN/4+gVRnHMLQZwzD0vdk4fuWVV9LW5ry2gXDooYce1P8/G/pfYdu2bVm0aFEuueSSjB49Oh/60Idy4YUXJkm++93v5p577skf//Ef73cm05vNcNrXtX0dKzhv3rzMmzev7/Vw2ZCwo6Mj6w8/PEeXStny859n83nnNTsScBBskApDn3EMQ5sxDEPfm43j7du3p1KpNDhRa9i+fftev/ubbVbekKV5SVKtVrNo0aJ84AMfyKmnnppk17GD5XI55XI55557bn71q18l2TXTacOGDX33dnd3p729fa/3N2zYkPY39kL67Wu1Wi1btmzJmDFjGvV4g8Ohh6Z2zDFp6+pqdhIAAACAvTSkiKrX6/nGN76RY445Jh/5yEf63u/p6en7909+8pNMmTIlSTJnzpwsX748O3fuzLp167JmzZpMnz4948ePz6hRo/Lcc8+lXq/nsccey5w5c5IkJ598ch555JEkyeOPP56ZM2fuc0bUcFcrCntEAQAAAINSQ5bmPfvss3nssccyderUfOYzn0mSXHzxxfnxj3+cF198MaVSKUceeWSuuOKKJMmUKVNy+umn55prrkm5XM5ll12WcnlXZ3b55ZfnzjvvzI4dOzJr1qzMfmNfpLlz5+b222/PVVddlTFjxmTBggWNeLRBp1oUGfmDHzQ7BgAAANBk9Xo9pVIpixYtyrXXXtv3esGCBXn88cdz+OGHJ0luvfXWvOc972lIplK91Y6W+x2rV69udoR+sXst7GHf+EbG3XRT1vziF6mPG9fsWMABsi8FDH3GMQxtxjAMfW82jrds2ZLRo0c3OFHj1Wq1PfbCeuqpp3LvvfcmSc4888z84z/+Y66//vosWLAg8+bN22PV2lu1r9/2zfaIsmX8MFObNi1J0rZyZXa+971NTgMAAACDyxe+MDa/+MWIfv3OE07YmS996fX9Xr/55ptzzDHH5JJLLkmSLFq0KKVSKY8//ng2btyYarWa6667Lh/+8If3+x3//b//93zrW9/Kjh07Mnv27Nxyyy2pVCqZMWNGrrjiijz66KP5whe+kH/37/7dHq8/9alP5aMf/Wh27tyZhQsX9utzvxUN26ycxqgWRZKkYsNyAAAAGBQ+9rGP5YEHHuh7/cADD+Siiy7KN7/5zTz00EO5995786UvfSn7W7T2f//v/83999+fJUuW5OGHH06lUsnf/d3fJdk1I+md73xnvve97+V973vfHq9Hjx6db3/72/m93/u9nHPOOfnKV77S951f+cpXMm/evHzxi1/M9u3bB/YH+C1mRA0zfTOibFgOAAAAe3mzmUsD5T3veU/Wr1+ftWvXZsOGDRk3blwmTpyY//Sf/lP+z//5PymVSlm7dm1effXVTJw4ca/7/+Ef/iE///nPc/755ydJtm3blo6OjiRJpVLJ/Pnz+z77269nzpyZm266KYsWLcq//tf/um/G1fXXX5+JEydmx44due6663LnnXfm6quvHuifIYkiatipjx6d2qRJiigAAAAYRObPn5/vf//7WbduXT72sY/l7/7u77Jhw4Y8+OCDGTFiRE499dT9zkyq1+v5+Mc/nuuvv36va4ceeuge+0L99utSqZQkufbaa/d4fdRRR/V99qKLLso3vvGN/nvQf4GlecNQtShSUUQBAADAoPGxj30s/+N//I98//vfz/z587Np06Z0dHRkxIgR+fGPf5xVq1bt9973v//9+d73vte3GXtPT8+bfv5f8sorryTZVXD98Ic/zLve9a63/F0Hy4yoYahaFBm5bFmzYwAAAABveOc735nf/OY3mTRpUo466qj83u/9Xj71qU/l3/ybf5OZM2dm+vTp+733+OOPz3XXXZeLL7449Xo9bW1tufnmm3Pssce+pSx/+qd/mu7u7tTr9cycObOhm5iX6vvbCatFrF69utkR+sVvH1M55utfz9iFC7PmuedSP+ywJicDDoQjo2HoM45haDOGYeh7s3G8ZcuWjB49usGJWsO+ftvJkyfv9/OW5g1DfSfnWZ4HAAAADCKW5g1D1c7OJLtOzqvOnNnkNAAAAMCB6O7uzkUXXbTX+9/97nfT3t7ehET9TxE1DNWmTUsSJ+cBAABAdm3KPRS0t7fn4YcfbnaMg3Kwv62lecNQ/fDDU+vosDQPAAAAkpTL5VSr1WbHGHaq1WrK5YOrlsyIGqZqRWFGFAAAACQZOXJktm3blu3bt6dUKjU7zrBQr9dTLpczcuTIg7pPETVMVYsihyxf3uwYAAAA0HSlUimjRo1qdgxiad6wVS2KtK1enWzd2uwoAAAAAEkUUcNWbffJeS+91OQkAAAAALsoooapalEkiQ3LAQAAgEFDETVM7S6i2rq6mhsEAAAA4A2KqGGqfsQR6T3iCCfnAQAAAIOGImoYq3Z2WpoHAAAADBqKqGGsWhRmRAEAAACDhiJqGKsVRSqrViU7djQ7CgAAAIAiajirFkVKvb2pvPRSs6MAAAAAKKKGs+q0aUlieR4AAAAwKCiihrFaZ2cSRRQAAAAwOCiihrHeCRPSO2aMk/MAAACAQUERNZyVSk7OAwAAAAYNRdQwVyuKtHV1NTsGAAAAgCJquKsWxa5T86rVZkcBAAAAWpwiapirdnamVK2m8vLLzY4CAAAAtDhF1DBXK4okTs4DAAAAmk8RNcxV3yiiKvaJAgAAAJpMETXM9R51VHpHjjQjCgAAAGg6RdRwVyql1tmpiAIAAACaThHVAqpFkcrKlc2OAQAAALQ4RVQLqBVF2lauTHp7mx0FAAAAaGGKqBZQLYqUtm9Pec2aZkcBAAAAWpgiqgXsPjnPPlEAAABAMymiWkCtszOJIgoAAABoLkVUC6gdfXTqhx6aiiIKAAAAaCJFVCsol1OdOtWMKAAAAKCpFFEtolYUaevqanYMAAAAoIUpolpEtSh2Lc2r15sdBQAAAGhRiqgWUS2KlLduTXndumZHAQAAAFqUIqpF1IoiiZPzAAAAgOZRRLWI6htFlJPzAAAAgGZRRLWI2rHHpt7WZsNyAAAAoGkUUa2irS21Y4+1NA8AAABoGkVUC6l2dlqaBwAAADSNIqqFVIti14yoer3ZUQAAAIAWpIhqIbWiSHnTppS7u5sdBQAAAGhBiqgW0ndyng3LAQAAgCZQRLWQ3UWUDcsBAACAZlBEtZDalCmpl8uKKAAAAKApFFGt5NBDUzvmGCfnAQAAAE2hiGoxtd0n5wEAAAA0mCKqxVSLwowoAAAAoCnaGvFH1q9fnzvuuCOvvfZaSqVS5s2bl/PPPz+bN2/OrbfemldffTVHHnlkrr766owZMyZJct9992XZsmUpl8u59NJLM2vWrCTJCy+8kDvuuCM7duzI7Nmzc+mll6ZUKmXnzp25/fbb88ILL+Twww/PggULMnHixEY83pBSLYpUenpSeu211I84otlxAAAAgBbSkBlRlUoln/zkJ3Prrbfm5ptvzkMPPZRVq1ZlyZIlOfHEE3PbbbflxBNPzJIlS5Ikq1atyvLly7N48eLccMMN+eY3v5ne3t4kyV133ZUrr7wyt912W9auXZsnn3wySbJs2bIcdthh+frXv5758+fnO9/5TiMebcipdXYmSdpWrmxyEgAAAKDVNKSIGj9+fI477rgkyahRo3LMMceku7s7K1asyNlnn50kOfvss7NixYokyYoVK3LGGWdkxIgRmThxYiZNmpTnn38+PT092bp1a44//viUSqWcddZZffc88cQTOeecc5Ikp512Wp5++unU6/VGPN6QUi2KJLE8DwAAAGi4hizN+23r1q1LV1dXpk+fno0bN2b8+PFJdpVVr7/+epKku7s7M2bM6Lunvb093d3dqVQqmTBhQt/7EyZMSHd3d989u69VKpWMHj06mzZtytixY/f4+0uXLs3SpUuTJAsXLkxHR8fAPWwDtbW1HdizHHZYkmTsunUZM0yeHYaDAx7DwKBlHMPQZgzD0GccDw0NLaK2bduWRYsW5ZJLLsno0aP3+7n9zWR6sxlO+7pWKpX2em/evHmZN29e3+v169e/WeQho6Oj44Cf5aijj86OZ57Ja8Pk2WE4OJgxDAxOxjEMbcYwDH3G8eAxefLk/V5r2Kl51Wo1ixYtygc+8IGceuqpSZJx48alp6cnSdLT09M3e2nChAnZsGFD373d3d1pb2/f6/0NGzakvb19r3tqtVq2bNnSt/E5e3JyHgAAANAMDSmi6vV6vvGNb+SYY47JRz7ykb7358yZk0cffTRJ8uijj+aUU07pe3/58uXZuXNn1q1blzVr1mT69OkZP358Ro0aleeeey71ej2PPfZY5syZkyQ5+eST88gjjyRJHn/88cycOXOfM6JIqp2daVNEAQAAAA3WkKV5zz77bB577LFMnTo1n/nMZ5IkF198cS644ILceuutWbZsWTo6OnLNNdckSaZMmZLTTz8911xzTcrlci677LKUy7s6s8svvzx33nlnduzYkVmzZmX27NlJkrlz5+b222/PVVddlTFjxmTBggWNeLQhqVYUqbz6akqbN6du1hgAAADQIKV6ix8tt3r16mZH6BcHsxZ25Pe/n/Yrrsi6hx5K9T3vGeBkwIGwnh2GPuMYhjZjGIY+43jwGBR7RDF4VKdNSxLL8wAAAICGUkS1oFpRJFFEAQAAAI2liGpB9TFjUjvySCfnAQAAAA2liGpR1aIwIwoAAABoKEVUi6oVRdq6upodAwAAAGghiqgWVS2KVNauTWnr1mZHAQAAAFqEIqpFVTs7kySVlSubnAQAAABoFYqoFuXkPAAAAKDRFFEtqjptWpI4OQ8AAABoGEVUi6ofcURq48fbsBwAAABoGEVUC6sVhaV5AAAAQMMoolpYtbPTZuUAAABAwyiiWlitKFJ5+eVk+/ZmRwEAAABagCKqhVWLIqXe3lReeqnZUQAAAIAWoIhqYdWiSBL7RAEAAAANoYhqYbXOziSKKAAAAKAxFFEtrHf8+PSOHZuKIgoAAABoAEVUKyuVUi0KM6IAAACAhlBEtbhaUaStq6vZMQAAAIAWoIhqcdWiSGXVqmTnzmZHAQAAAIY5RVSLqxZFStVqKi+/3OwoAAAAwDCniGpxtaJI4uQ8AAAAYOApolpc9Y0iysl5AAAAwEBTRLW43okT0ztqlA3LAQAAgAGniGp1pdKuk/PMiAIAAAAGmCKKVDs7Lc0DAAAABpwiilSLIm2//nVSqzU7CgAAADCMKaJIrShS2rEjlTVrmh0FAAAAGMYUUfy/k/NsWA4AAAAMIEUUfUWUDcsBAACAgaSIIr1HH536oYcqogAAAIABpYgiKZdTnTbNyXkAAADAgFJEkeSNk/NWrmx2DAAAAGAYU0SRZNfJeZWurqReb3YUAAAAYJhSRJFk14yo8rZtKb/ySrOjAAAAAMOUIookSa2zM4mT8wAAAICBo4giya4ZUUlsWA4AAAAMGEUUSZLa5MmpjxiRtq6uZkcBAAAAhilFFLu0taU2ZYqleQAAAMCAUUTRp1oUluYBAAAAA0YRRZ9qZ+euGVH1erOjAAAAAMOQIoo+taJIefPmlDdsaHYUAAAAYBhSRNGn7+Q8G5YDAAAAA0ARRZ/qtGlJYsNyAAAAYEAoouhTmzIl9XJZEQUAAAAMCEUU/88hh6R27LFOzgMAAAAGhCKKPVSLwowoAAAAYEAoothDTREFAAAADBBFFHuoFkXKr72WUk9Ps6MAAAAAw4wiij1UOzuTODkPAAAA6H+KKPZQK4okiigAAACg/ymi2EN16tTUSyUn5wEAAAD9ThHFnkaOTO3oo9PW1dXsJAAAAMAwo4hiL07OAwAAAAaCIoq9VDs7U1m5stkxAAAAgGFGEcVeakWRyvr1KW3a1OwoAAAAwDCiiGIv1TdOzjMrCgAAAOhPbY34I3feeWd+9rOfZdy4cVm0aFGS5G/+5m/y93//9xk7dmyS5OKLL85JJ52UJLnvvvuybNmylMvlXHrppZk1a1aS5IUXXsgdd9yRHTt2ZPbs2bn00ktTKpWyc+fO3H777XnhhRdy+OGHZ8GCBZk4cWIjHm1Y2l1EtXV1pfqe9zQ3DAAAADBsNGRG1DnnnJPPfe5ze70/f/78fPWrX81Xv/rVvhJq1apVWb58eRYvXpwbbrgh3/zmN9Pb25skueuuu3LllVfmtttuy9q1a/Pkk08mSZYtW5bDDjssX//61zN//vx85zvfacRjDVu13UWUDcsBAACAftSQIuqEE07ImDFjDuizK1asyBlnnJERI0Zk4sSJmTRpUp5//vn09PRk69atOf7441MqlXLWWWdlxYoVSZInnngi55xzTpLktNNOy9NPP516vT5QjzPs1UePTu2oo1JRRAEAAAD9qCFL8/bnoYceymOPPZbjjjsuf/iHf5gxY8aku7s7M2bM6PtMe3t7uru7U6lUMmHChL73J0yYkO7u7iRJd3d337VKpZLRo0dn06ZNfcv+ftvSpUuzdOnSJMnChQvT0dExkI/YMG1tbf36LKUZMzLq5ZczYpj8PjDY9fcYBhrPOIahzRiGoc84HhqaVkR96EMfyoUXXpgk+e53v5t77rknf/zHf7zfmUxvNsNpX9dKpdI+Pztv3rzMmzev7/X69esPJvag1dHR0a/PcsQxx+TQRx8dNr8PDHb9PYaBxjOOYWgzhmHoM44Hj8mTJ+/3WtNOzTviiCNSLpdTLpdz7rnn5le/+lWSXTOdNkqiOBYAACAASURBVGzY0Pe57u7utLe37/X+hg0b0t7evtc9tVotW7ZsOeClgOxbtShSWbs2pS1bmh0FAAAAGCaaVkT19PT0/fsnP/lJpkyZkiSZM2dOli9fnp07d2bdunVZs2ZNpk+fnvHjx2fUqFF57rnnUq/X89hjj2XOnDlJkpNPPjmPPPJIkuTxxx/PzJkz9zsjigOz++S8ysqVzQ0CAAAADBsNWZr3ta99Lb/4xS+yadOmfPrTn87v//7v55lnnsmLL76YUqmUI488MldccUWSZMqUKTn99NNzzTXXpFwu57LLLku5vKsvu/zyy3PnnXdmx44dmTVrVmbPnp0kmTt3bm6//fZcddVVGTNmTBYsWNCIxxrWfvvkvOq7393cMAAAAMCwUKq3+PFyq1evbnaEftHfa2FLGzfm6BNOyMbPfz6/+f/+v377XmDfrGeHoc84hqHNGIahzzgePAblHlEMbvVx41Jrb09bV1ezowAAAADDhCKK/aoVRdpefLHZMQAAAIBhQhHFflWLIhVFFAAAANBPFFHsV7WzM5XVq5Nt25odBQAAABgGDqiIqtfreeWVV9Lb2zvQeRhEakWRUr2etpdeanYUAAAAYBg4oCKqVCrlz/7szwY6C4NMtSiSJBUblgMAAAD94ICX5hVFkTVr1gxkFgaZ3UWUDcsBAACA/tB2oB+cOXNmvvzlL+fss89OR0fHHtfmzp3b78Fovvr48ekdN04RBQAAAPSLAy6inn322UycODG//OUv97qmiBqmSiUn5wEAAAD95oCLqC9+8YsDmYNBqloUOeSf/qnZMQAAAIBh4ICLqCTZvHlzfvrTn6a7uzvt7e05+eSTM2bMmIHKxiBQK4pUvve9ZOfOZMSIZscBAAAAhrAD3qz8ueeey1VXXZWHH344K1euzNKlS3PVVVflueeeG8h8NFm1KFKq1VJZtarZUQAAAIAh7oBnRN199925/PLLc+aZZ/a9t3z58vzlX/5lbrnllgEJR/PVOjuT7Do5b/e/AQAAAN6KA54RtWbNmpx++ul7vHfaaadl7dq1/R6KwaNaFEliw3IAAADgbTvgImrSpElZvnz5Hu/97//9v3PUUUf1eygGj96OjvQedljaurqaHQUAAAAY4g54ad4ll1yShQsX5sEHH0xHR0deffXVrFmzJp/97GcHMh/NViqlVhRpMyMKAAAAeJsOqIiq1+s54ogj8rWvfS3/9E//lJ6enpx88sk56aSTnJrXAqpFkbZ//udmxwAAAACGuAMqokqlUv7sz/4s3/72t3PWWWcNdCYGmWpnZ0b+6EdJrZZUKs2OAwAAAAxRB7xHVFEUWbNmzUBmYZCqFUVKO3emsnp1s6MAAAAAQ9gB7xE1c+bMfPnLX87ZZ5+djo6OPa7NnTu334MxePSdnNfVldqUKc0NAwAAAAxZB1xEPfvss5k4cWJ++ctf7nVNETW8VadNS5K0vfhidliaCQAAALxFB1RE9fb25gMf+EDe//7355BDDhnoTAwyvZMmpT5ypJPzAAAAgLflgPaIKpfLueeee5RQrapcTnXatFQUUQAAAMDbcMCblZ988sl54oknBjILg1i1KMyIAgAAAN6WA94jaufOnVm8eHGOP/74TJgwIaVSqe/an/7pnw5IOAaPWlFk5KOPJr29SfmA+0sAAACAPgdcRE2ZMiVTnJjWsqpFkdK2bSmvXZveyZObHQcAAAAYgg54asvHP/7xvPOd78yrr76aX/3qV/n4xz+ek046Ke9+97sHMh+DRLUoksTyPAAAAOAtO+Ai6sEHH8xdd92VyZMn55e//GWS5JBDDslf//VfD1g4Bo9aZ2cSRRQAAADw1h1wEfWDH/wgN954Yy644IKU39gj6Jhjjsnq1asHLByDR23y5NRHjHByHgAAAPCWHXARtXXr1nR0dOzxXrVaTVvbAW8zxVBWqaQ6dWraurqanQQAAAAYog64iHr3u9+dJUuW7PHegw8+mJkzZ/Z7KAanWlFYmgcAAAC8ZQdcRP3RH/1RfvKTn+RP/uRPsm3btvzH//gf8/jjj+dTn/rUQOZjEKkWRSorVyb1erOjAAAAAEPQAa+rGz9+fG655Zb86le/yquvvpoJEyZk+vTpfftFMfxVOztT/s1vUl6/Pr1HHtnsOAAAAMAQc1AbPJVKpUyfPj3Tp08fqDwMYrWiSLLr5LwdiigAAADgIJnOxAGrvlFEVWxYDgAAALwFiigOWO3YY1OvVGxYDgAAALwliigO3IgRqU2ZkooiCgAAAHgLFFEclGpRmBEFAAAAvCWKKA5KrSjS1tWV1OvNjgIAAAAMMYooDkq1KFJ+/fWUenqaHQUAAAAYYhRRHJTdJ+dZngcAAAAcLEUUB6XW2ZlEEQUAAAAcPEUUB6U6ZUrqpZKT8wAAAICDpoji4Bx6aGqTJ+/asBwAAADgICiiOGi1orA0DwAAADhoiigOWrUoLM0DAAAADpoiioNW7exMpbs7pY0bmx0FAAAAGEIUURy0WlEkSdpWrmxuEAAAAGBIUURx0KpvFFEVG5YDAAAAB0ERxUGrTZuWJDYsBwAAAA6KIoqDVh89OrVJkxRRAAAAwEFRRPGWODkPAAAAOFiKKN6SalGYEQUAAAAcFEUUb0mtKFJZty6lLVuaHQUAAAAYIhRRvCV9J+eZFQUAAAAcIEUUb0m1szOJk/MAAACAA9fWiD9y55135mc/+1nGjRuXRYsWJUk2b96cW2+9Na+++mqOPPLIXH311RkzZkyS5L777suyZctSLpdz6aWXZtasWUmSF154IXfccUd27NiR2bNn59JLL02pVMrOnTtz++2354UXXsjhhx+eBQsWZOLEiY14tJZVmzYtiSIKAAAAOHANmRF1zjnn5HOf+9we7y1ZsiQnnnhibrvttpx44olZsmRJkmTVqlVZvnx5Fi9enBtuuCHf/OY309vbmyS56667cuWVV+a2227L2rVr8+STTyZJli1blsMOOyxf//rXM3/+/HznO99pxGO1tPrhh6fW0WFpHgAAAHDAGlJEnXDCCX2znXZbsWJFzj777CTJ2WefnRUrVvS9f8YZZ2TEiBGZOHFiJk2alOeffz49PT3ZunVrjj/++JRKpZx11ll99zzxxBM555xzkiSnnXZann766dTr9UY8WkurFUXaurqaHQMAAAAYIhqyNG9fNm7cmPHjxydJxo8fn9dffz1J0t3dnRkzZvR9rr29Pd3d3alUKpkwYULf+xMmTEh3d3ffPbuvVSqVjB49Ops2bcrYsWP3+rtLly7N0qVLkyQLFy5MR0fHwDxgg7W1tTX8WSrvelfKjz46bH5DaKZmjGGgfxnHMLQZwzD0GcdDQ9OKqP3Z30ymN5vhtK9rpVJpn5+dN29e5s2b1/d6/fr1B5lwcOro6Gj4s4yZNCljX3op6196KRk1qqF/G4abZoxhoH8ZxzC0GcMw9BnHg8fkyZP3e61pp+aNGzcuPT09SZKenp6+2UsTJkzIhg0b+j7X3d2d9vb2vd7fsGFD2tvb97qnVqtly5Ytey0FpP/Vdp+c99JLTU4CAAAADAVNK6LmzJmTRx99NEny6KOP5pRTTul7f/ny5dm5c2fWrVuXNWvWZPr06Rk/fnxGjRqV5557LvV6PY899ljmzJmTJDn55JPzyCOPJEkef/zxzJw5c78zoug/1aJIEhuWAwAAAAekIUvzvva1r+UXv/hFNm3alE9/+tP5/d///VxwwQW59dZbs2zZsnR0dOSaa65JkkyZMiWnn356rrnmmpTL5Vx22WUpl3f1ZZdffnnuvPPO7NixI7Nmzcrs2bOTJHPnzs3tt9+eq666KmPGjMmCBQsa8VgtrzptWpKkrasr25ucBQAAABj8SvUWP15u9erVzY7QL5q1FnbSzJnZ+tGPZuMttzT8b8NwYj07DH3GMQxtxjAMfcbx4DEo94hieKgWhaV5AAAAwAFRRPG2VIsibYooAAAA4AAoonhbakWRyqpVyY4dzY4CAAAADHKKKN6WalGk1NubyksvNTsKAAAAMMgponhbqkWRJJbnAQAAAP8iRRRvS62zM4kiCgAAAPiXKaJ4W3onTEjvmDFOzgMAAAD+RYoo3p5Sycl5AAAAwAFRRPG21YoibV1dzY4BAAAADHKKKN62alGksmpVUq02OwoAAAAwiCmieNuqnZ0p7dyZyurVzY4CAAAADGKKKN62WlEkcXIeAAAA8OYUUbxt1TeKqIp9ogAAAIA3oYjibes96qj0jhxpRhQAAADwphRRvH2lUmqdnakoogAAAIA3oYiiX1SLwowoAAAA4E0pougXtaJI28qVSW9vs6MAAAAAg5Qiin5RLYqUtm9Pec2aZkcBAAAABilFFP1i98l5lucBAAAA+6OIol/UOjuTKKIAAACA/VNE0S9qkyalfsghTs4DAAAA9ksRRf+oVFKdOtWMKAAAAGC/FFH0m1pRpK2rq9kxAAAAgEFKEUW/qRbFrqV59XqzowAAAACDkCKKflPt7Ex569aU161rdhQAAABgEFJE0W9qRZHEyXkAAADAvimi6DfVN4ooJ+cBAAAA+6KIot/Ujj029bY2G5YDAAAA+6SIov+0taV27LGW5gEAAAD7pIiiX1U7Oy3NAwAAAPZJEUW/qhbFrhlR9XqzowAAAACDjCKKflUripQ3bUq5p6fZUQAAAIBBRhFFv+o7Oc+G5QAAAMDvUETRr3YXUTYsBwAAAH6XIop+VZsyJfVyWREFAAAA7EURRf869NDUjjnGyXkAAADAXhRR9LtaUaTNHlEAAADA71BE0e+qRWFGFAAAALAXRRT9rloUqfT0pPTaa82OAgAAAAwiiij6Xa2zM0nStnJlk5MAAAAAg4kiin5XLYoksTwPAAAA2IMiin5XnTo1SWxYDgAAAOxBEUX/GzUqtUmT0mZGFAAAAPBbFFEMiGpnp6V5AAAAwB4UUQyIalGYEQUAAADsQRHFgKgVRSqvvprS5s3NjgIAAAAMEoooBoST8wAAAIDfpYhiQOwuoizPAwAAAHZTRDEgaoooAAAA4HcoohgQ9TFjUjvySEvzAAAAgD6KKAaMk/MAAACA36aIYsDUiiJtXV3NjgEAAAAMEoooBky1KFJZuzbZurXZUQAAAIBBQBHFgKl2diZJ2n796yYnAQAAAAYDRRQDxsl5AAAAwG9TRDFgqtOmJUkq9okCAAAAoohiANWPOCK18ePNiAIAAACSJG3NDvAnf/InGTlyZMrlciqVShYuXJjNmzfn1ltvzauvvpojjzwyV199dcaMGZMkue+++7Js2bKUy+VceumlmTVrVpLkhRdeyB133JEdO3Zk9uzZufTSS1MqlZr5aOSNk/MUUQAAAEAGQRGVJF/84hczduzYvtdLlizJiSeemAsuuCBLlizJkiVL8olPfCKrVq3K8uXLs3jx4vT09OSmm27KX/zFX6RcLueuu+7KlVdemRkzZuSWW27Jk08+mdmzZzfxqUh2bVh+yIoVzY4BAAAADAKDcmneihUrcvbZZydJzj777Kx4o8hYsWJFzjjjjIwYMSITJ07MpEmT8vzzz6enpydbt27N8ccfn1KplLPOOqvvHpqrVhSpvPxysn17s6MAAAAATTYoZkTdfPPNSZLzzjsv8+bNy8aNGzN+/Pgkyfjx4/P6668nSbq7uzNjxoy++9rb29Pd3Z1KpZIJEyb0vT9hwoR0d3fv828tXbo0S5cuTZIsXLgwHR0dA/JMjdbW1jYon6V84okp9famY/Pm5Jhjmh0HBq3BOoaBA2ccw9BmDMPQZxwPDU0vom666aa0t7dn48aN+S//5b9k8uTJ+/1svV4/qPf3Zd68eZk3b17f6/Xr1x942EGso6NjUD7LiAkTcmSSTf/4j9n+W2UhsKfBOoaBA2ccw9BmDMPQZxwPHm/W7TR9aV57e3uSZNy4cTnllFPy/PPPZ9y4cenp6UmS9PT09O0fNWHChGzYsKHv3u7u7rS3t+/1/oYNG/q+l+aqdXYmiQ3LAQAAgOYWUdu2bcvWrVv7/v3UU09l6tSpmTNnTh599NEkyaOPPppTTjklSTJnzpwsX748O3fuzLp167JmzZpMnz4948ePz6hRo/Lcc8+lXq/nsccey5w5c5r2XPw/vePHp/fww1NRRAEAAEDLa+rSvI0bN+bP//zPkyS1Wi3vf//7M2vWrLzjHe/IrbfemmXLlqWjoyPXXHNNkmTKlCk5/fTTc80116RcLueyyy5LubyrS7v88stz5513ZseOHZk1a5YT8waLUinVojAjCgAAAEipfjAbLA1Dq1evbnaEfjGY18KO//SnM+LnP8+6H/+42VFg0BrMYxg4MMYxDG3GMAx9xvHgMaj3iGL4qxZFKqtWJTt3NjsKAAAA0ESKKAZctbMzpWo1lZdfbnYUAAAAoIkUUQy4WlEkcXIeAAAAtDpFFAOu+kYR5eQ8AAAAaG2KKAZc78SJ6R01Km1dXc2OAgAAADSRIoqBVyqlVhSW5gEAAECLU0TRENXOTkvzAAAAoMUpomiIalGk7de/Tmq1ZkcBAAAAmkQRRUPUiiKlHTtSWbu22VEAAACAJlFE0RB9J+fZsBwAAABaliKKhthdRNmwHAAAAFqXIoqG6D366NQPPVQRBQAAAC1MEUVjlMupTpvm5DwAAABoYYooGqZaFGZEAQAAQAtTRNEwtaLYtVl5vd7sKAAAAEATKKJomGpRpLxtW8qvvNLsKAAAAEATKKJomFpnZxIn5wEAAECrUkTRMNWiSBIblgMAAECLUkTRMLXJk1Nva0tbV1ezowAAAABNoIiicdraUpsyxdI8AAAAaFGKKBqq2tlpaR4AAAC0KEUUDVUtil0zour1ZkcBAAAAGkwRRUPViiLlzZtT3rCh2VEAAACABlNE0VB9J+fZsBwAAABajiKKhtpdRNmwHAAAAFqPIoqGqk2Zknq5rIgCAACAFqSIorEOOSS1Y491ch4AAAC0IEUUDdd3ch4AAADQUhRRNFxNEQUAAAAtSRFFw1WLIuXXXkupp6fZUQAAAIAGUkTRcNXOziRJ28qVTU4CAAAANJIiioarFUWSWJ4HAAAALUYRRcNVp05NvVRKpaur2VEAAACABlJE0XgjR6Z29NFmRAEAAECLUUTRFE7OAwAAgNajiKIpqp2dqSiiAAAAoKUoomiKWlGksn59Sps2NTsKAAAA0CCKKJqi+sbJeZWVK5sbBAAAAGgYRRRNsbuIanNyHgAAALQMRRRNUdtdRNknCgAAAFqGIoqmqI8endrEiTYsBwAAgBaiiKJpqkVhRhQAAAC0EEUUTVNTRAEAAEBLUUTRNNWiSGXt2pS2bGl2FAAAAKABFFE0ze6T8yorVzY3CAAAANAQiiiaptbZmcTJeQAAANAqFFE0TXXatCRxch4AAAC0CEUUTVMfNy619va0dXU1OwoAAADQAIoomsrJeQAAANA6FFE0VbUoLM0DAACAFqGIoqmqnZ2prF6dbN/e7CgAAADAAFNE0VS1okipXk/bSy81OwoAAAAwwBRRNFW1KJIkFRuWAwAAwLCniKKpdhdRNiwHAACA4U8RRVPVx49P77hxiigAAABoAW3NDkCLK5VSLYq0PfNM2p55JqlUkkol9XJ5n//e43W5vOe1cjkplZr9RAAAAMB+DKsi6sknn8xf/uVfpre3N+eee24uuOCCZkdqiLFPXJRUenNEtZZSuZJS+f9v7+5io6j/PY5/ZncVsdU+7JaWx2CR6KkWkWxDghLAVmKkUWKUExI0YhM1cuGBIwEMgYuCYoSgF/gQQny4MOBVTzQx/kNDIRESSBpDomkCKFxoeWi31IJtdNk5F92dnd2d7W5pO9Nd3q+k6cxvfg/fmZ3fzuy3u1tD8gUkwy8ZPplGQJJPMgIy42XWckr58I+1LL/MeF17uSl73UC8v/h2pfVhBIb7kG3Z6m94+dbcak39v/9o2sqVYz4WKUkqv1/y+ySfX6Y/Ue4fLvcZki+e2LIlsuzL1jb7cnoCzL7NNCXTlBH/nfIjZZRl1EuvE18ft/6c6iXqJNgTeYYhGYbM+G9rm9N6tvpZ6tjXM+o7xJBSL1sMhpF8jAwj9fGzP07ZttmWrXMh1zaH7SP26/cP74c9qZrYdu2a/P39yf1KJFZty6bkWC6fb3hblnYZx9leJ/2YAwDGX/p1Oc9lw95+tH0k2udZN+P+I5+xs5WlL9v3Jcv2kdqOW900RnqMZWW66/r1kdvm0//txJTreN1uv+NpovtPH2MM58GkP99ud4x8t43ivB/T/o31nEx/3MZh7vhKSnTvjRujOza2MsfHKZ++nOo6jJH1PLAt31y/XmZJiXM/RaJoElGxWEyHDh3S9u3bFQwGtW3bNoXDYc2aNcvr0CZczX//RzeHpmaUG0ZMhmHKkDn8O77s89nKZFr1fOn1be2ybbPKx1I/9r6Mae8Nrytx4xRfNpVZpuEJbC9P1HNsY8bLoqY18bO1MdKeINLLknWV2Ua2JzAjy7LV2GHZqi/n+un9SDIN24XWGKlPM7VOfKDkshyPZ/K4p/Y54mNj32ZkeawMh+Ps0Gd6fyONL0lGzJTi24Z/MpeTibhkudPNXvL4xeI/zuzHeSx1xrveaPsyJVtiT7bfRtq5ZaRtT7YzjOT5l6iQPG+T7eznXaK9/dy1+lJqPPY5YI0pczjJZq9nj9Ua2syM1x6Dvf+0xJw1z+zF8YL0uDPLDecxUsqNtH1zKnfqJ+3xygw9o8+U88KhcqLEdCpMXUxbcejfYZzU8bOFmbiRcwomjZm6YKS1NdIrjtin7fnDcYzcfQV8hm7FYiPcpNpiMtMaJ56TjLRtiecvJfYpPUYztX3KJnusyWUjvU7Kw5LlODj2mR5G/Pk03xciZua25GOYZRzHbfbjo8zjl/6YSTLyqJO6bDqOl3rcUx/3iUjx53puH4/rw0Rvz6VQ2hf69d+t+m6NQfvJ034yKPR9eKD5Od1FIqownD9/XjU1NaqurpYkLVmyRGfOnLkjElH/87//KhC4Szdv/h3/o5Rh/XEqcT+c/kerWCxZZ7i+IdP0pZWZMmOmzHhhLLEc/534SZZLphkbHssql62upJipmFWmeF+2daXel5rm8As6p32Q0ssMmTJlmsN38cPr8Xv6EdpYddNfW5gafgWavt3ePvGyKeXeM/lSLrmc/lokS7mtvrKUp94X5+5nNPWTx8CwyjPLEo1sdTL6Sda195UyRmJdhmNZRj8jbLOXjyTl+CY4FJnmHfr1eWbabwAAAACu+tl3VlVeBzHBiiYRFYlEFAwGrfVgMKhz585l1Dt69KiOHj0qSdqzZ49CoZBrMU6UHTukQMCnaPQer0MBXFBY2ZJc70hO8PsDikaj49JfvmOOZ7083imdd9l49jWWMXNtK5TyYtmey2RoHwjkN49vN4ixxphz+DE+r5qxMbYf4w6OtX0eA0xs/3kP7xxHRniOT34jF4x5Hud1DmSvY46wlr2RaVvM9kep/PryGT7dit3Kf8gRDsj4XGPt+5ZHX6Ocg7lr53F+jPPzVs55nHO8iX4eyzH+mEafDM+jY2o+CQaQfD6/bt3KPY8ns9r/elBTphZNqsZR0eyd06QzHD520NTUpKamJmu9p6dnQuNySygUKpp9Ae5EoVBIkQhzuJhl+9gcX9FVPLgWA4WNOVwIcl00uaje6YphHg/cvK6Bm15HMXYzZszIuq1oPn8SDAbV29trrff29qqiosLDiAAAAAAAAGBXNImoefPmqbu7W1evXlU0GtXJkycVDoe9DgsAAAAAAABxRfPRPL/fr9dee027d+9WLBbTihUrNHv2bK/DAgAAAAAAQFzRJKIkadGiRVq0aJHXYQAAAAAAAMBB0Xw0DwAAAAAAAJMbiSgAAAAAAAC4gkQUAAAAAAAAXEEiCgAAAAAAAK4gEQUAAAAAAABXkIgCAAAAAACAK0hEAQAAAAAAwBUkogAAAAAAAOAKElEAAAAAAABwBYkoAAAAAAAAuIJEFAAAAAAAAFxhmKZpeh0EAAAAAAAAih/viCoSW7du9ToEAGPAHAYKH/MYKGzMYaDwMY8LA4koAAAAAAAAuIJEFAAAAAAAAFxBIqpINDU1eR0CgDFgDgOFj3kMFDbmMFD4mMeFgS8rBwAAAAAAgCt4RxQAAAAAAABcQSIKAAAAAAAArgh4HQDG5ueff9YXX3yhWCymxsZGrV692uuQAIzShg0bdM8998jn88nv92vPnj1ehwQgh08++USdnZ0qKyvTvn37JEk3btzQ/v37de3aNVVVVWnjxo0qLS31OFIATpzm8Lfffqv29nbdf//9kqS1a9dq0aJFXoYJIIuenh4dOHBA169fl2EYampq0rPPPsu1uECQiCpgsVhMhw4d0vbt2xUMBrVt2zaFw2HNmjXL69AAjNLOnTutG18Ak9/y5cv1zDPP6MCBA1ZZW1ub6uvrtXr1arW1tamtrU3r1q3zMEoA2TjNYUlatWqVnnvuOY+iApAvv9+vl19+WbW1tRocHNTWrVu1YMECdXR0cC0uAHw0r4CdP39eNTU1qq6uViAQ0JIlS3TmzBmvwwIAoOjV1dVl/IX1zJkzWrZsmSRp2bJlXJOBScxpDgMoHBUVFaqtrZUkTZ06VTNnzlQkEuFaXCB4R1QBi0QiCgaD1nowGNS5c+c8jAjA7dq9e7ck6emnn+bfzgIFqr+/XxUVFZKGb5D/+usvjyMCMFo//vijTpw4odraWr3yyiskq4ACcPXqVf3+++968MEHuRYXCBJRBcw0zYwywzA8iATAWLS2tqqyslL9/f3atWuXZsyYobq6Oq/DAgDgjrJy5Uq9+OKLkqQjR47o66+/1ltvveVxVABGMjQ0pH379unVV1/Vvffe63U4yBMfzStgwWBQvb291npvb6+V/QVQOCorKyVJZWVlamho0Pnz5z2OCMDtKCsrU19fCXu6NAAABUpJREFUnySpr6+P730DCkx5ebl8Pp98Pp8aGxt14cIFr0MCMIJoNKp9+/Zp6dKlWrx4sSSuxYWCRFQBmzdvnrq7u3X16lVFo1GdPHlS4XDY67AAjMLQ0JAGBwet5bNnz2rOnDkeRwXgdoTDYR0/flySdPz4cTU0NHgcEYDRSLx4laTTp09r9uzZHkYDYCSmaeqzzz7TzJkz1dzcbJVzLS4Mhun0+S4UjM7OTn311VeKxWJasWKFXnjhBa9DAjAKV65c0d69eyVJt27d0pNPPsk8BgrARx99pF9//VUDAwMqKyvTmjVr1NDQoP3796unp0ehUEibNm3i+2WAScppDv/yyy+6ePGiDMNQVVWVXn/9dT5tAExSXV1d2rFjh+bMmWN9Pc3atWs1f/58rsUFgEQUAAAAAAAAXMFH8wAAAAAAAOAKElEAAAAAAABwBYkoAAAAAAAAuIJEFAAAAAAAAFxBIgoAAAAAAACuIBEFAABQBNasWaPLly97HQYAAMCIAl4HAAAAUIw2bNig69evy+dL/t1v+fLlamlp8TAqAAAAb5GIAgAAmCBbtmzRggULvA4DAABg0iARBQAA4KKOjg61t7frgQce0PHjx1VRUaGWlhbV19dLkiKRiA4ePKiuri6Vlpbq+eefV1NTkyQpFoupra1Nx44dU39/v6ZPn67NmzcrFApJks6ePav33ntPAwMDeuKJJ9TS0iLDMHT58mV9+umnunjxogKBgB599FFt3LjRs2MAAADuXCSiAAAAXHbu3DktXrxYhw4d0unTp7V3714dOHBApaWl+vjjjzV79mx9/vnn+vPPP9Xa2qrq6mrV19fr+++/108//aRt27Zp+vTpunTpkqZMmWL129nZqffff1+Dg4PasmWLwuGwFi5cqMOHD+uxxx7Tzp07FY1G9dtvv3m49wAA4E5GIgoAAGCCfPjhh/L7/db6unXrFAgEVFZWplWrVskwDC1ZskTfffedOjs7VVdXp66uLm3dulV333235s6dq8bGRp04cUL19fVqb2/XunXrNGPGDEnS3LlzU8ZbvXq1SkpKVFJSokceeUQXL17UwoULFQgEdO3aNfX19SkYDOrhhx928zAAAABYSEQBAABMkM2bN2d8R1RHR4cqKytlGIZVVlVVpUgkor6+PpWWlmrq1KnWtlAopAsXLkiSent7VV1dnXW88vJya3nKlCkaGhqSNJwAO3z4sN59912VlJSoublZTz311LjsIwAAwGiQiAIAAHBZJBKRaZpWMqqnp0fhcFgVFRW6ceOGBgcHrWRUT0+PKisrJUnBYFBXrlzRnDlzRjVeeXm53nzzTUlSV1eXWltbVVdXp5qamnHcKwAAgNx8uasAAABgPPX39+uHH35QNBrVqVOn9Mcff+jxxx9XKBTSQw89pG+++Ub//POPLl26pGPHjmnp0qWSpMbGRh05ckTd3d0yTVOXLl3SwMBAzvFOnTql3t5eSVJJSYkkyefjNhAAALiPd0QBAABMkA8++CAl4bNgwQI1NDRo/vz56u7uVktLi8rLy7Vp0ybdd999kqS3335bBw8e1BtvvKHS0lK99NJL1sf7mpub9e+//2rXrl0aGBjQzJkz9c477+SM48KFC/ryyy/1999/q7y8XOvXr9e0adMmZqcBAABGYJimaXodBAAAwJ2io6ND7e3tam1t9ToUAAAA1/GebAAAAAAAALiCRBQAAAAAAABcwUfzAAAAAAAA4AreEQUAAAAAAABXkIgCAAAAAACAK0hEAQAAAAAAwBUkogAAAAAAAOAKElEAAAAAAABwxf8Drj11ut/3SCUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_mse = result_df_tr_all.values[:,3].squeeze()\n",
    "tr_spr_50 = 100*result_df_tr_all.values[:,4].squeeze()\n",
    "va_err = 5*result_df_va_all.values[:,-1].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_mse, color='orange', label='train mse')\n",
    "plt.plot(tr_spr_50, color='red', label='tr spr*100')\n",
    "plt.plot(va_err, color='blue', label='va_err*5')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
