{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "sys.path.insert(1,'/home/wsubuntu/GitHub/keyhandshapediscovery')\n",
    "import helperFuncs as funcH\n",
    "import pandas as pd\n",
    "\n",
    "EXPERIMENT_ID = 4\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'sum','batchmean'\n",
    "SIGMOID_ACT=True\n",
    "MSE_PLUS_MINUS='-'\n",
    "APPLY_SPARSITY_TO='bottleneck' #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 20  # args['epochs']\n",
    "reg_param = 0.001  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": '/media/wsubuntu/SSD_Data/DataPath',\n",
    "    \"experiment\": '/media/wsubuntu/SSD_Data/vaesae_experiments/sparse_torch_ae_ws_' + str(EXPERIMENT_ID).zfill(3),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=16)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=16, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    "\n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        bottleneck = F.relu(self.enc5(x))  \n",
    "        return bottleneck\n",
    "        \n",
    "    def decode(self, bottleneck):\n",
    "        # decoding\n",
    "        x = F.relu(self.dec1(bottleneck))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x)) \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encode(x)\n",
    "        x = self.decode(bottleneck)\n",
    "        return x, bottleneck\n",
    "\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=16, bias=True)\n",
      "Linear(in_features=16, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    rho = 0.05\n",
    "    bottleneck = torch.mean(torch.sigmoid(bottleneck), 1)  # sigmoid because we need the probability distributions\n",
    "    rho = torch.tensor([rho] * len(bottleneck)).to(device)\n",
    "    loss_ret_1 = torch.nn.functional.kl_div(bottleneck, rho, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct:\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    _, preds = torch.max(bt, 1)\n",
    "    loss_ret_1 = loss_fun(bt, preds)    \n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss\n",
    "\n",
    "def sparse_loss_bottleneck(bottleneck, print_info, loss_type):\n",
    "    loss = 0\n",
    "    #if print_info:\n",
    "        #print(i, ' shape=', values.shape)\n",
    "    if loss_type=='l1':\n",
    "        loss += loss_l1(bottleneck)\n",
    "    if loss_type=='l2':\n",
    "        loss += loss_l2(bottleneck)\n",
    "    if loss_type=='kl':\n",
    "        loss += kl_divergence(bottleneck, reduction=LOSS_REDUCTION)\n",
    "    if loss_type=='cre':\n",
    "        loss += loss_crossentropy(bottleneck, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION)\n",
    "    if print_info:\n",
    "        print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            if APPLY_SPARSITY_TO=='all':\n",
    "                sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            elif APPLY_SPARSITY_TO=='bottleneck': #all\n",
    "                sp_loss = sparse_loss_bottleneck(bottleneck, print_losses_fit, model.loss_type)\n",
    "            else:\n",
    "                os.exit(4)\n",
    "                \n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            \n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "                \n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_ws05 :: \n",
      "EXPERIMENT_ID:  4\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  True\n",
      "APPLY_SPARSITY_TO :  bottleneck\n",
      "total loss = mse_loss - reg_param * sp_loss\n",
      "*****\n",
      " Epoch 0 of 20\n",
      "TrEpoch(000) - cre tensor(2.7411, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.7410919666290283\n",
      "\n",
      "       acc     bmx  bmn      mse      spr      run\n",
      "0  16.642  28.871  0.0  149.231  4783.99  144.447\n",
      "ValEpoch(000) - \n",
      "      acc     bmx  bmn     run\n",
      "0  20.77  29.891  0.0  16.371\n",
      "*****\n",
      " Epoch 1 of 20\n",
      "TrEpoch(001) - \n",
      "       acc     bmx  bmn     mse       spr     run\n",
      "0  24.647  36.147  0.0  90.008  4870.251  85.137\n",
      "ValEpoch(001) - \n",
      "      acc     bmx  bmn   run\n",
      "0  17.39  35.406  0.0  13.9\n",
      "*****\n",
      " Epoch 2 of 20\n",
      "TrEpoch(002) - \n",
      "      acc     bmx  bmn     mse       spr    run\n",
      "0  27.38  37.637  0.0  78.662  4891.992  73.77\n",
      "ValEpoch(002) - \n",
      "      acc     bmx  bmn     run\n",
      "0  28.97  36.093  0.0  12.667\n",
      "*****\n",
      " Epoch 3 of 20\n",
      "TrEpoch(003) - \n",
      "       acc     bmx  bmn     mse       spr     run\n",
      "0  28.878  40.069  0.0  72.564  4918.796  67.646\n",
      "ValEpoch(003) - \n",
      "      acc     bmx  bmn     run\n",
      "0  28.11  39.712  0.0  11.801\n",
      "*****\n",
      " Epoch 4 of 20\n",
      "TrEpoch(004) - \n",
      "       acc     bmx  bmn     mse       spr     run\n",
      "0  27.635  41.924  0.0  69.321  4936.342  64.385\n",
      "ValEpoch(004) - \n",
      "      acc    bmx  bmn     run\n",
      "0  26.95  41.36  0.0  11.461\n",
      "*****\n",
      " Epoch 5 of 20\n",
      "TrEpoch(005) - \n",
      "      acc     bmx  bmn     mse       spr     run\n",
      "0  27.35  42.958  0.0  67.182  4944.975  62.237\n",
      "ValEpoch(005) - \n",
      "      acc     bmx  bmn     run\n",
      "0  26.63  42.052  0.0  11.095\n",
      "*****\n",
      " Epoch 6 of 20\n",
      "TrEpoch(006) - cre tensor(2.6404, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.640403985977173\n",
      "\n",
      "       acc     bmx  bmn     mse       spr     run\n",
      "0  27.462  43.759  0.0  65.544  4950.475  60.593\n",
      "ValEpoch(006) - \n",
      "      acc     bmx  bmn     run\n",
      "0  27.63  42.727  0.0  10.908\n",
      "*****\n",
      " Epoch 7 of 20\n",
      "TrEpoch(007) - \n",
      "       acc     bmx  bmn     mse       spr     run\n",
      "0  27.692  44.601  0.0  63.787  4955.003  58.832\n",
      "ValEpoch(007) - \n",
      "      acc     bmx  bmn     run\n",
      "0  27.49  43.872  0.0  10.529\n",
      "*****\n",
      " Epoch 8 of 20\n",
      "TrEpoch(008) - \n",
      "       acc    bmx  bmn     mse       spr     run\n",
      "0  24.862  46.19  0.0  61.259  4960.842  56.299\n",
      "ValEpoch(008) - \n",
      "      acc     bmx  bmn     run\n",
      "0  27.24  44.788  0.0  10.133\n",
      "*****\n",
      " Epoch 9 of 20\n",
      "TrEpoch(009) - \n",
      "       acc     bmx  bmn    mse      spr     run\n",
      "0  28.078  45.766  0.0  59.63  4972.75  54.657\n",
      "ValEpoch(009) - \n",
      "     acc     bmx  bmn    run\n",
      "0  27.9  44.888  0.0  9.921\n",
      "*****\n",
      " Epoch 10 of 20\n",
      "TrEpoch(010) - \n",
      "       acc     bmx  bmn    mse       spr     run\n",
      "0  28.173  46.961  0.0  58.68  4984.103  53.696\n",
      "ValEpoch(010) - \n",
      "      acc   bmx  bmn    run\n",
      "0  27.63  45.9  0.0  9.695\n",
      "*****\n",
      " Epoch 11 of 20\n",
      "TrEpoch(011) - cre tensor(2.6614, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.6613872051239014\n",
      "\n",
      "       acc     bmx  bmn     mse       spr   run\n",
      "0  28.092  47.249  0.0  56.692  4991.304  51.7\n",
      "ValEpoch(011) - \n",
      "     acc     bmx  bmn    run\n",
      "0  27.9  46.058  0.0  9.449\n",
      "*****\n",
      " Epoch 12 of 20\n",
      "TrEpoch(012) - \n",
      "       acc     bmx  bmn     mse       spr     run\n",
      "0  28.007  47.041  0.0  56.101  4994.724  51.107\n",
      "ValEpoch(012) - \n",
      "      acc     bmx  bmn    run\n",
      "0  27.61  46.509  0.0  9.386\n",
      "*****\n",
      " Epoch 13 of 20\n",
      "TrEpoch(013) - \n",
      "      acc     bmx  bmn     mse       spr     run\n",
      "0  28.02  47.015  0.0  55.657  4996.433  50.661\n",
      "ValEpoch(013) - \n",
      "      acc     bmx  bmn    run\n",
      "0  27.61  45.933  0.0  9.295\n",
      "*****\n",
      " Epoch 14 of 20\n",
      "TrEpoch(014) - \n",
      "       acc   bmx  bmn     mse       spr     run\n",
      "0  28.093  46.4  0.0  55.174  4997.432  50.176\n",
      "ValEpoch(014) - \n",
      "      acc     bmx  bmn    run\n",
      "0  27.49  45.784  0.0  9.247\n",
      "*****\n",
      " Epoch 15 of 20\n",
      "TrEpoch(015) - \n",
      "       acc     bmx  bmn     mse       spr     run\n",
      "0  28.007  46.344  0.0  53.942  4998.355  48.944\n",
      "ValEpoch(015) - \n",
      "      acc     bmx  bmn    run\n",
      "0  27.34  45.715  0.0  8.874\n",
      "*****\n",
      " Epoch 16 of 20\n",
      "TrEpoch(016) - cre tensor(2.6684, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.6684153079986572\n",
      "\n",
      "       acc     bmx  bmn     mse       spr     run\n",
      "0  27.915  45.613  0.0  52.312  4998.969  47.313\n",
      "ValEpoch(016) - \n",
      "      acc     bmx  bmn    run\n",
      "0  27.65  45.036  0.0  8.576\n",
      "*****\n",
      " Epoch 17 of 20\n",
      "TrEpoch(017) - \n",
      "       acc    bmx  bmn     mse       spr     run\n",
      "0  27.965  46.01  0.0  50.794  4999.349  45.795\n",
      "ValEpoch(017) - \n",
      "      acc     bmx  bmn    run\n",
      "0  27.48  44.897  0.0  8.495\n",
      "*****\n",
      " Epoch 18 of 20\n",
      "TrEpoch(018) - \n",
      "       acc    bmx  bmn     mse       spr     run\n",
      "0  28.125  45.46  0.0  50.138  4999.835  45.138\n",
      "ValEpoch(018) - \n",
      "      acc     bmx  bmn    run\n",
      "0  27.37  44.735  0.0  8.337\n",
      "*****\n",
      " Epoch 19 of 20\n",
      "TrEpoch(019) - \n",
      "       acc     bmx  bmn     mse      spr     run\n",
      "0  28.243  45.421  0.0  49.393  5000.18  44.393\n",
      "ValEpoch(019) - \n",
      "      acc     bmx  bmn    run\n",
      "0  27.62  44.583  0.0  8.274\n",
      "30.2 minutes\n"
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_ws05 :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"APPLY_SPARSITY_TO : \", APPLY_SPARSITY_TO)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param * sp_loss\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       acc     bmx  bmn      mse       spr      run\n",
      "0   16.642  28.871  0.0  149.231  4783.990  144.447\n",
      "1   24.647  36.147  0.0   90.008  4870.251   85.137\n",
      "2   27.380  37.637  0.0   78.662  4891.992   73.770\n",
      "3   28.878  40.069  0.0   72.564  4918.796   67.646\n",
      "4   27.635  41.924  0.0   69.321  4936.342   64.385\n",
      "5   27.350  42.958  0.0   67.182  4944.975   62.237\n",
      "6   27.462  43.759  0.0   65.544  4950.475   60.593\n",
      "7   27.692  44.601  0.0   63.787  4955.003   58.832\n",
      "8   24.862  46.190  0.0   61.259  4960.842   56.299\n",
      "9   28.078  45.766  0.0   59.630  4972.750   54.657\n",
      "10  28.173  46.961  0.0   58.680  4984.103   53.696\n",
      "11  28.092  47.249  0.0   56.692  4991.304   51.700\n",
      "12  28.007  47.041  0.0   56.101  4994.724   51.107\n",
      "13  28.020  47.015  0.0   55.657  4996.433   50.661\n",
      "14  28.093  46.400  0.0   55.174  4997.432   50.176\n",
      "15  28.007  46.344  0.0   53.942  4998.355   48.944\n",
      "16  27.915  45.613  0.0   52.312  4998.969   47.313\n",
      "17  27.965  46.010  0.0   50.794  4999.349   45.795\n",
      "18  28.125  45.460  0.0   50.138  4999.835   45.138\n",
      "19  28.243  45.421  0.0   49.393  5000.180   44.393\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      acc     bmx  bmn     run\n",
      "0   20.77  29.891  0.0  16.371\n",
      "1   17.39  35.406  0.0  13.900\n",
      "2   28.97  36.093  0.0  12.667\n",
      "3   28.11  39.712  0.0  11.801\n",
      "4   26.95  41.360  0.0  11.461\n",
      "5   26.63  42.052  0.0  11.095\n",
      "6   27.63  42.727  0.0  10.908\n",
      "7   27.49  43.872  0.0  10.529\n",
      "8   27.24  44.788  0.0  10.133\n",
      "9   27.90  44.888  0.0   9.921\n",
      "10  27.63  45.900  0.0   9.695\n",
      "11  27.90  46.058  0.0   9.449\n",
      "12  27.61  46.509  0.0   9.386\n",
      "13  27.61  45.933  0.0   9.295\n",
      "14  27.49  45.784  0.0   9.247\n",
      "15  27.34  45.715  0.0   8.874\n",
      "16  27.65  45.036  0.0   8.576\n",
      "17  27.48  44.897  0.0   8.495\n",
      "18  27.37  44.735  0.0   8.337\n",
      "19  27.62  44.583  0.0   8.274\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
