{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:  1.1.0\n",
      "torch:  1.6.0\n",
      "numpy:  1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "import pandas as pd\n",
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"torch: \", torch.__version__)\n",
    "print(\"numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsubuntu_khs_dir = /home/wsubuntu/GitHub/keyhandshapediscovery\n",
      "wsubuntu_data_path = /media/wsubuntu/SSD_Data/DataPath\n",
      "wsubuntu_experiment_path = /media/wsubuntu/SSD_Data/vaesae_experiments\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "def get_var_by_comp_name(variableName):\n",
    "    curCompName = socket.gethostname()\n",
    "    retVal = None\n",
    "    if variableName == 'khs_dir':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/home/wsubuntu/GitHub/keyhandshapediscovery'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'data_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/Datasets'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/DataPath'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'experiment_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/SPARSE_TORCH'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/vaesae_experiments'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "        \n",
    "    print(curCompName + '_' + variableName, '=',  retVal)\n",
    "    if retVal is None:\n",
    "        os.error(5)\n",
    "    return retVal\n",
    "\n",
    "khs_dir = get_var_by_comp_name('khs_dir')\n",
    "data_path = get_var_by_comp_name('data_path')\n",
    "experiment_path = get_var_by_comp_name('experiment_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, khs_dir)\n",
    "import helperFuncs as funcH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 18\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'batchmean','sum'\n",
    "SIGMOID_ACT=False\n",
    "APPLY_LOG_SOFTMAX=True\n",
    "MSE_PLUS_MINUS='+'\n",
    "APPLY_SPARSITY_TO='bottleneck' #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 100  # args['epochs']\n",
    "reg_param = 0.1  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": data_path,\n",
    "    \"experiment\": os.path.join(experiment_path, 'sparse_torch_ae_' + str(EXPERIMENT_ID).zfill(3)),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseAutoencoder - loss_type(cre), device(cpu)\n"
     ]
    }
   ],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=32)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    "        print(\"SparseAutoencoder - loss_type(\" + loss_type +\"), device(\" + self.device + \")\")\n",
    "\n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        if self.loss_type=='cre':\n",
    "            bottleneck = self.enc5(x) \n",
    "        else:\n",
    "            bottleneck = F.relu(self.enc5(x))  \n",
    "        \n",
    "        return bottleneck\n",
    "        \n",
    "    def decode(self, bottleneck):\n",
    "        # decoding\n",
    "        if self.loss_type=='cre':\n",
    "            x = F.relu(self.dec1(F.relu(bottleneck)))\n",
    "        else:\n",
    "            x = F.relu(self.dec1(bottleneck))\n",
    "        \n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x)) \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encode(x)\n",
    "        x = self.decode(bottleneck)\n",
    "        return x, bottleneck\n",
    "\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    rho_val = 1/bt.size(1)\n",
    "    rho_mat = torch.tensor([rho_val] * np.ones(bt.size()), dtype=torch.float32).to(device)\n",
    "    #https://discuss.pytorch.org/t/kl-divergence-produces-negative-values/16791/13\n",
    "    #KLDLoss(p, q), sum(q) needs to equal one\n",
    "    #p = log_softmax(tensor)\n",
    "    loss_ret_1 = F.kl_div(F.log_softmax(bt, dim=1).to(device), rho_mat, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct and apply_log_softmax:  \n",
    "        if print_info:\n",
    "            print(\"1-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    elif sigmoidAct and not apply_log_softmax:     \n",
    "        if print_info:\n",
    "            print(\"2-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(bt.to(device), preds)    \n",
    "    elif not sigmoidAct and apply_log_softmax:\n",
    "        if print_info:\n",
    "            print(\"3-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bottleneck, dim=1).to(device), preds)    \n",
    "    else:#nothing\n",
    "        if print_info:\n",
    "            print(\"4-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(bottleneck.to(device), preds)\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy_old(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct:\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    else:\n",
    "        bt = bottleneck    \n",
    "    _, preds = torch.max(bt, 1)\n",
    "    loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss\n",
    "\n",
    "def sparse_loss_bottleneck(bottleneck, print_info, loss_type):\n",
    "    loss = 0\n",
    "    #if print_info:\n",
    "        #print(i, ' shape=', values.shape)\n",
    "    if loss_type=='l1':\n",
    "        loss += loss_l1(bottleneck)\n",
    "    if loss_type=='l2':\n",
    "        loss += loss_l2(bottleneck)\n",
    "    if loss_type=='kl':\n",
    "        loss += kl_divergence(bottleneck, reduction=LOSS_REDUCTION)\n",
    "    if loss_type=='cre':\n",
    "        loss += loss_crossentropy(bottleneck, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "    if print_info:\n",
    "        print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            if APPLY_SPARSITY_TO=='all':\n",
    "                sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            elif APPLY_SPARSITY_TO=='bottleneck': #all\n",
    "                sp_loss = sparse_loss_bottleneck(bottleneck, print_losses_fit, model.loss_type)\n",
    "            else:\n",
    "                os.exit(4)\n",
    "                \n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            \n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "                \n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_ws :: \n",
      "EXPERIMENT_ID:  18\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  False\n",
      "APPLY_LOG_SOFTMAX :  True\n",
      "APPLY_SPARSITY_TO :  bottleneck\n",
      "total loss = mse_loss + reg_param * sp_loss\n",
      "*****\n",
      " Epoch 0 of 100\n",
      "TrEpoch(000) - 3- False True\n",
      "cre tensor(3.2950, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.295018196105957\n",
      "\n",
      "       acc      bmx     bmn      mse      spr      run\n",
      "0  10.005  100.009 -60.976  182.259  217.349  203.994\n",
      "ValEpoch(000) - \n",
      "     acc     bmx   bmn    run\n",
      "0  10.0  103.97 -62.3  21.64\n",
      "*****\n",
      " Epoch 1 of 100\n",
      "TrEpoch(001) - \n",
      "     acc      bmx     bmn      mse    spr      run\n",
      "0  10.0  132.886 -76.681  117.083  0.116  117.095\n",
      "ValEpoch(001) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  132.245 -74.605  18.479\n",
      "*****\n",
      " Epoch 2 of 100\n",
      "TrEpoch(002) - \n",
      "     acc      bmx     bmn     mse    spr      run\n",
      "0  10.0  143.037 -79.792  106.95  0.041  106.954\n",
      "ValEpoch(002) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  139.06 -76.919  17.196\n",
      "*****\n",
      " Epoch 3 of 100\n",
      "TrEpoch(003) - \n",
      "     acc      bmx     bmn      mse    spr      run\n",
      "0  10.0  144.713 -79.848  101.059  0.023  101.061\n",
      "ValEpoch(003) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  141.051 -76.665  16.13\n",
      "*****\n",
      " Epoch 4 of 100\n",
      "TrEpoch(004) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  147.285 -79.494  89.131  0.017  89.133\n",
      "ValEpoch(004) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  144.681 -78.168  14.069\n",
      "*****\n",
      " Epoch 5 of 100\n",
      "TrEpoch(005) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  151.563 -80.684  80.804  0.012  80.805\n",
      "ValEpoch(005) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  145.334 -78.032  12.825\n",
      "*****\n",
      " Epoch 6 of 100\n",
      "TrEpoch(006) - 3- False True\n",
      "cre tensor(1.3634e-06, grad_fn=<AddBackward0>)\n",
      "sp_loss: 1.3634353308589198e-06\n",
      "\n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  150.276 -79.922  74.912  0.013  74.914\n",
      "ValEpoch(006) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  146.686 -78.387  12.068\n",
      "*****\n",
      " Epoch 7 of 100\n",
      "TrEpoch(007) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  153.385 -81.604  70.835  0.013  70.837\n",
      "ValEpoch(007) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  147.371 -79.443  11.648\n",
      "*****\n",
      " Epoch 8 of 100\n",
      "TrEpoch(008) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  152.377 -82.617  68.031  0.012  68.032\n",
      "ValEpoch(008) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  144.794 -79.976  11.132\n",
      "*****\n",
      " Epoch 9 of 100\n",
      "TrEpoch(009) - \n",
      "     acc      bmx     bmn     mse    spr    run\n",
      "0  10.0  148.817 -84.211  66.179  0.012  66.18\n",
      "ValEpoch(009) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  142.706 -82.436  10.964\n",
      "*****\n",
      " Epoch 10 of 100\n",
      "TrEpoch(010) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  146.988 -87.136  64.932  0.012  64.933\n",
      "ValEpoch(010) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  140.921 -85.105  10.763\n",
      "*****\n",
      " Epoch 11 of 100\n",
      "TrEpoch(011) - 3- False True\n",
      "cre tensor(7.4506e-09, grad_fn=<AddBackward0>)\n",
      "sp_loss: 7.4505797087454084e-09\n",
      "\n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  146.328 -90.378  63.204  0.012  63.206\n",
      "ValEpoch(011) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  140.723 -89.007  10.413\n",
      "*****\n",
      " Epoch 12 of 100\n",
      "TrEpoch(012) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  145.379 -94.164  60.896  0.012  60.897\n",
      "ValEpoch(012) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  138.62 -91.153  10.072\n",
      "*****\n",
      " Epoch 13 of 100\n",
      "TrEpoch(013) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  144.476 -96.563  59.684  0.012  59.685\n",
      "ValEpoch(013) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  138.583 -93.738  9.971\n",
      "*****\n",
      " Epoch 14 of 100\n",
      "TrEpoch(014) - \n",
      "     acc      bmx     bmn     mse    spr    run\n",
      "0  10.0  143.341 -97.272  58.639  0.012  58.64\n",
      "ValEpoch(014) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  137.196 -95.473  9.885\n",
      "*****\n",
      " Epoch 15 of 100\n",
      "TrEpoch(015) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  141.828 -100.577  57.077  0.012  57.078\n",
      "ValEpoch(015) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  133.963 -96.677  9.433\n",
      "*****\n",
      " Epoch 16 of 100\n",
      "TrEpoch(016) - 3- False True\n",
      "cre tensor(0., grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.0\n",
      "\n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  141.179 -104.435  55.284  0.013  55.285\n",
      "ValEpoch(016) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  133.904 -99.529  9.184\n",
      "*****\n",
      " Epoch 17 of 100\n",
      "TrEpoch(017) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  140.354 -104.369  54.362  0.013  54.364\n",
      "ValEpoch(017) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  134.511 -102.822  9.078\n",
      "*****\n",
      " Epoch 18 of 100\n",
      "TrEpoch(018) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  139.942 -108.288  53.811  0.012  53.812\n",
      "ValEpoch(018) - \n",
      "     acc     bmx      bmn    run\n",
      "0  10.0  134.07 -104.737  9.002\n",
      "*****\n",
      " Epoch 19 of 100\n",
      "TrEpoch(019) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  140.017 -109.992  53.337  0.012  53.339\n",
      "ValEpoch(019) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  133.225 -105.551  8.928\n",
      "*****\n",
      " Epoch 20 of 100\n",
      "TrEpoch(020) - \n",
      "     acc      bmx      bmn     mse    spr    run\n",
      "0  10.0  137.764 -110.277  52.949  0.012  52.95\n",
      "ValEpoch(020) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  131.949 -105.669  8.874\n",
      "*****\n",
      " Epoch 21 of 100\n",
      "TrEpoch(021) - 3- False True\n",
      "cre tensor(5.5134e-07, grad_fn=<AddBackward0>)\n",
      "sp_loss: 5.513380756383413e-07\n",
      "\n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  137.348 -110.443  52.375  0.012  52.376\n",
      "ValEpoch(021) - \n",
      "     acc      bmx     bmn   run\n",
      "0  10.0  131.286 -105.72  8.73\n",
      "*****\n",
      " Epoch 22 of 100\n",
      "TrEpoch(022) - \n",
      "     acc      bmx      bmn     mse    spr    run\n",
      "0  10.0  136.163 -110.441  51.338  0.013  51.34\n",
      "ValEpoch(022) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  131.965 -107.723  8.541\n",
      "*****\n",
      " Epoch 23 of 100\n",
      "TrEpoch(023) - \n",
      "     acc     bmx      bmn     mse    spr     run\n",
      "0  10.0  137.15 -110.805  50.753  0.013  50.755\n",
      "ValEpoch(023) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  130.609 -107.35  8.494\n",
      "*****\n",
      " Epoch 24 of 100\n",
      "TrEpoch(024) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  135.188 -109.597  50.483  0.013  50.484\n",
      "ValEpoch(024) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  128.261 -106.95  8.457\n",
      "*****\n",
      " Epoch 25 of 100\n",
      "TrEpoch(025) - \n",
      "     acc      bmx      bmn     mse    spr    run\n",
      "0  10.0  135.974 -110.351  50.229  0.012  50.23\n",
      "ValEpoch(025) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  128.864 -107.513  8.409\n",
      "*****\n",
      " Epoch 26 of 100\n",
      "TrEpoch(026) - 3- False True\n",
      "cre tensor(7.6147e-05, grad_fn=<AddBackward0>)\n",
      "sp_loss: 7.614692731294781e-05\n",
      "\n",
      "     acc     bmx      bmn     mse    spr     run\n",
      "0  10.0  134.46 -110.055  50.024  0.013  50.025\n",
      "ValEpoch(026) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  127.766 -107.56  8.369\n",
      "*****\n",
      " Epoch 27 of 100\n",
      "TrEpoch(027) - \n",
      "     acc      bmx      bmn     mse    spr    run\n",
      "0  10.0  133.139 -109.352  49.819  0.013  49.82\n",
      "ValEpoch(027) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  127.621 -107.876  8.372\n",
      "*****\n",
      " Epoch 28 of 100\n",
      "TrEpoch(028) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  130.544 -109.122  49.387  0.013  49.388\n",
      "ValEpoch(028) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  124.378 -106.476  8.197\n",
      "*****\n",
      " Epoch 29 of 100\n",
      "TrEpoch(029) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  130.862 -108.905  48.305  0.012  48.306\n",
      "ValEpoch(029) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  123.694 -106.045  8.018\n",
      "*****\n",
      " Epoch 30 of 100\n",
      "TrEpoch(030) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  128.448 -107.973  47.594  0.012  47.595\n",
      "ValEpoch(030) - \n",
      "     acc      bmx      bmn  run\n",
      "0  10.0  122.656 -106.103  8.0\n",
      "*****\n",
      " Epoch 31 of 100\n",
      "TrEpoch(031) - 3- False True\n",
      "cre tensor(2.0489e-07, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.0489031271608837e-07\n",
      "\n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  128.168 -107.752  47.354  0.012  47.355\n",
      "ValEpoch(031) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  121.868 -105.358  7.754\n",
      "*****\n",
      " Epoch 32 of 100\n",
      "TrEpoch(032) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  125.731 -107.331  46.133  0.011  46.134\n",
      "ValEpoch(032) - \n",
      "     acc      bmx      bmn   run\n",
      "0  10.0  120.776 -104.938  7.74\n",
      "*****\n",
      " Epoch 33 of 100\n",
      "TrEpoch(033) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  124.928 -107.093  45.952  0.011  45.953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValEpoch(033) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  120.203 -104.334  7.701\n",
      "*****\n",
      " Epoch 34 of 100\n",
      "TrEpoch(034) - \n",
      "     acc      bmx      bmn     mse    spr    run\n",
      "0  10.0  124.458 -106.502  45.779  0.011  45.78\n",
      "ValEpoch(034) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  119.673 -104.348  7.696\n",
      "*****\n",
      " Epoch 35 of 100\n",
      "TrEpoch(035) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  124.202 -106.453  45.352  0.011  45.353\n",
      "ValEpoch(035) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  117.942 -103.38  7.595\n",
      "*****\n",
      " Epoch 36 of 100\n",
      "TrEpoch(036) - 3- False True\n",
      "cre tensor(3.7253e-09, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.725290076417309e-09\n",
      "\n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  122.828 -105.503  45.148  0.011  45.149\n",
      "ValEpoch(036) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  117.507 -102.829  7.589\n",
      "*****\n",
      " Epoch 37 of 100\n",
      "TrEpoch(037) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  122.134 -104.45  44.978  0.011  44.979\n",
      "ValEpoch(037) - \n",
      "     acc     bmx      bmn    run\n",
      "0  10.0  116.39 -102.088  7.447\n",
      "*****\n",
      " Epoch 38 of 100\n",
      "TrEpoch(038) - \n",
      "     acc     bmx      bmn     mse    spr     run\n",
      "0  10.0  119.41 -103.032  44.267  0.011  44.268\n",
      "ValEpoch(038) - \n",
      "     acc     bmx      bmn    run\n",
      "0  10.0  115.38 -101.429  7.419\n",
      "*****\n",
      " Epoch 39 of 100\n",
      "TrEpoch(039) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  119.465 -103.807  44.131  0.011  44.132\n",
      "ValEpoch(039) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  114.885 -100.712  7.422\n",
      "*****\n",
      " Epoch 40 of 100\n",
      "TrEpoch(040) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  118.243 -102.577  44.025  0.011  44.026\n",
      "ValEpoch(040) - \n",
      "     acc      bmx    bmn    run\n",
      "0  10.0  113.129 -99.66  7.398\n",
      "*****\n",
      " Epoch 41 of 100\n",
      "TrEpoch(041) - 3- False True\n",
      "cre tensor(1.6354e-06, grad_fn=<AddBackward0>)\n",
      "sp_loss: 1.6353623095710645e-06\n",
      "\n",
      "     acc     bmx      bmn     mse    spr     run\n",
      "0  10.0  118.51 -102.128  43.878  0.011  43.879\n",
      "ValEpoch(041) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  112.808 -99.232  7.373\n",
      "*****\n",
      " Epoch 42 of 100\n",
      "TrEpoch(042) - \n",
      "     acc      bmx      bmn   mse    spr     run\n",
      "0  10.0  116.726 -101.516  43.8  0.011  43.801\n",
      "ValEpoch(042) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  112.197 -98.602  7.396\n",
      "*****\n",
      " Epoch 43 of 100\n",
      "TrEpoch(043) - \n",
      "     acc     bmx      bmn     mse    spr     run\n",
      "0  10.0  115.89 -100.495  43.155  0.012  43.156\n",
      "ValEpoch(043) - \n",
      "     acc      bmx     bmn   run\n",
      "0  10.0  110.749 -97.634  7.23\n",
      "*****\n",
      " Epoch 44 of 100\n",
      "TrEpoch(044) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  115.422 -98.951  42.902  0.012  42.903\n",
      "ValEpoch(044) - \n",
      "     acc      bmx    bmn   run\n",
      "0  10.0  110.227 -96.91  7.22\n",
      "*****\n",
      " Epoch 45 of 100\n",
      "TrEpoch(045) - \n",
      "     acc      bmx    bmn    mse    spr     run\n",
      "0  10.0  115.346 -98.69  42.81  0.012  42.812\n",
      "ValEpoch(045) - \n",
      "     acc      bmx    bmn  run\n",
      "0  10.0  109.686 -96.44  7.2\n",
      "*****\n",
      " Epoch 46 of 100\n",
      "TrEpoch(046) - 3- False True\n",
      "cre tensor(2.6077e-07, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.6076924086737563e-07\n",
      "\n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  113.689 -97.657  42.724  0.012  42.725\n",
      "ValEpoch(046) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  108.823 -95.415  7.193\n",
      "*****\n",
      " Epoch 47 of 100\n",
      "TrEpoch(047) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  112.525 -97.047  42.607  0.012  42.608\n",
      "ValEpoch(047) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  107.547 -94.518  7.167\n",
      "*****\n",
      " Epoch 48 of 100\n",
      "TrEpoch(048) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  112.028 -95.825  42.482  0.012  42.483\n",
      "ValEpoch(048) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  106.657 -93.415  7.049\n",
      "*****\n",
      " Epoch 49 of 100\n",
      "TrEpoch(049) - \n",
      "     acc      bmx     bmn     mse    spr    run\n",
      "0  10.0  110.124 -94.968  41.729  0.012  41.73\n",
      "ValEpoch(049) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  106.704 -93.459  7.024\n",
      "*****\n",
      " Epoch 50 of 100\n",
      "TrEpoch(050) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  110.261 -94.907  41.654  0.012  41.655\n",
      "ValEpoch(050) - \n",
      "     acc      bmx     bmn   run\n",
      "0  10.0  105.301 -92.111  7.03\n",
      "*****\n",
      " Epoch 51 of 100\n",
      "TrEpoch(051) - 3- False True\n",
      "cre tensor(9.6112e-07, grad_fn=<AddBackward0>)\n",
      "sp_loss: 9.611177347323974e-07\n",
      "\n",
      "     acc    bmx    bmn     mse    spr   run\n",
      "0  10.0  109.6 -93.94  41.499  0.012  41.5\n",
      "ValEpoch(051) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  104.926 -91.788  6.994\n",
      "*****\n",
      " Epoch 52 of 100\n",
      "TrEpoch(052) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  108.561 -93.242  41.336  0.012  41.337\n",
      "ValEpoch(052) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  104.383 -91.092  6.987\n",
      "*****\n",
      " Epoch 53 of 100\n",
      "TrEpoch(053) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  107.496 -92.392  41.274  0.012  41.275\n",
      "ValEpoch(053) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  104.056 -90.707  6.954\n",
      "*****\n",
      " Epoch 54 of 100\n",
      "TrEpoch(054) - \n",
      "     acc      bmx    bmn   mse    spr     run\n",
      "0  10.0  108.107 -92.49  41.2  0.012  41.202\n",
      "ValEpoch(054) - \n",
      "     acc      bmx    bmn    run\n",
      "0  10.0  102.698 -89.78  6.966\n",
      "*****\n",
      " Epoch 55 of 100\n",
      "TrEpoch(055) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  106.919 -91.697  41.127  0.012  41.128\n",
      "ValEpoch(055) - \n",
      "     acc    bmx     bmn    run\n",
      "0  10.0  102.3 -89.027  6.925\n",
      "*****\n",
      " Epoch 56 of 100\n",
      "TrEpoch(056) - 3- False True\n",
      "cre tensor(6.0303e-05, grad_fn=<AddBackward0>)\n",
      "sp_loss: 6.030268195900135e-05\n",
      "\n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  106.656 -90.703  41.062  0.012  41.063\n",
      "ValEpoch(056) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  102.074 -88.659  6.932\n",
      "*****\n",
      " Epoch 57 of 100\n",
      "TrEpoch(057) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  105.394 -90.069  41.006  0.013  41.008\n",
      "ValEpoch(057) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  101.448 -88.105  6.916\n",
      "*****\n",
      " Epoch 58 of 100\n",
      "TrEpoch(058) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  105.15 -90.178  40.948  0.012  40.949\n",
      "ValEpoch(058) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  99.947 -86.686  6.908\n",
      "*****\n",
      " Epoch 59 of 100\n",
      "TrEpoch(059) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  104.577 -88.912  40.886  0.013  40.887\n",
      "ValEpoch(059) - \n",
      "     acc     bmx     bmn   run\n",
      "0  10.0  99.536 -86.366  6.91\n",
      "*****\n",
      " Epoch 60 of 100\n",
      "TrEpoch(060) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  103.478 -88.289  40.833  0.014  40.834\n",
      "ValEpoch(060) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  99.729 -86.157  6.895\n",
      "*****\n",
      " Epoch 61 of 100\n",
      "TrEpoch(061) - 3- False True\n",
      "cre tensor(1.3039e-07, grad_fn=<AddBackward0>)\n",
      "sp_loss: 1.303850751810387e-07\n",
      "\n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  103.386 -87.901  40.772  0.013  40.774\n",
      "ValEpoch(061) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  98.868 -85.478  6.875\n",
      "*****\n",
      " Epoch 62 of 100\n",
      "TrEpoch(062) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  103.284 -87.152  40.729  0.014  40.731\n",
      "ValEpoch(062) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  98.013 -84.723  6.882\n",
      "*****\n",
      " Epoch 63 of 100\n",
      "TrEpoch(063) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  103.499 -86.341  40.674  0.013  40.676\n",
      "ValEpoch(063) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  97.942 -84.384  6.898\n",
      "*****\n",
      " Epoch 64 of 100\n",
      "TrEpoch(064) - \n",
      "     acc      bmx    bmn     mse    spr     run\n",
      "0  10.0  101.765 -86.06  40.618  0.013  40.619\n",
      "ValEpoch(064) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  97.997 -84.536  6.881\n",
      "*****\n",
      " Epoch 65 of 100\n",
      "TrEpoch(065) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  101.868 -85.849  40.567  0.013  40.568\n",
      "ValEpoch(065) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  96.746 -83.242  6.849\n",
      "*****\n",
      " Epoch 66 of 100\n",
      "TrEpoch(066) - 3- False True\n",
      "cre tensor(9.3132e-08, grad_fn=<AddBackward0>)\n",
      "sp_loss: 9.313218640727428e-08\n",
      "\n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  101.148 -85.963  40.516  0.014  40.518\n",
      "ValEpoch(066) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  96.994 -83.352  6.868\n",
      "*****\n",
      " Epoch 67 of 100\n",
      "TrEpoch(067) - \n",
      "     acc      bmx     bmn    mse    spr     run\n",
      "0  10.0  100.779 -84.988  40.42  0.014  40.421\n",
      "ValEpoch(067) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  96.274 -82.794  6.821\n",
      "*****\n",
      " Epoch 68 of 100\n",
      "TrEpoch(068) - \n",
      "     acc      bmx     bmn    mse    spr     run\n",
      "0  10.0  100.965 -84.469  40.18  0.014  40.182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValEpoch(068) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  95.938 -82.448  6.749\n",
      "*****\n",
      " Epoch 69 of 100\n",
      "TrEpoch(069) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  100.599 -84.963  39.847  0.014  39.849\n",
      "ValEpoch(069) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  94.898 -81.623  6.748\n",
      "*****\n",
      " Epoch 70 of 100\n",
      "TrEpoch(070) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  99.297 -84.186  39.791  0.014  39.792\n",
      "ValEpoch(070) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  95.483 -81.224  6.754\n",
      "*****\n",
      " Epoch 71 of 100\n",
      "TrEpoch(071) - 3- False True\n",
      "cre tensor(1.7509e-07, grad_fn=<AddBackward0>)\n",
      "sp_loss: 1.7508841665403452e-07\n",
      "\n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  100.201 -83.079  39.746  0.015  39.748\n",
      "ValEpoch(071) - \n",
      "     acc     bmx    bmn    run\n",
      "0  10.0  94.489 -80.63  6.708\n",
      "*****\n",
      " Epoch 72 of 100\n",
      "TrEpoch(072) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  99.034 -82.811  39.588  0.015  39.589\n",
      "ValEpoch(072) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  94.893 -80.722  6.696\n",
      "*****\n",
      " Epoch 73 of 100\n",
      "TrEpoch(073) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  98.856 -82.575  39.546  0.015  39.548\n",
      "ValEpoch(073) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  94.606 -80.233  6.698\n",
      "*****\n",
      " Epoch 74 of 100\n",
      "TrEpoch(074) - \n",
      "     acc     bmx     bmn     mse    spr    run\n",
      "0  10.0  98.724 -82.018  39.509  0.015  39.51\n",
      "ValEpoch(074) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  94.029 -79.625  6.714\n",
      "*****\n",
      " Epoch 75 of 100\n",
      "TrEpoch(075) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  98.415 -81.713  39.453  0.016  39.455\n",
      "ValEpoch(075) - \n",
      "     acc    bmx     bmn   run\n",
      "0  10.0  93.99 -79.547  6.69\n",
      "*****\n",
      " Epoch 76 of 100\n",
      "TrEpoch(076) - 3- False True\n",
      "cre tensor(2.5704e-07, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5704446215968346e-07\n",
      "\n",
      "     acc     bmx    bmn     mse    spr     run\n",
      "0  10.0  98.113 -81.57  39.424  0.015  39.425\n",
      "ValEpoch(076) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  93.596 -78.684  6.696\n",
      "*****\n",
      " Epoch 77 of 100\n",
      "TrEpoch(077) - \n",
      "     acc    bmx     bmn     mse    spr     run\n",
      "0  10.0  97.71 -81.067  39.369  0.016  39.371\n",
      "ValEpoch(077) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  92.948 -78.698  6.687\n",
      "*****\n",
      " Epoch 78 of 100\n",
      "TrEpoch(078) - \n",
      "     acc     bmx     bmn     mse    spr    run\n",
      "0  10.0  96.792 -80.817  39.338  0.016  39.34\n",
      "ValEpoch(078) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  93.336 -78.366  6.675\n",
      "*****\n",
      " Epoch 79 of 100\n",
      "TrEpoch(079) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  97.398 -80.322  39.303  0.016  39.305\n",
      "ValEpoch(079) - \n",
      "     acc     bmx    bmn    run\n",
      "0  10.0  92.817 -78.14  6.661\n",
      "*****\n",
      " Epoch 80 of 100\n",
      "TrEpoch(080) - \n",
      "     acc     bmx     bmn     mse    spr    run\n",
      "0  10.0  97.029 -80.179  39.258  0.016  39.26\n",
      "ValEpoch(080) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  92.429 -77.747  6.677\n",
      "*****\n",
      " Epoch 81 of 100\n",
      "TrEpoch(081) - 3- False True\n",
      "cre tensor(4.5448e-07, grad_fn=<AddBackward0>)\n",
      "sp_loss: 4.5448254581970104e-07\n",
      "\n",
      "     acc     bmx    bmn     mse    spr     run\n",
      "0  10.0  96.345 -80.02  39.224  0.016  39.225\n",
      "ValEpoch(081) - \n",
      "     acc     bmx     bmn   run\n",
      "0  10.0  91.762 -76.664  6.71\n",
      "*****\n",
      " Epoch 82 of 100\n",
      "TrEpoch(082) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  96.176 -79.843  39.198  0.017  39.199\n",
      "ValEpoch(082) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  92.188 -77.254  6.651\n",
      "*****\n",
      " Epoch 83 of 100\n",
      "TrEpoch(083) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  96.184 -79.461  39.156  0.017  39.157\n",
      "ValEpoch(083) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  91.509 -76.296  6.648\n",
      "*****\n",
      " Epoch 84 of 100\n",
      "TrEpoch(084) - \n",
      "     acc     bmx     bmn    mse    spr     run\n",
      "0  10.0  95.894 -78.694  39.11  0.017  39.112\n",
      "ValEpoch(084) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  91.129 -75.885  6.646\n",
      "*****\n",
      " Epoch 85 of 100\n",
      "TrEpoch(085) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  95.458 -78.026  39.084  0.017  39.086\n",
      "ValEpoch(085) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  91.304 -76.146  6.631\n",
      "*****\n",
      " Epoch 86 of 100\n",
      "TrEpoch(086) - 3- False True\n",
      "cre tensor(7.4506e-09, grad_fn=<AddBackward0>)\n",
      "sp_loss: 7.4505797087454084e-09\n",
      "\n",
      "     acc     bmx    bmn     mse    spr     run\n",
      "0  10.0  95.814 -78.33  39.047  0.017  39.049\n",
      "ValEpoch(086) - \n",
      "     acc     bmx    bmn    run\n",
      "0  10.0  90.537 -74.89  6.633\n",
      "*****\n",
      " Epoch 87 of 100\n",
      "TrEpoch(087) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  94.983 -78.031  39.007  0.018  39.009\n",
      "ValEpoch(087) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  91.341 -75.093  6.644\n",
      "*****\n",
      " Epoch 88 of 100\n",
      "TrEpoch(088) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  94.648 -77.433  38.983  0.018  38.984\n",
      "ValEpoch(088) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  90.415 -74.733  6.641\n",
      "*****\n",
      " Epoch 89 of 100\n",
      "TrEpoch(089) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  94.194 -76.592  38.941  0.018  38.943\n",
      "ValEpoch(089) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  90.358 -74.168  6.612\n",
      "*****\n",
      " Epoch 90 of 100\n",
      "TrEpoch(090) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  93.975 -76.913  38.917  0.018  38.918\n",
      "ValEpoch(090) - \n",
      "     acc     bmx    bmn    run\n",
      "0  10.0  90.729 -74.22  6.625\n",
      "*****\n",
      " Epoch 91 of 100\n",
      "TrEpoch(091) - 3- False True\n",
      "cre tensor(3.3528e-08, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.352759492258883e-08\n",
      "\n",
      "     acc    bmx    bmn     mse    spr     run\n",
      "0  10.0  93.35 -76.67  38.892  0.019  38.894\n",
      "ValEpoch(091) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  90.349 -74.047  6.609\n",
      "*****\n",
      " Epoch 92 of 100\n",
      "TrEpoch(092) - \n",
      "     acc     bmx    bmn     mse    spr     run\n",
      "0  10.0  93.794 -75.89  38.845  0.018  38.847\n",
      "ValEpoch(092) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  89.424 -73.748  6.607\n",
      "*****\n",
      " Epoch 93 of 100\n",
      "TrEpoch(093) - \n",
      "     acc     bmx    bmn    mse    spr     run\n",
      "0  10.0  94.234 -75.93  38.52  0.018  38.522\n",
      "ValEpoch(093) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  89.481 -73.074  6.489\n",
      "*****\n",
      " Epoch 94 of 100\n",
      "TrEpoch(094) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  93.346 -75.527  38.109  0.019  38.111\n",
      "ValEpoch(094) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  89.073 -72.662  6.492\n",
      "*****\n",
      " Epoch 95 of 100\n",
      "TrEpoch(095) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  93.457 -75.296  38.073  0.019  38.074\n",
      "ValEpoch(095) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  89.236 -72.701  6.479\n",
      "*****\n",
      " Epoch 96 of 100\n",
      "TrEpoch(096) - 3- False True\n",
      "cre tensor(6.8132e-06, grad_fn=<AddBackward0>)\n",
      "sp_loss: 6.813159416196868e-06\n",
      "\n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  92.441 -74.511  38.046  0.019  38.048\n",
      "ValEpoch(096) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  89.432 -72.506  6.489\n",
      "*****\n",
      " Epoch 97 of 100\n",
      "TrEpoch(097) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  92.792 -75.066  38.017  0.019  38.019\n",
      "ValEpoch(097) - \n",
      "     acc     bmx    bmn   run\n",
      "0  10.0  89.274 -72.42  6.48\n",
      "*****\n",
      " Epoch 98 of 100\n",
      "TrEpoch(098) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  92.765 -74.714  37.996  0.019  37.998\n",
      "ValEpoch(098) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  88.072 -71.234  6.492\n",
      "*****\n",
      " Epoch 99 of 100\n",
      "TrEpoch(099) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  93.334 -74.934  37.961  0.019  37.963\n",
      "ValEpoch(099) - \n",
      "     acc     bmx     bmn   run\n",
      "0  10.0  88.672 -71.677  6.47\n",
      "1.6e+02 minutes\n"
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_ws :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"APPLY_LOG_SOFTMAX : \", APPLY_LOG_SOFTMAX)\n",
    "print(\"APPLY_SPARSITY_TO : \", APPLY_SPARSITY_TO)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param * sp_loss\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       acc      bmx      bmn      mse      spr      run\n",
      "0   10.005  100.009  -60.976  182.259  217.349  203.994\n",
      "1   10.000  132.886  -76.681  117.083    0.116  117.095\n",
      "2   10.000  143.037  -79.792  106.950    0.041  106.954\n",
      "3   10.000  144.713  -79.848  101.059    0.023  101.061\n",
      "4   10.000  147.285  -79.494   89.131    0.017   89.133\n",
      "5   10.000  151.563  -80.684   80.804    0.012   80.805\n",
      "6   10.000  150.276  -79.922   74.912    0.013   74.914\n",
      "7   10.000  153.385  -81.604   70.835    0.013   70.837\n",
      "8   10.000  152.377  -82.617   68.031    0.012   68.032\n",
      "9   10.000  148.817  -84.211   66.179    0.012   66.180\n",
      "10  10.000  146.988  -87.136   64.932    0.012   64.933\n",
      "11  10.000  146.328  -90.378   63.204    0.012   63.206\n",
      "12  10.000  145.379  -94.164   60.896    0.012   60.897\n",
      "13  10.000  144.476  -96.563   59.684    0.012   59.685\n",
      "14  10.000  143.341  -97.272   58.639    0.012   58.640\n",
      "15  10.000  141.828 -100.577   57.077    0.012   57.078\n",
      "16  10.000  141.179 -104.435   55.284    0.013   55.285\n",
      "17  10.000  140.354 -104.369   54.362    0.013   54.364\n",
      "18  10.000  139.942 -108.288   53.811    0.012   53.812\n",
      "19  10.000  140.017 -109.992   53.337    0.012   53.339\n",
      "20  10.000  137.764 -110.277   52.949    0.012   52.950\n",
      "21  10.000  137.348 -110.443   52.375    0.012   52.376\n",
      "22  10.000  136.163 -110.441   51.338    0.013   51.340\n",
      "23  10.000  137.150 -110.805   50.753    0.013   50.755\n",
      "24  10.000  135.188 -109.597   50.483    0.013   50.484\n",
      "25  10.000  135.974 -110.351   50.229    0.012   50.230\n",
      "26  10.000  134.460 -110.055   50.024    0.013   50.025\n",
      "27  10.000  133.139 -109.352   49.819    0.013   49.820\n",
      "28  10.000  130.544 -109.122   49.387    0.013   49.388\n",
      "29  10.000  130.862 -108.905   48.305    0.012   48.306\n",
      "30  10.000  128.448 -107.973   47.594    0.012   47.595\n",
      "31  10.000  128.168 -107.752   47.354    0.012   47.355\n",
      "32  10.000  125.731 -107.331   46.133    0.011   46.134\n",
      "33  10.000  124.928 -107.093   45.952    0.011   45.953\n",
      "34  10.000  124.458 -106.502   45.779    0.011   45.780\n",
      "35  10.000  124.202 -106.453   45.352    0.011   45.353\n",
      "36  10.000  122.828 -105.503   45.148    0.011   45.149\n",
      "37  10.000  122.134 -104.450   44.978    0.011   44.979\n",
      "38  10.000  119.410 -103.032   44.267    0.011   44.268\n",
      "39  10.000  119.465 -103.807   44.131    0.011   44.132\n",
      "40  10.000  118.243 -102.577   44.025    0.011   44.026\n",
      "41  10.000  118.510 -102.128   43.878    0.011   43.879\n",
      "42  10.000  116.726 -101.516   43.800    0.011   43.801\n",
      "43  10.000  115.890 -100.495   43.155    0.012   43.156\n",
      "44  10.000  115.422  -98.951   42.902    0.012   42.903\n",
      "45  10.000  115.346  -98.690   42.810    0.012   42.812\n",
      "46  10.000  113.689  -97.657   42.724    0.012   42.725\n",
      "47  10.000  112.525  -97.047   42.607    0.012   42.608\n",
      "48  10.000  112.028  -95.825   42.482    0.012   42.483\n",
      "49  10.000  110.124  -94.968   41.729    0.012   41.730\n",
      "50  10.000  110.261  -94.907   41.654    0.012   41.655\n",
      "51  10.000  109.600  -93.940   41.499    0.012   41.500\n",
      "52  10.000  108.561  -93.242   41.336    0.012   41.337\n",
      "53  10.000  107.496  -92.392   41.274    0.012   41.275\n",
      "54  10.000  108.107  -92.490   41.200    0.012   41.202\n",
      "55  10.000  106.919  -91.697   41.127    0.012   41.128\n",
      "56  10.000  106.656  -90.703   41.062    0.012   41.063\n",
      "57  10.000  105.394  -90.069   41.006    0.013   41.008\n",
      "58  10.000  105.150  -90.178   40.948    0.012   40.949\n",
      "59  10.000  104.577  -88.912   40.886    0.013   40.887\n",
      "60  10.000  103.478  -88.289   40.833    0.014   40.834\n",
      "61  10.000  103.386  -87.901   40.772    0.013   40.774\n",
      "62  10.000  103.284  -87.152   40.729    0.014   40.731\n",
      "63  10.000  103.499  -86.341   40.674    0.013   40.676\n",
      "64  10.000  101.765  -86.060   40.618    0.013   40.619\n",
      "65  10.000  101.868  -85.849   40.567    0.013   40.568\n",
      "66  10.000  101.148  -85.963   40.516    0.014   40.518\n",
      "67  10.000  100.779  -84.988   40.420    0.014   40.421\n",
      "68  10.000  100.965  -84.469   40.180    0.014   40.182\n",
      "69  10.000  100.599  -84.963   39.847    0.014   39.849\n",
      "70  10.000   99.297  -84.186   39.791    0.014   39.792\n",
      "71  10.000  100.201  -83.079   39.746    0.015   39.748\n",
      "72  10.000   99.034  -82.811   39.588    0.015   39.589\n",
      "73  10.000   98.856  -82.575   39.546    0.015   39.548\n",
      "74  10.000   98.724  -82.018   39.509    0.015   39.510\n",
      "75  10.000   98.415  -81.713   39.453    0.016   39.455\n",
      "76  10.000   98.113  -81.570   39.424    0.015   39.425\n",
      "77  10.000   97.710  -81.067   39.369    0.016   39.371\n",
      "78  10.000   96.792  -80.817   39.338    0.016   39.340\n",
      "79  10.000   97.398  -80.322   39.303    0.016   39.305\n",
      "80  10.000   97.029  -80.179   39.258    0.016   39.260\n",
      "81  10.000   96.345  -80.020   39.224    0.016   39.225\n",
      "82  10.000   96.176  -79.843   39.198    0.017   39.199\n",
      "83  10.000   96.184  -79.461   39.156    0.017   39.157\n",
      "84  10.000   95.894  -78.694   39.110    0.017   39.112\n",
      "85  10.000   95.458  -78.026   39.084    0.017   39.086\n",
      "86  10.000   95.814  -78.330   39.047    0.017   39.049\n",
      "87  10.000   94.983  -78.031   39.007    0.018   39.009\n",
      "88  10.000   94.648  -77.433   38.983    0.018   38.984\n",
      "89  10.000   94.194  -76.592   38.941    0.018   38.943\n",
      "90  10.000   93.975  -76.913   38.917    0.018   38.918\n",
      "91  10.000   93.350  -76.670   38.892    0.019   38.894\n",
      "92  10.000   93.794  -75.890   38.845    0.018   38.847\n",
      "93  10.000   94.234  -75.930   38.520    0.018   38.522\n",
      "94  10.000   93.346  -75.527   38.109    0.019   38.111\n",
      "95  10.000   93.457  -75.296   38.073    0.019   38.074\n",
      "96  10.000   92.441  -74.511   38.046    0.019   38.048\n",
      "97  10.000   92.792  -75.066   38.017    0.019   38.019\n",
      "98  10.000   92.765  -74.714   37.996    0.019   37.998\n",
      "99  10.000   93.334  -74.934   37.961    0.019   37.963\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc      bmx      bmn     run\n",
      "0   10.0  103.970  -62.300  21.640\n",
      "1   10.0  132.245  -74.605  18.479\n",
      "2   10.0  139.060  -76.919  17.196\n",
      "3   10.0  141.051  -76.665  16.130\n",
      "4   10.0  144.681  -78.168  14.069\n",
      "5   10.0  145.334  -78.032  12.825\n",
      "6   10.0  146.686  -78.387  12.068\n",
      "7   10.0  147.371  -79.443  11.648\n",
      "8   10.0  144.794  -79.976  11.132\n",
      "9   10.0  142.706  -82.436  10.964\n",
      "10  10.0  140.921  -85.105  10.763\n",
      "11  10.0  140.723  -89.007  10.413\n",
      "12  10.0  138.620  -91.153  10.072\n",
      "13  10.0  138.583  -93.738   9.971\n",
      "14  10.0  137.196  -95.473   9.885\n",
      "15  10.0  133.963  -96.677   9.433\n",
      "16  10.0  133.904  -99.529   9.184\n",
      "17  10.0  134.511 -102.822   9.078\n",
      "18  10.0  134.070 -104.737   9.002\n",
      "19  10.0  133.225 -105.551   8.928\n",
      "20  10.0  131.949 -105.669   8.874\n",
      "21  10.0  131.286 -105.720   8.730\n",
      "22  10.0  131.965 -107.723   8.541\n",
      "23  10.0  130.609 -107.350   8.494\n",
      "24  10.0  128.261 -106.950   8.457\n",
      "25  10.0  128.864 -107.513   8.409\n",
      "26  10.0  127.766 -107.560   8.369\n",
      "27  10.0  127.621 -107.876   8.372\n",
      "28  10.0  124.378 -106.476   8.197\n",
      "29  10.0  123.694 -106.045   8.018\n",
      "30  10.0  122.656 -106.103   8.000\n",
      "31  10.0  121.868 -105.358   7.754\n",
      "32  10.0  120.776 -104.938   7.740\n",
      "33  10.0  120.203 -104.334   7.701\n",
      "34  10.0  119.673 -104.348   7.696\n",
      "35  10.0  117.942 -103.380   7.595\n",
      "36  10.0  117.507 -102.829   7.589\n",
      "37  10.0  116.390 -102.088   7.447\n",
      "38  10.0  115.380 -101.429   7.419\n",
      "39  10.0  114.885 -100.712   7.422\n",
      "40  10.0  113.129  -99.660   7.398\n",
      "41  10.0  112.808  -99.232   7.373\n",
      "42  10.0  112.197  -98.602   7.396\n",
      "43  10.0  110.749  -97.634   7.230\n",
      "44  10.0  110.227  -96.910   7.220\n",
      "45  10.0  109.686  -96.440   7.200\n",
      "46  10.0  108.823  -95.415   7.193\n",
      "47  10.0  107.547  -94.518   7.167\n",
      "48  10.0  106.657  -93.415   7.049\n",
      "49  10.0  106.704  -93.459   7.024\n",
      "50  10.0  105.301  -92.111   7.030\n",
      "51  10.0  104.926  -91.788   6.994\n",
      "52  10.0  104.383  -91.092   6.987\n",
      "53  10.0  104.056  -90.707   6.954\n",
      "54  10.0  102.698  -89.780   6.966\n",
      "55  10.0  102.300  -89.027   6.925\n",
      "56  10.0  102.074  -88.659   6.932\n",
      "57  10.0  101.448  -88.105   6.916\n",
      "58  10.0   99.947  -86.686   6.908\n",
      "59  10.0   99.536  -86.366   6.910\n",
      "60  10.0   99.729  -86.157   6.895\n",
      "61  10.0   98.868  -85.478   6.875\n",
      "62  10.0   98.013  -84.723   6.882\n",
      "63  10.0   97.942  -84.384   6.898\n",
      "64  10.0   97.997  -84.536   6.881\n",
      "65  10.0   96.746  -83.242   6.849\n",
      "66  10.0   96.994  -83.352   6.868\n",
      "67  10.0   96.274  -82.794   6.821\n",
      "68  10.0   95.938  -82.448   6.749\n",
      "69  10.0   94.898  -81.623   6.748\n",
      "70  10.0   95.483  -81.224   6.754\n",
      "71  10.0   94.489  -80.630   6.708\n",
      "72  10.0   94.893  -80.722   6.696\n",
      "73  10.0   94.606  -80.233   6.698\n",
      "74  10.0   94.029  -79.625   6.714\n",
      "75  10.0   93.990  -79.547   6.690\n",
      "76  10.0   93.596  -78.684   6.696\n",
      "77  10.0   92.948  -78.698   6.687\n",
      "78  10.0   93.336  -78.366   6.675\n",
      "79  10.0   92.817  -78.140   6.661\n",
      "80  10.0   92.429  -77.747   6.677\n",
      "81  10.0   91.762  -76.664   6.710\n",
      "82  10.0   92.188  -77.254   6.651\n",
      "83  10.0   91.509  -76.296   6.648\n",
      "84  10.0   91.129  -75.885   6.646\n",
      "85  10.0   91.304  -76.146   6.631\n",
      "86  10.0   90.537  -74.890   6.633\n",
      "87  10.0   91.341  -75.093   6.644\n",
      "88  10.0   90.415  -74.733   6.641\n",
      "89  10.0   90.358  -74.168   6.612\n",
      "90  10.0   90.729  -74.220   6.625\n",
      "91  10.0   90.349  -74.047   6.609\n",
      "92  10.0   89.424  -73.748   6.607\n",
      "93  10.0   89.481  -73.074   6.489\n",
      "94  10.0   89.073  -72.662   6.492\n",
      "95  10.0   89.236  -72.701   6.479\n",
      "96  10.0   89.432  -72.506   6.489\n",
      "97  10.0   89.274  -72.420   6.480\n",
      "98  10.0   88.072  -71.234   6.492\n",
      "99  10.0   88.672  -71.677   6.470\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tr acc =  10.005\n",
      "Max va acc =  10.0\n"
     ]
    }
   ],
   "source": [
    "tr_acc = result_df_tr_all.values[:,0].squeeze()\n",
    "va_acc = result_df_va_all.values[:,0].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_acc, color='orange', label='train acc')\n",
    "plt.plot(va_acc, color='red', label='validataion acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Max tr acc = \", np.max(tr_acc))\n",
    "print(\"Max va acc = \", np.max(va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_mse = result_df_tr_all.values[:,3].squeeze()\n",
    "tr_spr_50 = 100*result_df_tr_all.values[:,4].squeeze()\n",
    "va_err = 5*result_df_va_all.values[:,-1].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_mse, color='orange', label='train mse')\n",
    "plt.plot(tr_spr_50, color='red', label='tr spr*100')\n",
    "plt.plot(va_err, color='blue', label='va_err*5')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
