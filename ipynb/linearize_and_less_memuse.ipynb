{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import importlib as impL\n",
    "import numpy as np\n",
    "from pandas import DataFrame as pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_dir(x):\n",
    "    return os.path.dirname(x)\n",
    "get_parent_dir(sys.path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1,os.path.join(get_parent_dir(sys.path[0]),'vae_torch'))\n",
    "sys.path.insert(1,get_parent_dir(sys.path[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vae_torch_model as vtm\n",
    "import helperFuncs as funcH\n",
    "desktop_dir = funcH.getVariableByComputerName('desktop_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_saved_corr_file(fn = '/home/doga/Desktop/correspondance_find.npz'):\n",
    "    a = np.load(fn)\n",
    "    predictions = a['predictions']\n",
    "    bottleneck_vec = a['bottleneck_vec']\n",
    "    labels = a['labels']\n",
    "    print(\"loaded from file - \", fn)\n",
    "    print(predictions.shape)\n",
    "    print(bottleneck_vec.shape)\n",
    "    print(labels.shape)\n",
    "    return bottleneck_vec, predictions, labels\n",
    "\n",
    "def analyze_corresondance_results(correspondance_tuple, centroid_df, pred_vec, lab_vec):\n",
    "    df = pd_df({'labels': lab_vec[np.asarray(centroid_df['sampleID'], dtype=int)],\n",
    "                'klusterID': np.asarray(centroid_df['klusterID'], dtype=int),\n",
    "                'sampleCounts': np.asarray(centroid_df['num_of_samples'], dtype=int)})\n",
    "    print('correspondance results({:}):'.format(len(correspondance_tuple[0])))\n",
    "    print(df.groupby(['labels'])[['labels', 'sampleCounts']].sum())\n",
    "    corr_in_clust = pred_vec[correspondance_tuple[0]]\n",
    "    corr_ou_clust = pred_vec[correspondance_tuple[1]]\n",
    "    _confMat_corr_preds = confusion_matrix(corr_in_clust, corr_ou_clust)\n",
    "    acc_corr_preds = 100 * np.sum(np.diag(_confMat_corr_preds)) / np.sum(\n",
    "        np.sum(_confMat_corr_preds))\n",
    "    print(\"_confMat_corr_preds - acc({:6.4f})\".format(acc_corr_preds))\n",
    "\n",
    "    corr_in_labels = lab_vec[correspondance_tuple[0]]\n",
    "    corr_ou_labels = lab_vec[correspondance_tuple[1]]\n",
    "    _confMat_corr = confusion_matrix(corr_in_labels, corr_ou_labels)\n",
    "    acc_corr = 100 * np.sum(np.diag(_confMat_corr)) / np.sum(np.sum(_confMat_corr))\n",
    "    print(\"confMat - acc({:6.4f}), correspondance match:\\n\".format(acc_corr), pd_df(_confMat_corr))\n",
    "\n",
    "b_v = np.random.rand(10,3)\n",
    "#print(b_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez('/home/doga/Desktop/correspondance_find.npz', bottleneck_vec=bottleneck_vec, predictions=pred_vec, labels=lab_vec)\n",
    "bottleneck_vec, pred_vec, lab_vec = load_from_saved_corr_file(os.path.join(desktop_dir, 'correspondance_find_epoch1009_conf516.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impL.reload(funcH)\n",
    "def get_cluster_correspondance_ids_jupy(X, cluster_ids, correspondance_type=\"shuffle\", verbose=0):\n",
    "    # uses X to find the center sample\n",
    "    # returns inds_in, inds_out where:\n",
    "    # if correspondance_type=='shuffle'\n",
    "    # inds_in : shuffled indices of a cluster\n",
    "    # inds_out: shuffled indices of a cluster\n",
    "    # elseif correspondance_type=='centered'\n",
    "    # inds_in : some_sample_id\n",
    "    # inds_out: the center of cluster of that sample_id\n",
    "    centroid_df = funcH.get_cluster_centroids(ft=X, predClusters=cluster_ids, verbose=0)\n",
    "    uq_pr = np.unique(cluster_ids)\n",
    "    inds_in = []\n",
    "    inds_out = []\n",
    "    num_of_samples = []\n",
    "    for i in range(len(uq_pr)):\n",
    "        cluster_id = uq_pr[i]\n",
    "        cluster_inds = funcH.getInds(cluster_ids, i)\n",
    "        num_of_samples.append(len(cluster_inds))\n",
    "        if correspondance_type == 'shuffle':\n",
    "            iin_cur = cluster_inds.copy()\n",
    "            np.random.shuffle(iin_cur)\n",
    "            out_cur = cluster_inds.copy()\n",
    "            np.random.shuffle(out_cur)\n",
    "        elif 'knear' in correspondance_type:\n",
    "            if verbose > 0:\n",
    "                print(\"\\n***\\nknear-row{:}\\n\".format(i), cluster_inds)\n",
    "            k = int(correspondance_type.replace('knear', ''))\n",
    "            # look at the closest k samples for each sample\n",
    "            X_sub = X[cluster_inds, :]\n",
    "            k = np.minimum(len(cluster_inds), k)\n",
    "            d_inds, d_vals = funcH.get_dist_inds(X_sub, k=k, metric=\"euclidean\", verbose=0)\n",
    "            # d_inds are from 0 to len(cluster_inds)\n",
    "            # we want to switcth them with real cluster_inds\n",
    "            if verbose > 2:\n",
    "                print(\"cluster_inds:\\n\", cluster_inds)\n",
    "                print(\"d_inds in:\", d_inds)\n",
    "            # d_inds.shape = [len(cluster_inds), k]\n",
    "            # each row represents a sample and all columns represent its nearest neighbours\n",
    "            # so i need to have each corr and k neighbours as correspondant frames\n",
    "            sidx = np.array([cluster_inds, ] * k).T.flatten()\n",
    "            if verbose > 1:\n",
    "                print(\"i = \", i)\n",
    "                print(\"sidx = \\n\", sidx)\n",
    "            d_inds = cluster_inds[d_inds.flatten()]\n",
    "            if verbose > 1:\n",
    "                print(\"d_inds = \\n\", d_inds)\n",
    "            iin_cur = sidx.copy()\n",
    "            out_cur = d_inds.copy()\n",
    "        else:\n",
    "            center_sample_inds = centroid_df['sampleID'].iloc[i]\n",
    "            if verbose > 0:\n",
    "                print(\"cluster_id({:-3d}), sampleCount({:-4d}), centerSampleId({:-5d})\".format(int(cluster_id),\n",
    "                                                                                               len(cluster_inds),\n",
    "                                                                                               center_sample_inds))\n",
    "            # inds_in <--all sampleids except cluster center\n",
    "            # inds_out<--cluster sample id with length of inds_in\n",
    "            iin_cur = np.asarray(cluster_inds[np.where(center_sample_inds != cluster_inds)], dtype=int).squeeze()\n",
    "            out_cur = np.asarray(np.ones(iin_cur.shape) * center_sample_inds, dtype=int)\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(\"iin_cur.shape{:}, out_cur.shape{:}\".format(iin_cur.shape, out_cur.shape))\n",
    "            #if i == 0:\n",
    "            print(\"iin=\", iin_cur)\n",
    "            print(\"out=\", out_cur)\n",
    "        inds_in.append(iin_cur)\n",
    "        inds_out.append(out_cur)\n",
    "\n",
    "    # first concatanate the lists into ndarray\n",
    "    inds_in = np.asarray(np.concatenate(inds_in), dtype=int)\n",
    "    inds_out = np.asarray(np.concatenate(inds_out), dtype=int)\n",
    "\n",
    "    if True:  # 'knear' not in correspondance_type:\n",
    "        # now a-b and b-a\n",
    "        ii_ret = np.asarray(np.concatenate([inds_in, inds_out]), dtype=int)\n",
    "        io_ret = np.asarray(np.concatenate([inds_out, inds_in]), dtype=int)\n",
    "    else:\n",
    "        ii_ret = inds_in.copy()\n",
    "        io_ret = inds_out.copy()\n",
    "\n",
    "    # now shuffle so that clusters not sorted in learning\n",
    "    print(\"shuffle all\")\n",
    "    p = np.random.permutation(len(ii_ret))\n",
    "    ii_ret = ii_ret[p]\n",
    "    io_ret = io_ret[p]\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(\"inds_in.shape{:}, inds_out.shape{:}\".format(inds_in.shape, inds_out.shape))\n",
    "    centroid_df['num_of_samples'] = num_of_samples\n",
    "    return (ii_ret, io_ret), centroid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correspondance_type = 'knear1'\n",
    "impL.reload(funcH)\n",
    "cluster_ids=np.asarray([0,0,0,0,1,1,2,2,1,1], dtype=int)\n",
    "classss_ids=np.asarray([1,1,1,1,2,2,2,2,3,3], dtype=int)\n",
    "corr_inds, centroid_df = funcH.get_cluster_correspondance_ids(b_v, cluster_ids=cluster_ids, correspondance_type=\"knear1\", verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "analyze_corresondance_results(corr_inds, centroid_df, cluster_ids, classss_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impL.reload(funcH)\n",
    "D, sort_inds = funcH.create_dist_mat(x=b_v, metric=\"euclidean\", verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sort_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [np.nan, 0.67650314, 0.42890377, 0.92405289, 0.43106637, 0.58283084, 0.38471857, 0.35347397, 0.56549665, 0.76402288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argsort(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sort_inds[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_X_all = \n",
      " [[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]]\n",
      "_Y_id_i = \n",
      " [[0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]\n",
      " [0 1 2 3 4]]\n",
      "_Y_id_j = \n",
      " [[0 0 0 0 0]\n",
      " [1 1 1 1 1]\n",
      " [2 2 2 2 2]\n",
      " [3 3 3 3 3]\n",
      " [4 4 4 4 4]]\n",
      "_X_udi = \n",
      " [[ 0  1  2  3  4]\n",
      " [ 0  0  7  8  9]\n",
      " [ 0  0  0 13 14]\n",
      " [ 0  0  0  0 19]\n",
      " [ 0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "_X_all = np.reshape(np.arange(25), (5,5))\n",
    "print(\"_X_all = \\n\", _X_all)\n",
    "_Y_id_i = np.asarray(([np.arange(5),]*5),dtype=int)\n",
    "print(\"_Y_id_i = \\n\", _Y_id_i)\n",
    "_Y_id_j = np.asarray(([np.arange(5),]*5),dtype=int).T\n",
    "print(\"_Y_id_j = \\n\", _Y_id_j)\n",
    "_X_udi = np.triu(_X_all, 1)\n",
    "print(\"_X_udi = \\n\", _X_udi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      " [ 1  2  3  4  7  8  9 13 14 19]\n",
      "in = \n",
      " [0 0 0 0 1 1 1 2 2 3]\n",
      "out = \n",
      " [1 2 3 4 2 3 4 3 4 4]\n",
      "_X_ = \n",
      " [ 1  2  3  4  7  8  9 13 14 19]\n"
     ]
    }
   ],
   "source": [
    "idx_in = _Y_id_j[np.triu_indices(5, k = 1)]\n",
    "idx_ou = _Y_id_i[np.triu_indices(5, k = 1)]\n",
    "print(\"X = \\n\", _X_all[np.triu_indices(5, k = 1)])\n",
    "print(\"in = \\n\", idx_in)\n",
    "print(\"out = \\n\", idx_ou)\n",
    "print(\"_X_ = \\n\", _X_all[idx_in,idx_ou])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impL.reload(funcH)\n",
    "_ = funcH.get_linearized_distance_matrix(_X_all,verbose=1, sort_dist=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = funcH.get_linearized_distance_matrix(_X_all,verbose=1, sort_dist=\"ascend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = funcH.get_linearized_distance_matrix(_X_all,verbose=1, sort_dist=\"descend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(5*4/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = funcH.get_linearized_distance_matrix(D,verbose=1, sort_dist=\"ascend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 2, 3, 4, 3, 4, 4])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.triu_indices(5, k = 1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0,0,0,1,1,1,2,2,3,"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for j in range(5-i-1):\n",
    "        print(i,end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for j in range(5-i-1) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 2, 2, 3], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray([i for i in range(n) for j in range(n-i-1)], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 2, 3, 4, 3, 4, 4], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray([i+j+1 for i in range(n) for j in range(n-i-1)], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "khs_ws5",
   "language": "python",
   "name": "khs_ws5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
