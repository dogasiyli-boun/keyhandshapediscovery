{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "sys.path.insert(1,'/home/wsubuntu/GitHub/keyhandshapediscovery')\n",
    "import helperFuncs as funcH\n",
    "import pandas as pd\n",
    "\n",
    "EXPERIMENT_ID = 3\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'sum','batchmean'\n",
    "SIGMOID_ACT=True\n",
    "MSE_PLUS_MINUS='-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 20  # args['epochs']\n",
    "reg_param = 0.001  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": '/media/wsubuntu/SSD_Data/DataPath',\n",
    "    \"experiment\": '/media/wsubuntu/SSD_Data/vaesae_experiments/sparse_torch_ae_ws_' + str(EXPERIMENT_ID).zfill(3),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=16)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=16, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    " \n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        bottleneck = F.relu(self.enc5(x))\n",
    "\n",
    "        # decoding\n",
    "        x = F.relu(self.dec1(bottleneck))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x))\n",
    "        return x, bottleneck\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=16, bias=True)\n",
      "Linear(in_features=16, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    rho = 0.05\n",
    "    bottleneck = torch.mean(torch.sigmoid(bottleneck), 1)  # sigmoid because we need the probability distributions\n",
    "    rho = torch.tensor([rho] * len(bottleneck)).to(device)\n",
    "    loss_ret_1 = torch.nn.functional.kl_div(bottleneck, rho, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct:\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    _, preds = torch.max(bt, 1)\n",
    "    loss_ret_1 = loss_fun(bt, preds)    \n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_ws05 :: \n",
      "EXPERIMENT_ID:  3\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  True\n",
      "total loss = mse_loss - reg_param * sp_loss\n",
      "*****\n",
      " Epoch 0 of 20\n",
      "TrEpoch(000) - cre tensor(5.4022, grad_fn=<AddBackward0>)\n",
      "cre tensor(10.2022, grad_fn=<AddBackward0>)\n",
      "cre tensor(14.3359, grad_fn=<AddBackward0>)\n",
      "cre tensor(17.7792, grad_fn=<AddBackward0>)\n",
      "cre tensor(20.5297, grad_fn=<AddBackward0>)\n",
      "cre tensor(23.9538, grad_fn=<AddBackward0>)\n",
      "cre tensor(28.0692, grad_fn=<AddBackward0>)\n",
      "cre tensor(32.8857, grad_fn=<AddBackward0>)\n",
      "cre tensor(38.4041, grad_fn=<AddBackward0>)\n",
      "cre tensor(45.0458, grad_fn=<AddBackward0>)\n",
      "sp_loss: 45.04578399658203\n",
      "\n",
      "       acc    bmx  bmn      mse       spr      run\n",
      "0  20.815  3.753  0.0  187.774  83445.35  104.329\n",
      "ValEpoch(000) - \n",
      "      acc    bmx  bmn     run\n",
      "0  29.86  3.825  0.0  21.781\n",
      "*****\n",
      " Epoch 1 of 20\n",
      "TrEpoch(001) - \n",
      "      acc    bmx  bmn      mse        spr     run\n",
      "0  22.98  4.146  0.0  122.562  82683.105  39.879\n",
      "ValEpoch(001) - \n",
      "      acc    bmx  bmn     run\n",
      "0  24.88  3.816  0.0  19.384\n",
      "*****\n",
      " Epoch 2 of 20\n",
      "TrEpoch(002) - \n",
      "       acc    bmx  bmn      mse        spr     run\n",
      "0  22.478  3.958  0.0  112.477  82830.491  29.646\n",
      "ValEpoch(002) - \n",
      "     acc    bmx  bmn     run\n",
      "0  33.4  3.684  0.0  18.265\n",
      "*****\n",
      " Epoch 3 of 20\n",
      "TrEpoch(003) - \n",
      "       acc    bmx  bmn      mse        spr     run\n",
      "0  31.328  4.178  0.0  100.246  82757.332  17.488\n",
      "ValEpoch(003) - \n",
      "      acc    bmx  bmn    run\n",
      "0  25.62  3.948  0.0  15.29\n",
      "*****\n",
      " Epoch 4 of 20\n",
      "TrEpoch(004) - \n",
      "       acc    bmx  bmn     mse        spr    run\n",
      "0  28.988  4.176  0.0  87.724  82637.369  5.087\n",
      "ValEpoch(004) - \n",
      "      acc    bmx  bmn     run\n",
      "0  26.28  4.187  0.0  13.919\n",
      "*****\n",
      " Epoch 5 of 20\n",
      "TrEpoch(005) - \n",
      "       acc    bmx  bmn     mse        spr    run\n",
      "0  34.077  4.322  0.0  82.271  82670.433 -0.399\n",
      "ValEpoch(005) - \n",
      "      acc  bmx  bmn     run\n",
      "0  30.02  3.8  0.0  13.598\n",
      "*****\n",
      " Epoch 6 of 20\n",
      "TrEpoch(006) - cre tensor(5.3684, grad_fn=<AddBackward0>)\n",
      "cre tensor(10.1390, grad_fn=<AddBackward0>)\n",
      "cre tensor(14.1827, grad_fn=<AddBackward0>)\n",
      "cre tensor(17.5410, grad_fn=<AddBackward0>)\n",
      "cre tensor(20.1709, grad_fn=<AddBackward0>)\n",
      "cre tensor(23.4915, grad_fn=<AddBackward0>)\n",
      "cre tensor(27.5476, grad_fn=<AddBackward0>)\n",
      "cre tensor(32.2592, grad_fn=<AddBackward0>)\n",
      "cre tensor(37.5905, grad_fn=<AddBackward0>)\n",
      "cre tensor(44.1423, grad_fn=<AddBackward0>)\n",
      "sp_loss: 44.14231491088867\n",
      "\n",
      "       acc    bmx  bmn     mse        spr    run\n",
      "0  30.682  3.774  0.0  79.832  82739.818 -2.907\n",
      "ValEpoch(006) - \n",
      "      acc    bmx  bmn     run\n",
      "0  34.46  3.543  0.0  13.139\n",
      "*****\n",
      " Epoch 7 of 20\n",
      "TrEpoch(007) - \n",
      "       acc    bmx  bmn     mse        spr    run\n",
      "0  31.275  3.584  0.0  77.587  82810.785 -5.224\n",
      "ValEpoch(007) - \n",
      "      acc    bmx  bmn     run\n",
      "0  32.73  3.416  0.0  12.761\n",
      "*****\n",
      " Epoch 8 of 20\n",
      "TrEpoch(008) - \n",
      "       acc    bmx  bmn     mse        spr    run\n",
      "0  33.228  3.451  0.0  75.773  82871.477 -7.099\n",
      "ValEpoch(008) - \n",
      "     acc    bmx  bmn     run\n",
      "0  32.7  3.345  0.0  12.627\n",
      "*****\n",
      " Epoch 9 of 20\n",
      "TrEpoch(009) - \n",
      "       acc    bmx  bmn     mse        spr    run\n",
      "0  32.303  3.313  0.0  73.863  82923.323 -9.061\n",
      "ValEpoch(009) - \n",
      "      acc    bmx  bmn     run\n",
      "0  32.79  3.254  0.0  12.195\n",
      "*****\n",
      " Epoch 10 of 20\n",
      "TrEpoch(010) - \n",
      "       acc    bmx  bmn     mse        spr     run\n",
      "0  27.842  3.262  0.0  72.488  82973.606 -10.486\n",
      "ValEpoch(010) - \n",
      "      acc    bmx  bmn     run\n",
      "0  33.21  3.114  0.0  12.115\n",
      "*****\n",
      " Epoch 11 of 20\n",
      "TrEpoch(011) - cre tensor(5.3816, grad_fn=<AddBackward0>)\n",
      "cre tensor(10.1543, grad_fn=<AddBackward0>)\n",
      "cre tensor(14.2093, grad_fn=<AddBackward0>)\n",
      "cre tensor(17.5738, grad_fn=<AddBackward0>)\n",
      "cre tensor(20.2068, grad_fn=<AddBackward0>)\n",
      "cre tensor(23.5302, grad_fn=<AddBackward0>)\n",
      "cre tensor(27.5758, grad_fn=<AddBackward0>)\n",
      "cre tensor(32.2728, grad_fn=<AddBackward0>)\n",
      "cre tensor(37.5664, grad_fn=<AddBackward0>)\n",
      "cre tensor(44.0884, grad_fn=<AddBackward0>)\n",
      "sp_loss: 44.088409423828125\n",
      "\n",
      "       acc    bmx  bmn     mse        spr     run\n",
      "0  31.138  3.193  0.0  71.602  83003.667 -11.402\n",
      "ValEpoch(011) - \n",
      "      acc    bmx  bmn     run\n",
      "0  27.24  2.967  0.0  11.893\n",
      "*****\n",
      " Epoch 12 of 20\n",
      "TrEpoch(012) - \n",
      "       acc    bmx  bmn     mse        spr     run\n",
      "0  30.272  3.071  0.0  69.459  83014.241 -13.555\n",
      "ValEpoch(012) - \n",
      "      acc    bmx  bmn     run\n",
      "0  27.09  2.966  0.0  11.494\n",
      "*****\n",
      " Epoch 13 of 20\n",
      "TrEpoch(013) - \n",
      "       acc   bmx  bmn     mse        spr     run\n",
      "0  30.482  3.03  0.0  68.265  83052.577 -14.788\n",
      "ValEpoch(013) - \n",
      "      acc    bmx  bmn     run\n",
      "0  25.97  2.882  0.0  11.427\n",
      "*****\n",
      " Epoch 14 of 20\n",
      "TrEpoch(014) - \n",
      "       acc    bmx  bmn    mse        spr    run\n",
      "0  28.555  2.939  0.0  67.71  83090.234 -15.38\n",
      "ValEpoch(014) - \n",
      "      acc    bmx  bmn     run\n",
      "0  27.61  2.806  0.0  11.192\n",
      "*****\n",
      " Epoch 15 of 20\n",
      "TrEpoch(015) - \n",
      "     acc    bmx  bmn    mse        spr     run\n",
      "0  29.2  2.827  0.0  66.53  83124.511 -16.595\n",
      "ValEpoch(015) - \n",
      "     acc    bmx  bmn     run\n",
      "0  26.5  2.666  0.0  11.094\n",
      "*****\n",
      " Epoch 16 of 20\n",
      "TrEpoch(016) - cre tensor(5.4025, grad_fn=<AddBackward0>)\n",
      "cre tensor(10.1901, grad_fn=<AddBackward0>)\n",
      "cre tensor(14.2635, grad_fn=<AddBackward0>)\n",
      "cre tensor(17.6448, grad_fn=<AddBackward0>)\n",
      "cre tensor(20.3007, grad_fn=<AddBackward0>)\n",
      "cre tensor(23.6507, grad_fn=<AddBackward0>)\n",
      "cre tensor(27.7185, grad_fn=<AddBackward0>)\n",
      "cre tensor(32.4242, grad_fn=<AddBackward0>)\n",
      "cre tensor(37.7300, grad_fn=<AddBackward0>)\n",
      "cre tensor(44.2610, grad_fn=<AddBackward0>)\n",
      "sp_loss: 44.26102828979492\n",
      "\n",
      "       acc    bmx  bmn     mse        spr     run\n",
      "0  27.928  2.693  0.0  65.079  83160.405 -18.082\n",
      "ValEpoch(016) - \n",
      "      acc    bmx  bmn     run\n",
      "0  27.07  2.628  0.0  10.891\n",
      "*****\n",
      " Epoch 17 of 20\n",
      "TrEpoch(017) - \n",
      "     acc    bmx  bmn     mse        spr     run\n",
      "0  29.9  2.613  0.0  64.599  83193.657 -18.594\n",
      "ValEpoch(017) - \n",
      "     acc    bmx  bmn     run\n",
      "0  27.5  2.432  0.0  10.816\n",
      "*****\n",
      " Epoch 18 of 20\n",
      "TrEpoch(018) - \n",
      "       acc    bmx  bmn     mse        spr     run\n",
      "0  29.102  2.542  0.0  64.345  83223.477 -18.878\n",
      "ValEpoch(018) - \n",
      "      acc    bmx  bmn     run\n",
      "0  24.43  2.339  0.0  10.788\n",
      "*****\n",
      " Epoch 19 of 20\n",
      "TrEpoch(019) - \n",
      "       acc    bmx  bmn     mse        spr     run\n",
      "0  30.412  2.385  0.0  63.647  83252.195 -19.605\n",
      "ValEpoch(019) - \n",
      "      acc    bmx  bmn    run\n",
      "0  28.23  2.278  0.0  10.49\n",
      "36.7 minutes\n"
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_ws05 :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param * sp_loss\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       acc    bmx  bmn      mse        spr      run\n",
      "0   20.815  3.753  0.0  187.774  83445.350  104.329\n",
      "1   22.980  4.146  0.0  122.562  82683.105   39.879\n",
      "2   22.478  3.958  0.0  112.477  82830.491   29.646\n",
      "3   31.328  4.178  0.0  100.246  82757.332   17.488\n",
      "4   28.988  4.176  0.0   87.724  82637.369    5.087\n",
      "5   34.077  4.322  0.0   82.271  82670.433   -0.399\n",
      "6   30.682  3.774  0.0   79.832  82739.818   -2.907\n",
      "7   31.275  3.584  0.0   77.587  82810.785   -5.224\n",
      "8   33.228  3.451  0.0   75.773  82871.477   -7.099\n",
      "9   32.303  3.313  0.0   73.863  82923.323   -9.061\n",
      "10  27.842  3.262  0.0   72.488  82973.606  -10.486\n",
      "11  31.138  3.193  0.0   71.602  83003.667  -11.402\n",
      "12  30.272  3.071  0.0   69.459  83014.241  -13.555\n",
      "13  30.482  3.030  0.0   68.265  83052.577  -14.788\n",
      "14  28.555  2.939  0.0   67.710  83090.234  -15.380\n",
      "15  29.200  2.827  0.0   66.530  83124.511  -16.595\n",
      "16  27.928  2.693  0.0   65.079  83160.405  -18.082\n",
      "17  29.900  2.613  0.0   64.599  83193.657  -18.594\n",
      "18  29.102  2.542  0.0   64.345  83223.477  -18.878\n",
      "19  30.412  2.385  0.0   63.647  83252.195  -19.605\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      acc    bmx  bmn     run\n",
      "0   29.86  3.825  0.0  21.781\n",
      "1   24.88  3.816  0.0  19.384\n",
      "2   33.40  3.684  0.0  18.265\n",
      "3   25.62  3.948  0.0  15.290\n",
      "4   26.28  4.187  0.0  13.919\n",
      "5   30.02  3.800  0.0  13.598\n",
      "6   34.46  3.543  0.0  13.139\n",
      "7   32.73  3.416  0.0  12.761\n",
      "8   32.70  3.345  0.0  12.627\n",
      "9   32.79  3.254  0.0  12.195\n",
      "10  33.21  3.114  0.0  12.115\n",
      "11  27.24  2.967  0.0  11.893\n",
      "12  27.09  2.966  0.0  11.494\n",
      "13  25.97  2.882  0.0  11.427\n",
      "14  27.61  2.806  0.0  11.192\n",
      "15  26.50  2.666  0.0  11.094\n",
      "16  27.07  2.628  0.0  10.891\n",
      "17  27.50  2.432  0.0  10.816\n",
      "18  24.43  2.339  0.0  10.788\n",
      "19  28.23  2.278  0.0  10.490\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
