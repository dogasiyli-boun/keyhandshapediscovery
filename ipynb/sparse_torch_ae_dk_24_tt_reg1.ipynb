{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:  1.1.0\n",
      "torch:  1.6.0\n",
      "numpy:  1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "import pandas as pd\n",
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"torch: \", torch.__version__)\n",
    "print(\"numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsubuntu_khs_dir = /home/wsubuntu/GitHub/keyhandshapediscovery\n",
      "wsubuntu_data_path = /media/wsubuntu/SSD_Data/DataPath\n",
      "wsubuntu_experiment_path = /media/wsubuntu/SSD_Data/vaesae_experiments\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "def get_var_by_comp_name(variableName):\n",
    "    curCompName = socket.gethostname()\n",
    "    retVal = None\n",
    "    if variableName == 'khs_dir':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/home/wsubuntu/GitHub/keyhandshapediscovery'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'data_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/Datasets'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/DataPath'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'experiment_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/SPARSE_TORCH'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/vaesae_experiments'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "        \n",
    "    print(curCompName + '_' + variableName, '=',  retVal)\n",
    "    if retVal is None:\n",
    "        os.error(5)\n",
    "    return retVal\n",
    "\n",
    "khs_dir = get_var_by_comp_name('khs_dir')\n",
    "data_path = get_var_by_comp_name('data_path')\n",
    "experiment_path = get_var_by_comp_name('experiment_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, khs_dir)\n",
    "import helperFuncs as funcH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 24\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'batchmean','sum'\n",
    "SIGMOID_ACT=True\n",
    "APPLY_LOG_SOFTMAX=True\n",
    "MSE_PLUS_MINUS='+'\n",
    "APPLY_SPARSITY_TO='bottleneck' #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 100  # args['epochs']\n",
    "reg_param = 1  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": data_path,\n",
    "    \"experiment\": os.path.join(experiment_path, 'sparse_torch_ae_' + str(EXPERIMENT_ID).zfill(3)),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseAutoencoder - loss_type(cre), device(cpu)\n"
     ]
    }
   ],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=32)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    "        print(\"SparseAutoencoder - loss_type(\" + loss_type +\"), device(\" + self.device + \")\")\n",
    "\n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        if self.loss_type=='cre':\n",
    "            bottleneck = self.enc5(x) \n",
    "        else:\n",
    "            bottleneck = F.relu(self.enc5(x))  \n",
    "        \n",
    "        return bottleneck\n",
    "        \n",
    "    def decode(self, bottleneck):\n",
    "        # decoding\n",
    "        if self.loss_type=='cre':\n",
    "            x = F.relu(self.dec1(F.relu(bottleneck)))\n",
    "        else:\n",
    "            x = F.relu(self.dec1(bottleneck))\n",
    "        \n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x)) \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encode(x)\n",
    "        x = self.decode(bottleneck)\n",
    "        return x, bottleneck\n",
    "\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    rho_val = 1/bt.size(1)\n",
    "    rho_mat = torch.tensor([rho_val] * np.ones(bt.size()), dtype=torch.float32).to(device)\n",
    "    #https://discuss.pytorch.org/t/kl-divergence-produces-negative-values/16791/13\n",
    "    #KLDLoss(p, q), sum(q) needs to equal one\n",
    "    #p = log_softmax(tensor)\n",
    "    loss_ret_1 = F.kl_div(F.log_softmax(bt, dim=1).to(device), rho_mat, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct and apply_log_softmax:  \n",
    "        if print_info:\n",
    "            print(\"1-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    elif sigmoidAct and not apply_log_softmax:     \n",
    "        if print_info:\n",
    "            print(\"2-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(bt.to(device), preds)    \n",
    "    elif not sigmoidAct and apply_log_softmax:\n",
    "        if print_info:\n",
    "            print(\"3-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bottleneck, dim=1).to(device), preds)    \n",
    "    else:#nothing\n",
    "        if print_info:\n",
    "            print(\"4-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(bottleneck.to(device), preds)\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy_old(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct:\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    else:\n",
    "        bt = bottleneck    \n",
    "    _, preds = torch.max(bt, 1)\n",
    "    loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss\n",
    "\n",
    "def sparse_loss_bottleneck(bottleneck, print_info, loss_type):\n",
    "    loss = 0\n",
    "    #if print_info:\n",
    "        #print(i, ' shape=', values.shape)\n",
    "    if loss_type=='l1':\n",
    "        loss += loss_l1(bottleneck)\n",
    "    if loss_type=='l2':\n",
    "        loss += loss_l2(bottleneck)\n",
    "    if loss_type=='kl':\n",
    "        loss += kl_divergence(bottleneck, reduction=LOSS_REDUCTION)\n",
    "    if loss_type=='cre':\n",
    "        loss += loss_crossentropy(bottleneck, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "    if print_info:\n",
    "        print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            if APPLY_SPARSITY_TO=='all':\n",
    "                sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            elif APPLY_SPARSITY_TO=='bottleneck': #all\n",
    "                sp_loss = sparse_loss_bottleneck(bottleneck, print_losses_fit, model.loss_type)\n",
    "            else:\n",
    "                os.exit(4)\n",
    "                \n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            \n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "                \n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_ws :: \n",
      "EXPERIMENT_ID:  24\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  True\n",
      "APPLY_LOG_SOFTMAX :  True\n",
      "APPLY_SPARSITY_TO :  bottleneck\n",
      "total loss = mse_loss + reg_param * sp_loss\n",
      "*****\n",
      " Epoch 0 of 100\n",
      "TrEpoch(000) - 1- True True\n",
      "cre tensor(3.4163, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.416327714920044\n",
      "\n",
      "     acc     bmx      bmn      mse       spr       run\n",
      "0  10.0  93.181 -150.725  190.997  4800.991  4991.989\n",
      "ValEpoch(000) - \n",
      "     acc     bmx      bmn    run\n",
      "0  10.0  93.473 -153.425  29.47\n",
      "*****\n",
      " Epoch 1 of 100\n",
      "TrEpoch(001) - \n",
      "     acc    bmx      bmn      mse       spr       run\n",
      "0  10.0  164.1 -273.464  169.632  4721.433  4891.065\n",
      "ValEpoch(001) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  154.889 -263.603  26.777\n",
      "*****\n",
      " Epoch 2 of 100\n",
      "TrEpoch(002) - \n",
      "     acc      bmx      bmn      mse       spr       run\n",
      "0  10.0  249.707 -386.109  147.771  4721.515  4869.286\n",
      "ValEpoch(002) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  234.584 -364.881  23.543\n",
      "*****\n",
      " Epoch 3 of 100\n",
      "TrEpoch(003) - \n",
      "     acc      bmx      bmn      mse       spr       run\n",
      "0  10.0  246.835 -382.449  137.532  4721.446  4858.978\n",
      "ValEpoch(003) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  178.414 -294.628  22.271\n",
      "*****\n",
      " Epoch 4 of 100\n",
      "TrEpoch(004) - \n",
      "     acc     bmx      bmn      mse       spr       run\n",
      "0  10.0  179.68 -308.782  128.051  4721.446  4849.496\n",
      "ValEpoch(004) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  147.372 -282.879  20.992\n",
      "*****\n",
      " Epoch 5 of 100\n",
      "TrEpoch(005) - "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-40a9651c7a19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"*****\\n Epoch {epoch} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mresult_df_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mresult_df_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint_losses_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-0a47c7f60ff3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, dataloader, epoch, print_losses_fit)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottleneck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mbottleneck_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mmse_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mmse_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#if print_losses_fit:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2646\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_ws :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"APPLY_LOG_SOFTMAX : \", APPLY_LOG_SOFTMAX)\n",
    "print(\"APPLY_SPARSITY_TO : \", APPLY_SPARSITY_TO)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param * sp_loss\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    acc      bmx      bmn      mse       spr       run\n",
      "0  10.0   93.181 -150.725  190.997  4800.991  4991.989\n",
      "1  10.0  164.100 -273.464  169.632  4721.433  4891.065\n",
      "2  10.0  249.707 -386.109  147.771  4721.515  4869.286\n",
      "3  10.0  246.835 -382.449  137.532  4721.446  4858.978\n",
      "4  10.0  179.680 -308.782  128.051  4721.446  4849.496\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    acc      bmx      bmn     run\n",
      "0  10.0   93.473 -153.425  29.470\n",
      "1  10.0  154.889 -263.603  26.777\n",
      "2  10.0  234.584 -364.881  23.543\n",
      "3  10.0  178.414 -294.628  22.271\n",
      "4  10.0  147.372 -282.879  20.992\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tr acc =  10.0\n",
      "Max va acc =  10.0\n"
     ]
    }
   ],
   "source": [
    "tr_acc = result_df_tr_all.values[:,0].squeeze()\n",
    "va_acc = result_df_va_all.values[:,0].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_acc, color='orange', label='train acc')\n",
    "plt.plot(va_acc, color='red', label='validataion acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Max tr acc = \", np.max(tr_acc))\n",
    "print(\"Max va acc = \", np.max(va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_mse = result_df_tr_all.values[:,3].squeeze()\n",
    "tr_spr_50 = 100*result_df_tr_all.values[:,4].squeeze()\n",
    "va_err = 5*result_df_va_all.values[:,-1].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_mse, color='orange', label='train mse')\n",
    "plt.plot(tr_spr_50, color='red', label='tr spr*100')\n",
    "plt.plot(va_err, color='blue', label='va_err*5')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
