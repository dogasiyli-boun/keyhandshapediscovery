{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:  1.1.0\n",
      "torch:  1.6.0\n",
      "numpy:  1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "import pandas as pd\n",
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"torch: \", torch.__version__)\n",
    "print(\"numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsubuntu_khs_dir = /home/wsubuntu/GitHub/keyhandshapediscovery\n",
      "wsubuntu_data_path = /media/wsubuntu/SSD_Data/DataPath\n",
      "wsubuntu_experiment_path = /media/wsubuntu/SSD_Data/vaesae_experiments\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "def get_var_by_comp_name(variableName):\n",
    "    curCompName = socket.gethostname()\n",
    "    retVal = None\n",
    "    if variableName == 'khs_dir':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/home/wsubuntu/GitHub/keyhandshapediscovery'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'data_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/Datasets'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/DataPath'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'experiment_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/SPARSE_TORCH'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/vaesae_experiments'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "        \n",
    "    print(curCompName + '_' + variableName, '=',  retVal)\n",
    "    if retVal is None:\n",
    "        os.error(5)\n",
    "    return retVal\n",
    "\n",
    "khs_dir = get_var_by_comp_name('khs_dir')\n",
    "data_path = get_var_by_comp_name('data_path')\n",
    "experiment_path = get_var_by_comp_name('experiment_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, khs_dir)\n",
    "import helperFuncs as funcH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 23\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'batchmean','sum'\n",
    "SIGMOID_ACT=True\n",
    "APPLY_LOG_SOFTMAX=False\n",
    "MSE_PLUS_MINUS='+'\n",
    "APPLY_SPARSITY_TO='bottleneck' #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 100  # args['epochs']\n",
    "reg_param = 1  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": data_path,\n",
    "    \"experiment\": os.path.join(experiment_path, 'sparse_torch_ae_' + str(EXPERIMENT_ID).zfill(3)),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseAutoencoder - loss_type(cre), device(cpu)\n"
     ]
    }
   ],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=32)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    "        print(\"SparseAutoencoder - loss_type(\" + loss_type +\"), device(\" + self.device + \")\")\n",
    "\n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        if self.loss_type=='cre':\n",
    "            bottleneck = self.enc5(x) \n",
    "        else:\n",
    "            bottleneck = F.relu(self.enc5(x))  \n",
    "        \n",
    "        return bottleneck\n",
    "        \n",
    "    def decode(self, bottleneck):\n",
    "        # decoding\n",
    "        if self.loss_type=='cre':\n",
    "            x = F.relu(self.dec1(F.relu(bottleneck)))\n",
    "        else:\n",
    "            x = F.relu(self.dec1(bottleneck))\n",
    "        \n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x)) \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encode(x)\n",
    "        x = self.decode(bottleneck)\n",
    "        return x, bottleneck\n",
    "\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    rho_val = 1/bt.size(1)\n",
    "    rho_mat = torch.tensor([rho_val] * np.ones(bt.size()), dtype=torch.float32).to(device)\n",
    "    #https://discuss.pytorch.org/t/kl-divergence-produces-negative-values/16791/13\n",
    "    #KLDLoss(p, q), sum(q) needs to equal one\n",
    "    #p = log_softmax(tensor)\n",
    "    loss_ret_1 = F.kl_div(F.log_softmax(bt, dim=1).to(device), rho_mat, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct and apply_log_softmax:  \n",
    "        if print_info:\n",
    "            print(\"1-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    elif sigmoidAct and not apply_log_softmax:     \n",
    "        if print_info:\n",
    "            print(\"2-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(bt.to(device), preds)    \n",
    "    elif not sigmoidAct and apply_log_softmax:\n",
    "        if print_info:\n",
    "            print(\"3-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bottleneck, dim=1).to(device), preds)    \n",
    "    else:#nothing\n",
    "        if print_info:\n",
    "            print(\"4-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(bottleneck.to(device), preds)\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy_old(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct:\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    else:\n",
    "        bt = bottleneck    \n",
    "    _, preds = torch.max(bt, 1)\n",
    "    loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss\n",
    "\n",
    "def sparse_loss_bottleneck(bottleneck, print_info, loss_type):\n",
    "    loss = 0\n",
    "    #if print_info:\n",
    "        #print(i, ' shape=', values.shape)\n",
    "    if loss_type=='l1':\n",
    "        loss += loss_l1(bottleneck)\n",
    "    if loss_type=='l2':\n",
    "        loss += loss_l2(bottleneck)\n",
    "    if loss_type=='kl':\n",
    "        loss += kl_divergence(bottleneck, reduction=LOSS_REDUCTION)\n",
    "    if loss_type=='cre':\n",
    "        loss += loss_crossentropy(bottleneck, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "    if print_info:\n",
    "        print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            if APPLY_SPARSITY_TO=='all':\n",
    "                sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            elif APPLY_SPARSITY_TO=='bottleneck': #all\n",
    "                sp_loss = sparse_loss_bottleneck(bottleneck, print_losses_fit, model.loss_type)\n",
    "            else:\n",
    "                os.exit(4)\n",
    "                \n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            \n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "                \n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_ws :: \n",
      "EXPERIMENT_ID:  23\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  True\n",
      "APPLY_LOG_SOFTMAX :  False\n",
      "APPLY_SPARSITY_TO :  bottleneck\n",
      "total loss = mse_loss + reg_param(1) * sp_loss\n",
      "*****\n",
      " Epoch 0 of 100\n",
      "TrEpoch(000) - 2- True False\n",
      "cre tensor(3.4078, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.4078190326690674\n",
      "\n",
      "     acc     bmx      bmn      mse       spr       run\n",
      "0  10.0  83.966 -174.316  195.784  4828.508  5024.292\n",
      "ValEpoch(000) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  83.974 -173.809  29.752\n",
      "*****\n",
      " Epoch 1 of 100\n",
      "TrEpoch(001) - \n",
      "     acc      bmx      bmn      mse       spr       run\n",
      "0  10.0  141.856 -257.922  172.084  4721.457  4893.541\n",
      "ValEpoch(001) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  140.496 -250.354  26.736\n",
      "*****\n",
      " Epoch 2 of 100\n",
      "TrEpoch(002) - \n",
      "     acc      bmx      bmn      mse       spr       run\n",
      "0  10.0  235.098 -359.768  151.874  4721.549  4873.423\n",
      "ValEpoch(002) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  214.071 -332.282  24.304\n",
      "*****\n",
      " Epoch 3 of 100\n",
      "TrEpoch(003) - \n",
      "     acc      bmx      bmn      mse       spr       run\n",
      "0  10.0  258.332 -387.636  140.013  4721.438  4861.451\n",
      "ValEpoch(003) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  233.142 -348.375  22.741\n",
      "*****\n",
      " Epoch 4 of 100\n",
      "TrEpoch(004) - \n",
      "     acc      bmx     bmn      mse       spr      run\n",
      "0  10.0  238.785 -351.41  134.496  4721.424  4855.92\n",
      "ValEpoch(004) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  202.599 -296.258  22.091\n",
      "*****\n",
      " Epoch 5 of 100\n",
      "TrEpoch(005) - \n",
      "     acc      bmx      bmn     mse       spr       run\n",
      "0  10.0  204.047 -294.466  130.88  4721.431  4852.311\n",
      "ValEpoch(005) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  171.684 -240.618  21.508\n",
      "*****\n",
      " Epoch 6 of 100\n",
      "TrEpoch(006) - 2- True False\n",
      "cre tensor(2.5181, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5180866718292236\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-537f58b86215>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"*****\\n Epoch {epoch} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mresult_df_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mresult_df_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint_losses_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-0a47c7f60ff3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, dataloader, epoch, print_losses_fit)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mmse_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlab_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2737\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2738\u001b[0m     \"\"\"\n\u001b[0;32m-> 2739\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2740\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2741\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_ws :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"APPLY_LOG_SOFTMAX : \", APPLY_LOG_SOFTMAX)\n",
    "print(\"APPLY_SPARSITY_TO : \", APPLY_SPARSITY_TO)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param(\"+ str(reg_param) +\") * sp_loss\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    acc      bmx      bmn      mse       spr       run\n",
      "0  10.0   83.966 -174.316  195.784  4828.508  5024.292\n",
      "1  10.0  141.856 -257.922  172.084  4721.457  4893.541\n",
      "2  10.0  235.098 -359.768  151.874  4721.549  4873.423\n",
      "3  10.0  258.332 -387.636  140.013  4721.438  4861.451\n",
      "4  10.0  238.785 -351.410  134.496  4721.424  4855.920\n",
      "5  10.0  204.047 -294.466  130.880  4721.431  4852.311\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    acc      bmx      bmn     run\n",
      "0  10.0   83.974 -173.809  29.752\n",
      "1  10.0  140.496 -250.354  26.736\n",
      "2  10.0  214.071 -332.282  24.304\n",
      "3  10.0  233.142 -348.375  22.741\n",
      "4  10.0  202.599 -296.258  22.091\n",
      "5  10.0  171.684 -240.618  21.508\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tr acc =  10.0\n",
      "Max va acc =  10.0\n"
     ]
    }
   ],
   "source": [
    "tr_acc = result_df_tr_all.values[:,0].squeeze()\n",
    "va_acc = result_df_va_all.values[:,0].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_acc, color='orange', label='train acc')\n",
    "plt.plot(va_acc, color='red', label='validataion acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Max tr acc = \", np.max(tr_acc))\n",
    "print(\"Max va acc = \", np.max(va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_mse = result_df_tr_all.values[:,3].squeeze()\n",
    "tr_spr_50 = 100*result_df_tr_all.values[:,4].squeeze()\n",
    "va_err = 5*result_df_va_all.values[:,-1].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_mse, color='orange', label='train mse')\n",
    "plt.plot(tr_spr_50, color='red', label='tr spr*100')\n",
    "plt.plot(va_err, color='blue', label='va_err*5')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
