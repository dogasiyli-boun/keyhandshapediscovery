{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:  1.1.0\n",
      "torch:  1.6.0\n",
      "numpy:  1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "import pandas as pd\n",
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"torch: \", torch.__version__)\n",
    "print(\"numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsubuntu_khs_dir = /home/wsubuntu/GitHub/keyhandshapediscovery\n",
      "wsubuntu_data_path = /media/wsubuntu/SSD_Data/DataPath\n",
      "wsubuntu_experiment_path = /media/wsubuntu/SSD_Data/vaesae_experiments\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "def get_var_by_comp_name(variableName):\n",
    "    curCompName = socket.gethostname()\n",
    "    retVal = None\n",
    "    if variableName == 'khs_dir':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/home/wsubuntu/GitHub/keyhandshapediscovery'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'data_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/Datasets'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/DataPath'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'experiment_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/SPARSE_TORCH'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/vaesae_experiments'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "        \n",
    "    print(curCompName + '_' + variableName, '=',  retVal)\n",
    "    if retVal is None:\n",
    "        os.error(5)\n",
    "    return retVal\n",
    "\n",
    "khs_dir = get_var_by_comp_name('khs_dir')\n",
    "data_path = get_var_by_comp_name('data_path')\n",
    "experiment_path = get_var_by_comp_name('experiment_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, khs_dir)\n",
    "import helperFuncs as funcH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 28\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'batchmean','sum'\n",
    "SIGMOID_ACT=True\n",
    "APPLY_LOG_SOFTMAX=False\n",
    "MSE_PLUS_MINUS='+'\n",
    "APPLY_SPARSITY_TO='bottleneck' #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 100  # args['epochs']\n",
    "reg_param = 1  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": data_path,\n",
    "    \"experiment\": os.path.join(experiment_path, 'sparse_torch_ae_' + str(EXPERIMENT_ID).zfill(3)),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseAutoencoder - loss_type(cre), device(cpu)\n"
     ]
    }
   ],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=32)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    "        print(\"SparseAutoencoder - loss_type(\" + loss_type +\"), device(\" + self.device + \")\")\n",
    "\n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        #if self.loss_type=='cre':\n",
    "        #    bottleneck = self.enc5(x) \n",
    "        #else:\n",
    "        bottleneck = F.relu(self.enc5(x))  \n",
    "        \n",
    "        return bottleneck\n",
    "        \n",
    "    def decode(self, bottleneck):\n",
    "        # decoding\n",
    "        #if self.loss_type=='cre':\n",
    "        #    x = F.relu(self.dec1(F.relu(bottleneck)))\n",
    "        #else:\n",
    "        x = F.relu(self.dec1(bottleneck))\n",
    "        \n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x)) \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encode(x)\n",
    "        x = self.decode(bottleneck)\n",
    "        return x, bottleneck\n",
    "\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    rho_val = 1/bt.size(1)\n",
    "    rho_mat = torch.tensor([rho_val] * np.ones(bt.size()), dtype=torch.float32).to(device)\n",
    "    #https://discuss.pytorch.org/t/kl-divergence-produces-negative-values/16791/13\n",
    "    #KLDLoss(p, q), sum(q) needs to equal one\n",
    "    #p = log_softmax(tensor)\n",
    "    loss_ret_1 = F.kl_div(F.log_softmax(bt, dim=1).to(device), rho_mat, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct and apply_log_softmax:  \n",
    "        if print_info:\n",
    "            print(\"1-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    elif sigmoidAct and not apply_log_softmax:     \n",
    "        if print_info:\n",
    "            print(\"2-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(bt.to(device), preds)    \n",
    "    elif not sigmoidAct and apply_log_softmax:\n",
    "        if print_info:\n",
    "            print(\"3-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bottleneck, dim=1).to(device), preds)    \n",
    "    else:#nothing\n",
    "        if print_info:\n",
    "            print(\"4-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(bottleneck.to(device), preds)\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy_old(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct:\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    else:\n",
    "        bt = bottleneck    \n",
    "    _, preds = torch.max(bt, 1)\n",
    "    loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss\n",
    "\n",
    "def sparse_loss_bottleneck(bottleneck, print_info, loss_type):\n",
    "    loss = 0\n",
    "    #if print_info:\n",
    "        #print(i, ' shape=', values.shape)\n",
    "    if loss_type=='l1':\n",
    "        loss += loss_l1(bottleneck)\n",
    "    if loss_type=='l2':\n",
    "        loss += loss_l2(bottleneck)\n",
    "    if loss_type=='kl':\n",
    "        loss += kl_divergence(bottleneck, reduction=LOSS_REDUCTION)\n",
    "    if loss_type=='cre':\n",
    "        loss += loss_crossentropy(bottleneck, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "    if print_info:\n",
    "        print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            if APPLY_SPARSITY_TO=='all':\n",
    "                sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            elif APPLY_SPARSITY_TO=='bottleneck': #all\n",
    "                sp_loss = sparse_loss_bottleneck(bottleneck, print_losses_fit, model.loss_type)\n",
    "            else:\n",
    "                os.exit(4)\n",
    "                \n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            \n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "                \n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_ws :: \n",
      "EXPERIMENT_ID:  28\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  True\n",
      "APPLY_LOG_SOFTMAX :  False\n",
      "APPLY_SPARSITY_TO :  bottleneck\n",
      "total loss = mse_loss + reg_param(1) * sp_loss\n",
      "*****\n",
      " Epoch 0 of 100\n",
      "TrEpoch(000) - 2- True False\n",
      "cre tensor(3.4291, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.4291458129882812\n",
      "\n",
      "     acc      bmx  bmn      mse       spr      run\n",
      "0  10.0  102.452  0.0  194.376  5623.894  5818.27\n",
      "ValEpoch(000) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  101.685  0.0  29.514\n",
      "*****\n",
      " Epoch 1 of 100\n",
      "TrEpoch(001) - \n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  202.163  0.0  166.368  5598.558  5764.926\n",
      "ValEpoch(001) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  199.356  0.0  25.309\n",
      "*****\n",
      " Epoch 2 of 100\n",
      "TrEpoch(002) - \n",
      "     acc      bmx  bmn      mse     spr       run\n",
      "0  10.0  233.377  0.0  147.307  5598.5  5745.807\n",
      "ValEpoch(002) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  196.136  0.0  23.884\n",
      "*****\n",
      " Epoch 3 of 100\n",
      "TrEpoch(003) - \n",
      "     acc      bmx  bmn     mse      spr      run\n",
      "0  10.0  196.937  0.0  138.41  5598.48  5736.89\n",
      "ValEpoch(003) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  159.821  0.0  22.418\n",
      "*****\n",
      " Epoch 4 of 100\n",
      "TrEpoch(004) - \n",
      "     acc     bmx  bmn      mse       spr       run\n",
      "0  10.0  151.13  0.0  132.619  5598.471  5731.091\n",
      "ValEpoch(004) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  136.787  0.0  21.826\n",
      "*****\n",
      " Epoch 5 of 100\n",
      "TrEpoch(005) - \n",
      "     acc      bmx  bmn      mse      spr       run\n",
      "0  10.0  138.199  0.0  129.156  5598.45  5727.606\n",
      "ValEpoch(005) - \n",
      "     acc      bmx  bmn    run\n",
      "0  10.0  131.652  0.0  21.39\n",
      "*****\n",
      " Epoch 6 of 100\n",
      "TrEpoch(006) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.985832452774048\n",
      "\n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  133.038  0.0  125.683  5598.444  5724.127\n",
      "ValEpoch(006) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  123.893  0.0  20.822\n",
      "*****\n",
      " Epoch 7 of 100\n",
      "TrEpoch(007) - \n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  129.645  0.0  124.163  5598.441  5722.604\n",
      "ValEpoch(007) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  122.864  0.0  20.554\n",
      "*****\n",
      " Epoch 8 of 100\n",
      "TrEpoch(008) - \n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  128.514  0.0  121.373  5598.448  5719.821\n",
      "ValEpoch(008) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  121.303  0.0  20.028\n",
      "*****\n",
      " Epoch 9 of 100\n",
      "TrEpoch(009) - \n",
      "     acc      bmx  bmn     mse       spr      run\n",
      "0  10.0  134.024  0.0  119.09  5598.451  5717.54\n",
      "ValEpoch(009) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  130.614  0.0  19.647\n",
      "*****\n",
      " Epoch 10 of 100\n",
      "TrEpoch(010) - \n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  136.412  0.0  116.736  5598.457  5715.192\n",
      "ValEpoch(010) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  132.433  0.0  19.455\n",
      "*****\n",
      " Epoch 11 of 100\n",
      "TrEpoch(011) - 2- True False\n",
      "cre tensor(2.9859, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.9858617782592773\n",
      "\n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  141.398  0.0  115.188  5598.464  5713.652\n",
      "ValEpoch(011) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  133.137  0.0  19.121\n",
      "*****\n",
      " Epoch 12 of 100\n",
      "TrEpoch(012) - \n",
      "     acc      bmx  bmn      mse      spr       run\n",
      "0  10.0  149.386  0.0  114.342  5598.47  5712.812\n",
      "ValEpoch(012) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  140.881  0.0  19.069\n",
      "*****\n",
      " Epoch 13 of 100\n",
      "TrEpoch(013) - \n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  145.646  0.0  113.556  5598.465  5712.021\n",
      "ValEpoch(013) - \n",
      "     acc      bmx  bmn    run\n",
      "0  10.0  141.923  0.0  18.95\n",
      "*****\n",
      " Epoch 14 of 100\n",
      "TrEpoch(014) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  148.594  0.0  111.74  5598.466  5710.206\n",
      "ValEpoch(014) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  139.418  0.0  18.632\n",
      "*****\n",
      " Epoch 15 of 100\n",
      "TrEpoch(015) - \n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  150.574  0.0  111.245  5598.459  5709.703\n",
      "ValEpoch(015) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  145.865  0.0  18.619\n",
      "*****\n",
      " Epoch 16 of 100\n",
      "TrEpoch(016) - 2- True False\n",
      "cre tensor(2.9859, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.98592472076416\n",
      "\n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  151.347  0.0  110.698  5598.468  5709.166\n",
      "ValEpoch(016) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  147.173  0.0  18.531\n",
      "*****\n",
      " Epoch 17 of 100\n",
      "TrEpoch(017) - \n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  153.411  0.0  110.344  5598.464  5708.808\n",
      "ValEpoch(017) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  146.336  0.0  18.452\n",
      "*****\n",
      " Epoch 18 of 100\n",
      "TrEpoch(018) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  151.565  0.0  110.03  5598.461  5708.491\n",
      "ValEpoch(018) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  150.904  0.0  18.557\n",
      "*****\n",
      " Epoch 19 of 100\n",
      "TrEpoch(019) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  159.134  0.0  109.25  5598.462  5707.712\n",
      "ValEpoch(019) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  148.644  0.0  18.195\n",
      "*****\n",
      " Epoch 20 of 100\n",
      "TrEpoch(020) - \n",
      "     acc     bmx  bmn      mse       spr       run\n",
      "0  10.0  156.58  0.0  107.732  5598.461  5706.193\n",
      "ValEpoch(020) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  149.843  0.0  18.041\n",
      "*****\n",
      " Epoch 21 of 100\n",
      "TrEpoch(021) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.985818386077881\n",
      "\n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  157.052  0.0  107.064  5598.457  5705.521\n",
      "ValEpoch(021) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  156.024  0.0  17.985\n",
      "*****\n",
      " Epoch 22 of 100\n",
      "TrEpoch(022) - \n",
      "     acc     bmx  bmn     mse       spr       run\n",
      "0  10.0  160.64  0.0  106.59  5598.462  5705.052\n",
      "ValEpoch(022) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  156.929  0.0  17.867\n",
      "*****\n",
      " Epoch 23 of 100\n",
      "TrEpoch(023) - \n",
      "     acc      bmx  bmn      mse      spr       run\n",
      "0  10.0  161.945  0.0  106.252  5598.46  5704.712\n",
      "ValEpoch(023) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  161.137  0.0  17.922\n",
      "*****\n",
      " Epoch 24 of 100\n",
      "TrEpoch(024) - \n",
      "     acc     bmx  bmn      mse      spr       run\n",
      "0  10.0  168.18  0.0  105.803  5598.46  5704.263\n",
      "ValEpoch(024) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  160.408  0.0  17.665\n",
      "*****\n",
      " Epoch 25 of 100\n",
      "TrEpoch(025) - \n",
      "     acc      bmx  bmn      mse      spr       run\n",
      "0  10.0  165.412  0.0  104.753  5598.46  5703.213\n",
      "ValEpoch(025) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  162.972  0.0  17.466\n",
      "*****\n",
      " Epoch 26 of 100\n",
      "TrEpoch(026) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.985814332962036\n",
      "\n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  164.417  0.0  103.856  5598.462  5702.318\n",
      "ValEpoch(026) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  167.821  0.0  17.425\n",
      "*****\n",
      " Epoch 27 of 100\n",
      "TrEpoch(027) - \n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  165.529  0.0  103.367  5598.465  5701.832\n",
      "ValEpoch(027) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  168.761  0.0  17.674\n",
      "*****\n",
      " Epoch 28 of 100\n",
      "TrEpoch(028) - \n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  170.347  0.0  102.161  5598.466  5700.627\n",
      "ValEpoch(028) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  168.776  0.0  17.132\n",
      "*****\n",
      " Epoch 29 of 100\n",
      "TrEpoch(029) - \n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  169.015  0.0  101.243  5598.462  5699.705\n",
      "ValEpoch(029) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  171.114  0.0  17.129\n",
      "*****\n",
      " Epoch 30 of 100\n",
      "TrEpoch(030) - \n",
      "     acc      bmx  bmn      mse       spr       run\n",
      "0  10.0  172.156  0.0  101.002  5598.463  5699.465\n",
      "ValEpoch(030) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  169.675  0.0  17.026\n",
      "*****\n",
      " Epoch 31 of 100\n",
      "TrEpoch(031) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.985832691192627\n",
      "\n",
      "     acc      bmx  bmn      mse       spr      run\n",
      "0  10.0  173.476  0.0  100.076  5598.464  5698.54\n",
      "ValEpoch(031) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  170.127  0.0  16.822\n",
      "*****\n",
      " Epoch 32 of 100\n",
      "TrEpoch(032) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  176.425  0.0  99.603  5598.462  5698.065\n",
      "ValEpoch(032) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  179.747  0.0  16.808\n",
      "*****\n",
      " Epoch 33 of 100\n",
      "TrEpoch(033) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  178.944  0.0  99.387  5598.461  5697.848\n",
      "ValEpoch(033) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  183.762  0.0  16.818\n",
      "*****\n",
      " Epoch 34 of 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrEpoch(034) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  181.443  0.0  98.998  5598.462  5697.461\n",
      "ValEpoch(034) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  172.188  0.0  16.912\n",
      "*****\n",
      " Epoch 35 of 100\n",
      "TrEpoch(035) - \n",
      "     acc      bmx  bmn    mse      spr       run\n",
      "0  10.0  175.851  0.0  99.03  5598.46  5697.489\n",
      "ValEpoch(035) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  183.72  0.0  16.697\n",
      "*****\n",
      " Epoch 36 of 100\n",
      "TrEpoch(036) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.9858267307281494\n",
      "\n",
      "     acc      bmx  bmn    mse       spr       run\n",
      "0  10.0  175.904  0.0  98.69  5598.464  5697.153\n",
      "ValEpoch(036) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  175.192  0.0  16.728\n",
      "*****\n",
      " Epoch 37 of 100\n",
      "TrEpoch(037) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  178.953  0.0  98.256  5598.467  5696.723\n",
      "ValEpoch(037) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  181.116  0.0  16.636\n",
      "*****\n",
      " Epoch 38 of 100\n",
      "TrEpoch(038) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  179.854  0.0  98.103  5598.458  5696.562\n",
      "ValEpoch(038) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  183.952  0.0  16.481\n",
      "*****\n",
      " Epoch 39 of 100\n",
      "TrEpoch(039) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  177.496  0.0  97.961  5598.463  5696.424\n",
      "ValEpoch(039) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  173.393  0.0  16.906\n",
      "*****\n",
      " Epoch 40 of 100\n",
      "TrEpoch(040) - \n",
      "     acc     bmx  bmn     mse       spr       run\n",
      "0  10.0  188.32  0.0  97.796  5598.465  5696.261\n",
      "ValEpoch(040) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  183.885  0.0  16.723\n",
      "*****\n",
      " Epoch 41 of 100\n",
      "TrEpoch(041) - 2- True False\n",
      "cre tensor(2.9861, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.9860594272613525\n",
      "\n",
      "       acc     bmx  bmn     mse       spr       run\n",
      "0  10.002  184.23  0.0  97.659  5598.467  5696.125\n",
      "ValEpoch(041) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  189.939  0.0  16.609\n",
      "*****\n",
      " Epoch 42 of 100\n",
      "TrEpoch(042) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  184.975  0.0  97.527  5598.467  5695.994\n",
      "ValEpoch(042) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  182.575  0.0  16.594\n",
      "*****\n",
      " Epoch 43 of 100\n",
      "TrEpoch(043) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  185.355  0.0  96.902  5598.459  5695.361\n",
      "ValEpoch(043) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  187.742  0.0  16.241\n",
      "*****\n",
      " Epoch 44 of 100\n",
      "TrEpoch(044) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  183.322  0.0  96.169  5598.458  5694.626\n",
      "ValEpoch(044) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  179.773  0.0  16.259\n",
      "*****\n",
      " Epoch 45 of 100\n",
      "TrEpoch(045) - \n",
      "     acc     bmx  bmn     mse       spr       run\n",
      "0  10.0  180.59  0.0  96.012  5598.462  5694.474\n",
      "ValEpoch(045) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  186.561  0.0  16.201\n",
      "*****\n",
      " Epoch 46 of 100\n",
      "TrEpoch(046) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.9858148097991943\n",
      "\n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  184.034  0.0  95.813  5598.456  5694.269\n",
      "ValEpoch(046) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  188.702  0.0  16.159\n",
      "*****\n",
      " Epoch 47 of 100\n",
      "TrEpoch(047) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  183.676  0.0  95.552  5598.456  5694.009\n",
      "ValEpoch(047) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  186.369  0.0  16.148\n",
      "*****\n",
      " Epoch 48 of 100\n",
      "TrEpoch(048) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  184.725  0.0  95.456  5598.456  5693.912\n",
      "ValEpoch(048) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  191.57  0.0  16.174\n",
      "*****\n",
      " Epoch 49 of 100\n",
      "TrEpoch(049) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  184.787  0.0  95.408  5598.447  5693.854\n",
      "ValEpoch(049) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  184.935  0.0  16.178\n",
      "*****\n",
      " Epoch 50 of 100\n",
      "TrEpoch(050) - \n",
      "     acc     bmx  bmn     mse       spr       run\n",
      "0  10.0  183.88  0.0  95.352  5598.454  5693.805\n",
      "ValEpoch(050) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  180.879  0.0  16.181\n",
      "*****\n",
      " Epoch 51 of 100\n",
      "TrEpoch(051) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.9858224391937256\n",
      "\n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  178.783  0.0  94.882  5598.471  5693.353\n",
      "ValEpoch(051) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  186.572  0.0  15.964\n",
      "*****\n",
      " Epoch 52 of 100\n",
      "TrEpoch(052) - \n",
      "     acc      bmx  bmn     mse      spr       run\n",
      "0  10.0  183.136  0.0  94.644  5598.46  5693.104\n",
      "ValEpoch(052) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  194.43  0.0  16.067\n",
      "*****\n",
      " Epoch 53 of 100\n",
      "TrEpoch(053) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  188.337  0.0  94.576  5598.465  5693.041\n",
      "ValEpoch(053) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  190.167  0.0  16.062\n",
      "*****\n",
      " Epoch 54 of 100\n",
      "TrEpoch(054) - \n",
      "     acc      bmx  bmn     mse       spr      run\n",
      "0  10.0  189.615  0.0  94.624  5598.465  5693.09\n",
      "ValEpoch(054) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  181.762  0.0  16.008\n",
      "*****\n",
      " Epoch 55 of 100\n",
      "TrEpoch(055) - \n",
      "     acc      bmx  bmn     mse      spr       run\n",
      "0  10.0  183.034  0.0  94.156  5598.46  5692.616\n",
      "ValEpoch(055) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  188.411  0.0  15.977\n",
      "*****\n",
      " Epoch 56 of 100\n",
      "TrEpoch(056) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.9858481884002686\n",
      "\n",
      "     acc      bmx  bmn     mse      spr       run\n",
      "0  10.0  187.579  0.0  93.721  5598.46  5692.181\n",
      "ValEpoch(056) - \n",
      "     acc      bmx  bmn    run\n",
      "0  10.0  189.995  0.0  15.75\n",
      "*****\n",
      " Epoch 57 of 100\n",
      "TrEpoch(057) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  186.129  0.0  93.443  5598.466  5691.909\n",
      "ValEpoch(057) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  180.921  0.0  15.939\n",
      "*****\n",
      " Epoch 58 of 100\n",
      "TrEpoch(058) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  188.158  0.0  93.426  5598.456  5691.881\n",
      "ValEpoch(058) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  185.432  0.0  15.945\n",
      "*****\n",
      " Epoch 59 of 100\n",
      "TrEpoch(059) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  182.507  0.0  92.633  5598.461  5691.094\n",
      "ValEpoch(059) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  183.371  0.0  15.765\n",
      "*****\n",
      " Epoch 60 of 100\n",
      "TrEpoch(060) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  182.883  0.0  92.262  5598.457  5690.719\n",
      "ValEpoch(060) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  182.04  0.0  16.028\n",
      "*****\n",
      " Epoch 61 of 100\n",
      "TrEpoch(061) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.985827922821045\n",
      "\n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  178.465  0.0  92.337  5598.455  5690.792\n",
      "ValEpoch(061) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  182.032  0.0  15.608\n",
      "*****\n",
      " Epoch 62 of 100\n",
      "TrEpoch(062) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  186.808  0.0  92.354  5598.457  5690.812\n",
      "ValEpoch(062) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  186.507  0.0  15.567\n",
      "*****\n",
      " Epoch 63 of 100\n",
      "TrEpoch(063) - \n",
      "     acc     bmx  bmn     mse       spr       run\n",
      "0  10.0  185.02  0.0  92.171  5598.463  5690.634\n",
      "ValEpoch(063) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  181.209  0.0  15.647\n",
      "*****\n",
      " Epoch 64 of 100\n",
      "TrEpoch(064) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  177.363  0.0  91.925  5598.457  5690.382\n",
      "ValEpoch(064) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  180.44  0.0  16.452\n",
      "*****\n",
      " Epoch 65 of 100\n",
      "TrEpoch(065) - \n",
      "     acc      bmx  bmn     mse       spr      run\n",
      "0  10.0  184.562  0.0  91.696  5598.454  5690.15\n",
      "ValEpoch(065) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  179.097  0.0  15.674\n",
      "*****\n",
      " Epoch 66 of 100\n",
      "TrEpoch(066) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.985825538635254\n",
      "\n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  179.464  0.0  92.206  5598.456  5690.662\n",
      "ValEpoch(066) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  174.524  0.0  15.633\n",
      "*****\n",
      " Epoch 67 of 100\n",
      "TrEpoch(067) - \n",
      "     acc      bmx  bmn    mse       spr       run\n",
      "0  10.0  180.001  0.0  91.89  5598.468  5690.358\n",
      "ValEpoch(067) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  176.593  0.0  15.406\n",
      "*****\n",
      " Epoch 68 of 100\n",
      "TrEpoch(068) - \n",
      "     acc      bmx  bmn    mse       spr       run\n",
      "0  10.0  183.253  0.0  91.51  5598.462  5689.972\n",
      "ValEpoch(068) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  176.042  0.0  15.467\n",
      "*****\n",
      " Epoch 69 of 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrEpoch(069) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  176.196  0.0  91.461  5598.468  5689.929\n",
      "ValEpoch(069) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  174.538  0.0  15.331\n",
      "*****\n",
      " Epoch 70 of 100\n",
      "TrEpoch(070) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  176.097  0.0  92.021  5598.454  5690.475\n",
      "ValEpoch(070) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  187.011  0.0  15.769\n",
      "*****\n",
      " Epoch 71 of 100\n",
      "TrEpoch(071) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.985813617706299\n",
      "\n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  179.619  0.0  91.625  5598.461  5690.085\n",
      "ValEpoch(071) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  177.775  0.0  15.314\n",
      "*****\n",
      " Epoch 72 of 100\n",
      "TrEpoch(072) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  179.656  0.0  91.229  5598.476  5689.705\n",
      "ValEpoch(072) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  175.861  0.0  15.147\n",
      "*****\n",
      " Epoch 73 of 100\n",
      "TrEpoch(073) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  170.499  0.0  90.414  5598.469  5688.884\n",
      "ValEpoch(073) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  164.065  0.0  15.159\n",
      "*****\n",
      " Epoch 74 of 100\n",
      "TrEpoch(074) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  175.726  0.0  90.275  5598.466  5688.741\n",
      "ValEpoch(074) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  171.261  0.0  15.223\n",
      "*****\n",
      " Epoch 75 of 100\n",
      "TrEpoch(075) - \n",
      "     acc      bmx  bmn     mse       spr      run\n",
      "0  10.0  181.017  0.0  90.373  5598.467  5688.84\n",
      "ValEpoch(075) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  178.913  0.0  15.092\n",
      "*****\n",
      " Epoch 76 of 100\n",
      "TrEpoch(076) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.985837459564209\n",
      "\n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  179.777  0.0  89.694  5598.465  5688.159\n",
      "ValEpoch(076) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  175.892  0.0  15.169\n",
      "*****\n",
      " Epoch 77 of 100\n",
      "TrEpoch(077) - \n",
      "     acc      bmx  bmn    mse      spr       run\n",
      "0  10.0  168.194  0.0  90.07  5598.45  5688.521\n",
      "ValEpoch(077) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  169.865  0.0  15.134\n",
      "*****\n",
      " Epoch 78 of 100\n",
      "TrEpoch(078) - \n",
      "     acc      bmx  bmn     mse       spr      run\n",
      "0  10.0  168.682  0.0  89.478  5598.463  5687.94\n",
      "ValEpoch(078) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  163.645  0.0  14.972\n",
      "*****\n",
      " Epoch 79 of 100\n",
      "TrEpoch(079) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  179.976  0.0  89.573  5598.465  5688.039\n",
      "ValEpoch(079) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  163.918  0.0  15.247\n",
      "*****\n",
      " Epoch 80 of 100\n",
      "TrEpoch(080) - \n",
      "     acc     bmx  bmn     mse       spr       run\n",
      "0  10.0  174.05  0.0  89.239  5598.462  5687.701\n",
      "ValEpoch(080) - \n",
      "     acc      bmx  bmn   run\n",
      "0  10.0  169.118  0.0  15.0\n",
      "*****\n",
      " Epoch 81 of 100\n",
      "TrEpoch(081) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.9858319759368896\n",
      "\n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  174.605  0.0  89.908  5598.477  5688.384\n",
      "ValEpoch(081) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  162.725  0.0  15.198\n",
      "*****\n",
      " Epoch 82 of 100\n",
      "TrEpoch(082) - \n",
      "     acc      bmx  bmn     mse      spr       run\n",
      "0  10.0  180.092  0.0  89.318  5598.47  5687.788\n",
      "ValEpoch(082) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  168.617  0.0  15.242\n",
      "*****\n",
      " Epoch 83 of 100\n",
      "TrEpoch(083) - \n",
      "     acc      bmx  bmn    mse       spr       run\n",
      "0  10.0  168.885  0.0  89.19  5598.465  5687.655\n",
      "ValEpoch(083) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  164.949  0.0  15.145\n",
      "*****\n",
      " Epoch 84 of 100\n",
      "TrEpoch(084) - \n",
      "     acc      bmx  bmn     mse      spr       run\n",
      "0  10.0  166.419  0.0  88.756  5598.46  5687.216\n",
      "ValEpoch(084) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  160.767  0.0  14.896\n",
      "*****\n",
      " Epoch 85 of 100\n",
      "TrEpoch(085) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  166.225  0.0  88.791  5598.456  5687.247\n",
      "ValEpoch(085) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  161.89  0.0  14.929\n",
      "*****\n",
      " Epoch 86 of 100\n",
      "TrEpoch(086) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.985812187194824\n",
      "\n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  167.451  0.0  88.181  5598.457  5686.637\n",
      "ValEpoch(086) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  166.967  0.0  14.884\n",
      "*****\n",
      " Epoch 87 of 100\n",
      "TrEpoch(087) - \n",
      "     acc      bmx  bmn    mse       spr       run\n",
      "0  10.0  169.928  0.0  88.59  5598.445  5687.035\n",
      "ValEpoch(087) - \n",
      "     acc      bmx  bmn    run\n",
      "0  10.0  159.098  0.0  14.85\n",
      "*****\n",
      " Epoch 88 of 100\n",
      "TrEpoch(088) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  165.255  0.0  88.422  5598.443  5686.864\n",
      "ValEpoch(088) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  163.307  0.0  14.826\n",
      "*****\n",
      " Epoch 89 of 100\n",
      "TrEpoch(089) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  164.337  0.0  87.853  5598.447  5686.301\n",
      "ValEpoch(089) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  162.482  0.0  14.644\n",
      "*****\n",
      " Epoch 90 of 100\n",
      "TrEpoch(090) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  167.077  0.0  87.702  5598.456  5686.158\n",
      "ValEpoch(090) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  162.013  0.0  14.623\n",
      "*****\n",
      " Epoch 91 of 100\n",
      "TrEpoch(091) - 2- True False\n",
      "cre tensor(2.9859, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.985863447189331\n",
      "\n",
      "     acc      bmx  bmn     mse      spr       run\n",
      "0  10.0  163.961  0.0  87.137  5598.47  5685.607\n",
      "ValEpoch(091) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  154.891  0.0  14.646\n",
      "*****\n",
      " Epoch 92 of 100\n",
      "TrEpoch(092) - \n",
      "     acc      bmx  bmn    mse       spr       run\n",
      "0  10.0  161.741  0.0  87.42  5598.465  5685.886\n",
      "ValEpoch(092) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  154.403  0.0  15.214\n",
      "*****\n",
      " Epoch 93 of 100\n",
      "TrEpoch(093) - \n",
      "     acc      bmx  bmn    mse       spr       run\n",
      "0  10.0  168.616  0.0  86.78  5598.476  5685.256\n",
      "ValEpoch(093) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  168.615  0.0  14.574\n",
      "*****\n",
      " Epoch 94 of 100\n",
      "TrEpoch(094) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  171.678  0.0  87.222  5598.466  5685.687\n",
      "ValEpoch(094) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  161.485  0.0  14.555\n",
      "*****\n",
      " Epoch 95 of 100\n",
      "TrEpoch(095) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  162.662  0.0  86.746  5598.467  5685.213\n",
      "ValEpoch(095) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  155.409  0.0  14.662\n",
      "*****\n",
      " Epoch 96 of 100\n",
      "TrEpoch(096) - 2- True False\n",
      "cre tensor(2.9858, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.9858462810516357\n",
      "\n",
      "     acc      bmx  bmn    mse       spr       run\n",
      "0  10.0  157.995  0.0  86.96  5598.473  5685.434\n",
      "ValEpoch(096) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  153.93  0.0  14.546\n",
      "*****\n",
      " Epoch 97 of 100\n",
      "TrEpoch(097) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  164.692  0.0  86.675  5598.467  5685.143\n",
      "ValEpoch(097) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  157.669  0.0  14.547\n",
      "*****\n",
      " Epoch 98 of 100\n",
      "TrEpoch(098) - \n",
      "     acc      bmx  bmn     mse       spr       run\n",
      "0  10.0  163.646  0.0  86.481  5598.464  5684.944\n",
      "ValEpoch(098) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  160.658  0.0  14.459\n",
      "*****\n",
      " Epoch 99 of 100\n",
      "TrEpoch(099) - \n",
      "     acc     bmx  bmn     mse       spr       run\n",
      "0  10.0  156.45  0.0  85.852  5598.461  5684.313\n",
      "ValEpoch(099) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  155.132  0.0  14.468\n",
      "4.21e+02 minutes\n"
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_ws :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"APPLY_LOG_SOFTMAX : \", APPLY_LOG_SOFTMAX)\n",
    "print(\"APPLY_SPARSITY_TO : \", APPLY_SPARSITY_TO)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param(\"+ str(reg_param) +\") * sp_loss\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       acc      bmx  bmn      mse       spr       run\n",
      "0   10.000  102.452  0.0  194.376  5623.894  5818.270\n",
      "1   10.000  202.163  0.0  166.368  5598.558  5764.926\n",
      "2   10.000  233.377  0.0  147.307  5598.500  5745.807\n",
      "3   10.000  196.937  0.0  138.410  5598.480  5736.890\n",
      "4   10.000  151.130  0.0  132.619  5598.471  5731.091\n",
      "5   10.000  138.199  0.0  129.156  5598.450  5727.606\n",
      "6   10.000  133.038  0.0  125.683  5598.444  5724.127\n",
      "7   10.000  129.645  0.0  124.163  5598.441  5722.604\n",
      "8   10.000  128.514  0.0  121.373  5598.448  5719.821\n",
      "9   10.000  134.024  0.0  119.090  5598.451  5717.540\n",
      "10  10.000  136.412  0.0  116.736  5598.457  5715.192\n",
      "11  10.000  141.398  0.0  115.188  5598.464  5713.652\n",
      "12  10.000  149.386  0.0  114.342  5598.470  5712.812\n",
      "13  10.000  145.646  0.0  113.556  5598.465  5712.021\n",
      "14  10.000  148.594  0.0  111.740  5598.466  5710.206\n",
      "15  10.000  150.574  0.0  111.245  5598.459  5709.703\n",
      "16  10.000  151.347  0.0  110.698  5598.468  5709.166\n",
      "17  10.000  153.411  0.0  110.344  5598.464  5708.808\n",
      "18  10.000  151.565  0.0  110.030  5598.461  5708.491\n",
      "19  10.000  159.134  0.0  109.250  5598.462  5707.712\n",
      "20  10.000  156.580  0.0  107.732  5598.461  5706.193\n",
      "21  10.000  157.052  0.0  107.064  5598.457  5705.521\n",
      "22  10.000  160.640  0.0  106.590  5598.462  5705.052\n",
      "23  10.000  161.945  0.0  106.252  5598.460  5704.712\n",
      "24  10.000  168.180  0.0  105.803  5598.460  5704.263\n",
      "25  10.000  165.412  0.0  104.753  5598.460  5703.213\n",
      "26  10.000  164.417  0.0  103.856  5598.462  5702.318\n",
      "27  10.000  165.529  0.0  103.367  5598.465  5701.832\n",
      "28  10.000  170.347  0.0  102.161  5598.466  5700.627\n",
      "29  10.000  169.015  0.0  101.243  5598.462  5699.705\n",
      "30  10.000  172.156  0.0  101.002  5598.463  5699.465\n",
      "31  10.000  173.476  0.0  100.076  5598.464  5698.540\n",
      "32  10.000  176.425  0.0   99.603  5598.462  5698.065\n",
      "33  10.000  178.944  0.0   99.387  5598.461  5697.848\n",
      "34  10.000  181.443  0.0   98.998  5598.462  5697.461\n",
      "35  10.000  175.851  0.0   99.030  5598.460  5697.489\n",
      "36  10.000  175.904  0.0   98.690  5598.464  5697.153\n",
      "37  10.000  178.953  0.0   98.256  5598.467  5696.723\n",
      "38  10.000  179.854  0.0   98.103  5598.458  5696.562\n",
      "39  10.000  177.496  0.0   97.961  5598.463  5696.424\n",
      "40  10.000  188.320  0.0   97.796  5598.465  5696.261\n",
      "41  10.002  184.230  0.0   97.659  5598.467  5696.125\n",
      "42  10.000  184.975  0.0   97.527  5598.467  5695.994\n",
      "43  10.000  185.355  0.0   96.902  5598.459  5695.361\n",
      "44  10.000  183.322  0.0   96.169  5598.458  5694.626\n",
      "45  10.000  180.590  0.0   96.012  5598.462  5694.474\n",
      "46  10.000  184.034  0.0   95.813  5598.456  5694.269\n",
      "47  10.000  183.676  0.0   95.552  5598.456  5694.009\n",
      "48  10.000  184.725  0.0   95.456  5598.456  5693.912\n",
      "49  10.000  184.787  0.0   95.408  5598.447  5693.854\n",
      "50  10.000  183.880  0.0   95.352  5598.454  5693.805\n",
      "51  10.000  178.783  0.0   94.882  5598.471  5693.353\n",
      "52  10.000  183.136  0.0   94.644  5598.460  5693.104\n",
      "53  10.000  188.337  0.0   94.576  5598.465  5693.041\n",
      "54  10.000  189.615  0.0   94.624  5598.465  5693.090\n",
      "55  10.000  183.034  0.0   94.156  5598.460  5692.616\n",
      "56  10.000  187.579  0.0   93.721  5598.460  5692.181\n",
      "57  10.000  186.129  0.0   93.443  5598.466  5691.909\n",
      "58  10.000  188.158  0.0   93.426  5598.456  5691.881\n",
      "59  10.000  182.507  0.0   92.633  5598.461  5691.094\n",
      "60  10.000  182.883  0.0   92.262  5598.457  5690.719\n",
      "61  10.000  178.465  0.0   92.337  5598.455  5690.792\n",
      "62  10.000  186.808  0.0   92.354  5598.457  5690.812\n",
      "63  10.000  185.020  0.0   92.171  5598.463  5690.634\n",
      "64  10.000  177.363  0.0   91.925  5598.457  5690.382\n",
      "65  10.000  184.562  0.0   91.696  5598.454  5690.150\n",
      "66  10.000  179.464  0.0   92.206  5598.456  5690.662\n",
      "67  10.000  180.001  0.0   91.890  5598.468  5690.358\n",
      "68  10.000  183.253  0.0   91.510  5598.462  5689.972\n",
      "69  10.000  176.196  0.0   91.461  5598.468  5689.929\n",
      "70  10.000  176.097  0.0   92.021  5598.454  5690.475\n",
      "71  10.000  179.619  0.0   91.625  5598.461  5690.085\n",
      "72  10.000  179.656  0.0   91.229  5598.476  5689.705\n",
      "73  10.000  170.499  0.0   90.414  5598.469  5688.884\n",
      "74  10.000  175.726  0.0   90.275  5598.466  5688.741\n",
      "75  10.000  181.017  0.0   90.373  5598.467  5688.840\n",
      "76  10.000  179.777  0.0   89.694  5598.465  5688.159\n",
      "77  10.000  168.194  0.0   90.070  5598.450  5688.521\n",
      "78  10.000  168.682  0.0   89.478  5598.463  5687.940\n",
      "79  10.000  179.976  0.0   89.573  5598.465  5688.039\n",
      "80  10.000  174.050  0.0   89.239  5598.462  5687.701\n",
      "81  10.000  174.605  0.0   89.908  5598.477  5688.384\n",
      "82  10.000  180.092  0.0   89.318  5598.470  5687.788\n",
      "83  10.000  168.885  0.0   89.190  5598.465  5687.655\n",
      "84  10.000  166.419  0.0   88.756  5598.460  5687.216\n",
      "85  10.000  166.225  0.0   88.791  5598.456  5687.247\n",
      "86  10.000  167.451  0.0   88.181  5598.457  5686.637\n",
      "87  10.000  169.928  0.0   88.590  5598.445  5687.035\n",
      "88  10.000  165.255  0.0   88.422  5598.443  5686.864\n",
      "89  10.000  164.337  0.0   87.853  5598.447  5686.301\n",
      "90  10.000  167.077  0.0   87.702  5598.456  5686.158\n",
      "91  10.000  163.961  0.0   87.137  5598.470  5685.607\n",
      "92  10.000  161.741  0.0   87.420  5598.465  5685.886\n",
      "93  10.000  168.616  0.0   86.780  5598.476  5685.256\n",
      "94  10.000  171.678  0.0   87.222  5598.466  5685.687\n",
      "95  10.000  162.662  0.0   86.746  5598.467  5685.213\n",
      "96  10.000  157.995  0.0   86.960  5598.473  5685.434\n",
      "97  10.000  164.692  0.0   86.675  5598.467  5685.143\n",
      "98  10.000  163.646  0.0   86.481  5598.464  5684.944\n",
      "99  10.000  156.450  0.0   85.852  5598.461  5684.313\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc      bmx  bmn     run\n",
      "0   10.0  101.685  0.0  29.514\n",
      "1   10.0  199.356  0.0  25.309\n",
      "2   10.0  196.136  0.0  23.884\n",
      "3   10.0  159.821  0.0  22.418\n",
      "4   10.0  136.787  0.0  21.826\n",
      "5   10.0  131.652  0.0  21.390\n",
      "6   10.0  123.893  0.0  20.822\n",
      "7   10.0  122.864  0.0  20.554\n",
      "8   10.0  121.303  0.0  20.028\n",
      "9   10.0  130.614  0.0  19.647\n",
      "10  10.0  132.433  0.0  19.455\n",
      "11  10.0  133.137  0.0  19.121\n",
      "12  10.0  140.881  0.0  19.069\n",
      "13  10.0  141.923  0.0  18.950\n",
      "14  10.0  139.418  0.0  18.632\n",
      "15  10.0  145.865  0.0  18.619\n",
      "16  10.0  147.173  0.0  18.531\n",
      "17  10.0  146.336  0.0  18.452\n",
      "18  10.0  150.904  0.0  18.557\n",
      "19  10.0  148.644  0.0  18.195\n",
      "20  10.0  149.843  0.0  18.041\n",
      "21  10.0  156.024  0.0  17.985\n",
      "22  10.0  156.929  0.0  17.867\n",
      "23  10.0  161.137  0.0  17.922\n",
      "24  10.0  160.408  0.0  17.665\n",
      "25  10.0  162.972  0.0  17.466\n",
      "26  10.0  167.821  0.0  17.425\n",
      "27  10.0  168.761  0.0  17.674\n",
      "28  10.0  168.776  0.0  17.132\n",
      "29  10.0  171.114  0.0  17.129\n",
      "30  10.0  169.675  0.0  17.026\n",
      "31  10.0  170.127  0.0  16.822\n",
      "32  10.0  179.747  0.0  16.808\n",
      "33  10.0  183.762  0.0  16.818\n",
      "34  10.0  172.188  0.0  16.912\n",
      "35  10.0  183.720  0.0  16.697\n",
      "36  10.0  175.192  0.0  16.728\n",
      "37  10.0  181.116  0.0  16.636\n",
      "38  10.0  183.952  0.0  16.481\n",
      "39  10.0  173.393  0.0  16.906\n",
      "40  10.0  183.885  0.0  16.723\n",
      "41  10.0  189.939  0.0  16.609\n",
      "42  10.0  182.575  0.0  16.594\n",
      "43  10.0  187.742  0.0  16.241\n",
      "44  10.0  179.773  0.0  16.259\n",
      "45  10.0  186.561  0.0  16.201\n",
      "46  10.0  188.702  0.0  16.159\n",
      "47  10.0  186.369  0.0  16.148\n",
      "48  10.0  191.570  0.0  16.174\n",
      "49  10.0  184.935  0.0  16.178\n",
      "50  10.0  180.879  0.0  16.181\n",
      "51  10.0  186.572  0.0  15.964\n",
      "52  10.0  194.430  0.0  16.067\n",
      "53  10.0  190.167  0.0  16.062\n",
      "54  10.0  181.762  0.0  16.008\n",
      "55  10.0  188.411  0.0  15.977\n",
      "56  10.0  189.995  0.0  15.750\n",
      "57  10.0  180.921  0.0  15.939\n",
      "58  10.0  185.432  0.0  15.945\n",
      "59  10.0  183.371  0.0  15.765\n",
      "60  10.0  182.040  0.0  16.028\n",
      "61  10.0  182.032  0.0  15.608\n",
      "62  10.0  186.507  0.0  15.567\n",
      "63  10.0  181.209  0.0  15.647\n",
      "64  10.0  180.440  0.0  16.452\n",
      "65  10.0  179.097  0.0  15.674\n",
      "66  10.0  174.524  0.0  15.633\n",
      "67  10.0  176.593  0.0  15.406\n",
      "68  10.0  176.042  0.0  15.467\n",
      "69  10.0  174.538  0.0  15.331\n",
      "70  10.0  187.011  0.0  15.769\n",
      "71  10.0  177.775  0.0  15.314\n",
      "72  10.0  175.861  0.0  15.147\n",
      "73  10.0  164.065  0.0  15.159\n",
      "74  10.0  171.261  0.0  15.223\n",
      "75  10.0  178.913  0.0  15.092\n",
      "76  10.0  175.892  0.0  15.169\n",
      "77  10.0  169.865  0.0  15.134\n",
      "78  10.0  163.645  0.0  14.972\n",
      "79  10.0  163.918  0.0  15.247\n",
      "80  10.0  169.118  0.0  15.000\n",
      "81  10.0  162.725  0.0  15.198\n",
      "82  10.0  168.617  0.0  15.242\n",
      "83  10.0  164.949  0.0  15.145\n",
      "84  10.0  160.767  0.0  14.896\n",
      "85  10.0  161.890  0.0  14.929\n",
      "86  10.0  166.967  0.0  14.884\n",
      "87  10.0  159.098  0.0  14.850\n",
      "88  10.0  163.307  0.0  14.826\n",
      "89  10.0  162.482  0.0  14.644\n",
      "90  10.0  162.013  0.0  14.623\n",
      "91  10.0  154.891  0.0  14.646\n",
      "92  10.0  154.403  0.0  15.214\n",
      "93  10.0  168.615  0.0  14.574\n",
      "94  10.0  161.485  0.0  14.555\n",
      "95  10.0  155.409  0.0  14.662\n",
      "96  10.0  153.930  0.0  14.546\n",
      "97  10.0  157.669  0.0  14.547\n",
      "98  10.0  160.658  0.0  14.459\n",
      "99  10.0  155.132  0.0  14.468\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tr acc =  10.001666666666667\n",
      "Max va acc =  10.0\n"
     ]
    }
   ],
   "source": [
    "tr_acc = result_df_tr_all.values[:,0].squeeze()\n",
    "va_acc = result_df_va_all.values[:,0].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_acc, color='orange', label='train acc')\n",
    "plt.plot(va_acc, color='red', label='validataion acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Max tr acc = \", np.max(tr_acc))\n",
    "print(\"Max va acc = \", np.max(va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_mse = result_df_tr_all.values[:,3].squeeze()\n",
    "tr_spr_50 = 100*result_df_tr_all.values[:,4].squeeze()\n",
    "va_err = 5*result_df_va_all.values[:,-1].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_mse, color='orange', label='train mse')\n",
    "plt.plot(tr_spr_50, color='red', label='tr spr*100')\n",
    "plt.plot(va_err, color='blue', label='va_err*5')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
