{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib as impL\n",
    "sys.path.insert(1,'/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/vae_torch')\n",
    "sys.path.insert(1,'/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery')\n",
    "import vae_torch_model as vtm\n",
    "import vae_torch as vt\n",
    "#from data_classes import khs_dataset_v2\n",
    "import vae_scripts as vs\n",
    "import sae_torch as st\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import vae_utils as vu\n",
    "import pandas as pd\n",
    "import helperFuncs as funcH\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_err(experiments_folder, exp_base_name,cf_int,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=1):\n",
    "    ae_fold_name = os.path.join(experiments_folder, exp_base_name + str(cf_int).zfill(z_fill_int))\n",
    "    ae_f_name = os.path.join(ae_fold_name, ae_f_name_base)\n",
    "    vfz = np.load(ae_f_name, allow_pickle=True)\n",
    "    loss_log_dict = {}\n",
    "    n = 0\n",
    "    loss_log_dict[data_log_key] = vfz.item().get(data_log_key)\n",
    "    if loss_log_dict[data_log_key] is None:\n",
    "        print(\"cf(\"+str(cf_int)+\") --> loss_log_dict\"+str(data_log_key)+\"] is none\")\n",
    "        return None, None, None\n",
    "    n = len(loss_log_dict[data_log_key])\n",
    "    if verbose>0:\n",
    "        print(str(cf_int), ', ', data_log_key, \" - log is loaded with len: \", n)\n",
    "    if loss_key not in loss_log_dict[data_log_key][0].keys():\n",
    "        return n, None, None\n",
    "\n",
    "    if loss_key in loss_log_dict[data_log_key][0]:\n",
    "        vec_len = len(loss_log_dict[data_log_key])\n",
    "        los_vec_cur = [loss_log_dict[data_log_key][l][loss_key] for l in range(0, vec_len)]\n",
    "        label_str = str(cf_int) + '_' + data_log_key + '_' + loss_key\n",
    "        if verbose>0:\n",
    "            print(label_str, los_vec_cur[-3:], \"\\nmax({:4.2f}),min({:4.2f})\".format(np.max(los_vec_cur), np.min(los_vec_cur)))\n",
    "        return n, np.min(los_vec_cur), np.max(los_vec_cur)\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "impL.reload(vu)\n",
    "experiments_folder='/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/FM/'\n",
    "config_folder = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/configs/'\n",
    "z_fill_int=2\n",
    "loss_key='reconstruction' # sparsity, bottleneck_kmeans, bottleneck_act\n",
    "data_log_keys=['tr_te']  # ['tr_va', 'va', 'te']\n",
    "exp_base_name='exp_conv_ae_simple_is28_cf'\n",
    "ae_f_name_base='ae_ft_conv_ae_simple_is28.npy'\n",
    "cf_int_arr=[201,202,203,204,205,206,207,208,209,210,211,212,213,214,216,217,218]\n",
    "#cf_int_arr=[201,204,205,207,213,214]\n",
    "#cf_int_arr=[201,204,205,216,217,218]\n",
    "df1 = pd.DataFrame(index=cf_int_arr, columns=['spMethod','spW','spR','kl_div','bact','lact','rcErr','lr','rcRed'])\n",
    "df2 = pd.DataFrame(index=cf_int_arr, columns=['n','bActMin','bActMax','bErrMin','bErrMax','kmMin','kmMax','rErrMax','rErrMin'])\n",
    "df3 = pd.DataFrame(index=cf_int_arr, columns=['n','bActMin','bActMax','bErrMin','bErrMax','kmMin','kmMax','rErrMax','rErrMin'])\n",
    "for i in range(0,len(cf_int_arr)):\n",
    "    cf = cf_int_arr[i]\n",
    "    #load model yaml as config\n",
    "    config_file = os.path.join(config_folder, 'conf_autoencoder_'+str(cf)+'.yaml')\n",
    "    CONF_PARAMS_ = funcH.CustomConfigParser(config_file=config_file)\n",
    "    df1.iloc[i]['spW'] = float(CONF_PARAMS_.MODEL.SPARSITY_WEIGHT)\n",
    "    if df1.iloc[i]['spW'] > 0:\n",
    "        df1.iloc[i]['spMethod'] = CONF_PARAMS_.MODEL.SPARSITY_ERROR\n",
    "        df1.iloc[i]['spR'] = CONF_PARAMS_.MODEL.SPARSITY_REDUCTION\n",
    "    else:\n",
    "        df1.iloc[i]['spW'] = None\n",
    "    df1.iloc[i]['kl_div'] = CONF_PARAMS_.MODEL.KL_DIV_RHO if 'kl_' in str(CONF_PARAMS_.MODEL.SPARSITY_ERROR) else None\n",
    "    try:\n",
    "        df1.iloc[i]['bact'] = (CONF_PARAMS_.MODEL.LAYERS.encoder.l04_act).replace('type: ','').replace(',dim:','')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df1.iloc[i]['lact'] = CONF_PARAMS_.MODEL.LAYERS.decoder.l01_act.replace('type: ','')\n",
    "    except:\n",
    "        pass\n",
    "    df1.iloc[i]['rcErr'] = CONF_PARAMS_.MODEL.RECONSTRUCTION_ERROR_FUNCTION\n",
    "    df1.iloc[i]['lr'] = CONF_PARAMS_.MODEL.LEARNING_RATE\n",
    "    df1.iloc[i]['rcRed'] = CONF_PARAMS_.MODEL.RECONSTRUCTION_ERROR_REDUCTION\n",
    "    \n",
    "    \n",
    "    data_log_key = 'tr_te'\n",
    "    loss_key = 'reconstruction' # reconstruction bottleneck_kmeans bottleneck_act sparsity\n",
    "    n, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df2.iloc[i]['n'] = n\n",
    "\n",
    "    df2.iloc[i]['rErrMin'] = mn\n",
    "    df2.iloc[i]['rErrMax'] = mx\n",
    "    \n",
    "    loss_key = 'bottleneck_kmeans' # bottleneck_act sparsity\n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df2.iloc[i]['kmMin'] = mn\n",
    "    df2.iloc[i]['kmMax'] = mx\n",
    "    \n",
    "    loss_key = 'bottleneck_act' #  sparsity\n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df2.iloc[i]['bActMin'] = mn\n",
    "    df2.iloc[i]['bActMax'] = mx if mx!=mn else '_n*c_'\n",
    "\n",
    "    loss_key = 'sparsity' #  \n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df2.iloc[i]['bErrMin'] = mn\n",
    "    df2.iloc[i]['bErrMax'] = mx if mx!=mn else '_n*c_'\n",
    "\n",
    "    \n",
    "    data_log_key = 'te'\n",
    "    loss_key = 'reconstruction' # reconstruction bottleneck_kmeans bottleneck_act sparsity\n",
    "    n, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df3.iloc[i]['n'] = n\n",
    "\n",
    "    df3.iloc[i]['rErrMin'] = mn\n",
    "    df3.iloc[i]['rErrMax'] = mx\n",
    "    \n",
    "    loss_key = 'bottleneck_kmeans' # bottleneck_act sparsity\n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df3.iloc[i]['kmMin'] = mn\n",
    "    df3.iloc[i]['kmMax'] = mx\n",
    "    \n",
    "    loss_key = 'bottleneck_act' #  sparsity\n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df3.iloc[i]['bActMin'] = mn\n",
    "    df3.iloc[i]['bActMax'] = mx if mx!=mn else '_n*c_'\n",
    "\n",
    "    loss_key = 'sparsity' #  \n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df3.iloc[i]['bErrMin'] = mn\n",
    "    df3.iloc[i]['bErrMax'] = mx if mx!=mn else '_n*c_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments explanations\n",
      "          spMethod    spW        spR  kl_div      bact  lact rcErr     lr rcRed\n",
      "201  kl_divergence   0.01  batchmean  0.0001  Softmax1   NaN   MSE  0.001   sum\n",
      "202        l2_norm   0.01  batchmean    None  Softmax1   NaN   MSE  0.001  mean\n",
      "203        l2_norm  0.001        sum    None  Softmax1   NaN   MSE  0.001  mean\n",
      "204  kl_divergence    0.5  batchmean  0.0001  Softmax1   NaN   MSE  0.001   sum\n",
      "205  kl_divergence      1  batchmean  0.0001  Softmax1   NaN   MSE  0.001   sum\n",
      "206            NaN   None        NaN    None  Softmax1   NaN   MSE  0.001  mean\n",
      "207            NaN   None        NaN    None  Softmax1   NaN   MSE  0.001   sum\n",
      "208        l1_norm   0.01  batchmean    None  Softmax1   NaN   MSE  0.001  mean\n",
      "209        l1_norm  0.001        sum    None  Softmax1   NaN   MSE  0.001  mean\n",
      "210        l1_norm   0.01        sum    None  Softmax1  ReLu   MSE  0.001   sum\n",
      "211        l1_norm    0.1        sum    None  Softmax1   NaN   MSE  0.001   sum\n",
      "212        l1_norm    0.1        sum    None  Softmax1  ReLu   MSE  0.001   sum\n",
      "213  cross_entropy      1       mean    None  Softmax1   NaN   MSE  0.001   sum\n",
      "214  cross_entropy      1        sum    None  Softmax1  ReLu   MSE  0.001   sum\n",
      "216  kl_divergence   0.01        sum  0.0001  Softmax1   NaN   MSE  0.001   sum\n",
      "217  kl_divergence    0.5        sum  0.0001  Softmax1   NaN   MSE  0.001   sum\n",
      "218  kl_divergence      1        sum  0.0001  Softmax1   NaN   MSE  0.001   sum\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.precision\", 2)\n",
    "print('experiments explanations')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_te dataset results\n",
      "       n bActMin bActMax     bErrMin     bErrMax   kmMin   kmMax     rErrMax     rErrMin\n",
      "201  250  16.697  46.887      6.9583      6.9583  46.287  62.152  1.8807e+06  8.9107e+05\n",
      "202   40      10   _n*c_     -289.52     -267.11  11.765  22.537      56.502      55.369\n",
      "203   40      10   _n*c_     -4978.6     -4906.7  13.178  21.042      57.371      55.642\n",
      "204  250  19.207  42.842      6.9583      6.9583  44.825  61.883  1.8229e+06  8.8944e+05\n",
      "205  250  28.107  45.532      6.9583      6.9583  48.023  64.568  1.6562e+06   8.888e+05\n",
      "206   40  8.0833   16.98           0       _n*c_   10.63   22.81      46.839      43.638\n",
      "207  250  15.142   45.24           0       _n*c_  43.335   62.11  2.4229e+06  8.9924e+05\n",
      "208   40   9.485  16.185       -3750       -3750  11.773  23.595      46.368      43.822\n",
      "209   40      10   _n*c_      -60000      -60000      10      10      60.167      57.468\n",
      "210   30  16.877  35.882      -60000      -60000  46.003  57.813  7.3034e+06  7.0631e+06\n",
      "211   10  21.397   29.95      -60000      -60000  52.265  65.042   1.685e+06  1.0626e+06\n",
      "212   30  15.335   37.99      -60000      -60000  47.012   59.77  7.3494e+06  7.0643e+06\n",
      "213  250  19.925  35.175     -1271.8     -1190.1  47.475  63.332   1.665e+06  8.9279e+05\n",
      "214  250  21.888  39.252 -1.6442e+05 -1.5948e+05  45.542   59.32    7.26e+06  7.0392e+06\n",
      "216  100  22.805  40.332      890.19      890.19  45.428  60.737  1.8885e+06  9.1077e+05\n",
      "217  100   18.65  40.677      890.19      890.19  47.062  63.425  1.9052e+06  9.1737e+05\n",
      "218  100   20.47  40.223      890.19      890.19   47.11  59.418  2.1278e+06  9.2967e+05\n"
     ]
    }
   ],
   "source": [
    "print('tr_te dataset results')\n",
    "pd.set_option(\"display.precision\", 5)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te dataset results\n",
      "       n bActMin bActMax bErrMin bErrMax  kmMin  kmMax     rErrMax     rErrMin\n",
      "201  250   18.99   45.96  1.1721  1.1721  47.82  60.25  3.1283e+05  1.4921e+05\n",
      "202   40      10   _n*c_ -48.426 -44.676  13.06  24.84      9.4758      9.2852\n",
      "203   40      10   _n*c_ -832.51 -820.54  10.58  21.72      9.6214      9.3313\n",
      "204  250   19.77      43  1.1721  1.1721  45.65  61.96   3.029e+05  1.4916e+05\n",
      "205  250   25.17   43.88  1.1721  1.1721  46.55  64.12  2.7542e+05  1.4902e+05\n",
      "206   40    9.89   17.06       0   _n*c_  11.98  21.89      7.8565      7.3202\n",
      "207  250   15.52   45.08       0   _n*c_  41.79  63.85   4.027e+05  1.5055e+05\n",
      "208   40    3.83   16.52    -625    -625  11.41  21.79      7.7772      7.3505\n",
      "209   40      10   _n*c_  -10000  -10000     10     10      10.092      9.6372\n",
      "210   30   15.37   36.31  -10000  -10000  46.28  59.06   1.212e+06  1.1726e+06\n",
      "211   10   23.37    28.4  -10000  -10000  53.17  62.93  2.8019e+05  1.7751e+05\n",
      "212   30   16.45   37.18  -10000  -10000  39.69  54.19  1.2195e+06  1.1726e+06\n",
      "213  250   22.59   36.03 -214.26 -200.49  48.78  62.69  2.7695e+05  1.4959e+05\n",
      "214  250   23.54   38.47  -27404  -26587   44.3  57.75   1.205e+06  1.1687e+06\n",
      "216  100   22.34   37.46  148.37  148.37  46.97  62.24  3.1427e+05  1.5271e+05\n",
      "217  100   26.75   36.92  148.37  148.37  47.66  62.69  3.1689e+05  1.5352e+05\n",
      "218  100   19.22   41.43  148.37  148.37  45.23  60.61  3.5359e+05  1.5579e+05\n"
     ]
    }
   ],
   "source": [
    "print('te dataset results')\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
