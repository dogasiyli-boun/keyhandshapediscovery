{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib as impL\n",
    "sys.path.insert(1,'/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/vae_torch')\n",
    "sys.path.insert(1,'/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery')\n",
    "import vae_torch_model as vtm\n",
    "import vae_torch as vt\n",
    "#from data_classes import khs_dataset_v2\n",
    "import vae_scripts as vs\n",
    "import sae_torch as st\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import vae_utils as vu\n",
    "import pandas as pd\n",
    "import helperFuncs as funcH\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_err(experiments_folder, exp_base_name,cf_int,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=1):\n",
    "    ae_fold_name = os.path.join(experiments_folder, exp_base_name + str(cf_int).zfill(z_fill_int))\n",
    "    ae_f_name = os.path.join(ae_fold_name, ae_f_name_base)\n",
    "    vfz = np.load(ae_f_name, allow_pickle=True)\n",
    "    loss_log_dict = {}\n",
    "    n = 0\n",
    "    loss_log_dict[data_log_key] = vfz.item().get(data_log_key)\n",
    "    if loss_log_dict[data_log_key] is None:\n",
    "        print(\"cf(\"+str(cf_int)+\") --> loss_log_dict\"+str(data_log_key)+\"] is none\")\n",
    "        return None, None, None\n",
    "    n = len(loss_log_dict[data_log_key])\n",
    "    if verbose>0:\n",
    "        print(str(cf_int), ', ', data_log_key, \" - log is loaded with len: \", n)\n",
    "    if loss_key not in loss_log_dict[data_log_key][0].keys():\n",
    "        return n, None, None\n",
    "\n",
    "    if loss_key in loss_log_dict[data_log_key][0]:\n",
    "        vec_len = len(loss_log_dict[data_log_key])\n",
    "        los_vec_cur = [loss_log_dict[data_log_key][l][loss_key] for l in range(0, vec_len)]\n",
    "        label_str = str(cf_int) + '_' + data_log_key + '_' + loss_key\n",
    "        if verbose>0:\n",
    "            print(label_str, los_vec_cur[-3:], \"\\nmax({:4.2f}),min({:4.2f})\".format(np.max(los_vec_cur), np.min(los_vec_cur)))\n",
    "        return n, np.min(los_vec_cur), np.max(los_vec_cur)\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impL.reload(vu)\n",
    "experiments_folder='/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/FM/'\n",
    "config_folder = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/configs/'\n",
    "z_fill_int=2\n",
    "loss_key='reconstruction' # sparsity, bottleneck_kmeans, bottleneck_act\n",
    "data_log_keys=['tr_te']  # ['tr_va', 'va', 'te']\n",
    "exp_base_name='exp_conv_ae_simple_is28_cf'\n",
    "ae_f_name_base='ae_ft_conv_ae_simple_is28.npy'\n",
    "cf_int_arr=[201,202,203,204,205,206,207,208,209,210,211,212,213,214,216,217,218]\n",
    "#cf_int_arr=[201,204,205,207,213,214]\n",
    "#cf_int_arr=[201,204,205,216,217,218]\n",
    "df1 = pd.DataFrame(index=cf_int_arr, columns=['spMethod','spW','spR','kl_div','bact','lact','rcErr','lr','rcRed'])\n",
    "df2 = pd.DataFrame(index=cf_int_arr, columns=['n','bActMin','bActMax','bErrMin','bErrMax','kmMin','kmMax','rErrMax','rErrMin'])\n",
    "df3 = pd.DataFrame(index=cf_int_arr, columns=['n','bActMin','bActMax','bErrMin','bErrMax','kmMin','kmMax','rErrMax','rErrMin'])\n",
    "for i in range(0,len(cf_int_arr)):\n",
    "    cf = cf_int_arr[i]\n",
    "    #load model yaml as config\n",
    "    config_file = os.path.join(config_folder, 'conf_autoencoder_'+str(cf)+'.yaml')\n",
    "    CONF_PARAMS_ = funcH.CustomConfigParser(config_file=config_file)\n",
    "    df1.iloc[i]['spW'] = float(CONF_PARAMS_.MODEL.SPARSITY_WEIGHT)\n",
    "    if df1.iloc[i]['spW'] > 0:\n",
    "        df1.iloc[i]['spMethod'] = CONF_PARAMS_.MODEL.SPARSITY_ERROR\n",
    "        df1.iloc[i]['spR'] = CONF_PARAMS_.MODEL.SPARSITY_REDUCTION\n",
    "    else:\n",
    "        df1.iloc[i]['spW'] = None\n",
    "    df1.iloc[i]['kl_div'] = CONF_PARAMS_.MODEL.KL_DIV_RHO if 'kl_' in str(CONF_PARAMS_.MODEL.SPARSITY_ERROR) else None\n",
    "    try:\n",
    "        df1.iloc[i]['bact'] = (CONF_PARAMS_.MODEL.LAYERS.encoder.l04_act).replace('type: ','').replace(',dim:','')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df1.iloc[i]['lact'] = CONF_PARAMS_.MODEL.LAYERS.decoder.l01_act.replace('type: ','')\n",
    "    except:\n",
    "        pass\n",
    "    df1.iloc[i]['rcErr'] = CONF_PARAMS_.MODEL.RECONSTRUCTION_ERROR_FUNCTION\n",
    "    df1.iloc[i]['lr'] = CONF_PARAMS_.MODEL.LEARNING_RATE\n",
    "    df1.iloc[i]['rcRed'] = CONF_PARAMS_.MODEL.RECONSTRUCTION_ERROR_REDUCTION\n",
    "    \n",
    "    \n",
    "    data_log_key = 'tr_te'\n",
    "    loss_key = 'reconstruction' # reconstruction bottleneck_kmeans bottleneck_act sparsity\n",
    "    n, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df2.iloc[i]['n'] = n\n",
    "\n",
    "    df2.iloc[i]['rErrMin'] = mn\n",
    "    df2.iloc[i]['rErrMax'] = mx\n",
    "    \n",
    "    loss_key = 'bottleneck_kmeans' # bottleneck_act sparsity\n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df2.iloc[i]['kmMin'] = mn\n",
    "    df2.iloc[i]['kmMax'] = mx\n",
    "    \n",
    "    loss_key = 'bottleneck_act' #  sparsity\n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df2.iloc[i]['bActMin'] = mn\n",
    "    df2.iloc[i]['bActMax'] = mx if mx!=mn else '_n*c_'\n",
    "\n",
    "    loss_key = 'sparsity' #  \n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df2.iloc[i]['bErrMin'] = mn\n",
    "    df2.iloc[i]['bErrMax'] = mx if mx!=mn else '_n*c_'\n",
    "\n",
    "    \n",
    "    data_log_key = 'te'\n",
    "    loss_key = 'reconstruction' # reconstruction bottleneck_kmeans bottleneck_act sparsity\n",
    "    n, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df3.iloc[i]['n'] = n\n",
    "\n",
    "    df3.iloc[i]['rErrMin'] = mn\n",
    "    df3.iloc[i]['rErrMax'] = mx\n",
    "    \n",
    "    loss_key = 'bottleneck_kmeans' # bottleneck_act sparsity\n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df3.iloc[i]['kmMin'] = mn\n",
    "    df3.iloc[i]['kmMax'] = mx\n",
    "    \n",
    "    loss_key = 'bottleneck_act' #  sparsity\n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df3.iloc[i]['bActMin'] = mn\n",
    "    df3.iloc[i]['bActMax'] = mx if mx!=mn else '_n*c_'\n",
    "\n",
    "    loss_key = 'sparsity' #  \n",
    "    _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "    df3.iloc[i]['bErrMin'] = mn\n",
    "    df3.iloc[i]['bErrMax'] = mx if mx!=mn else '_n*c_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 2)\n",
    "print('experiments explanations')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tr_te dataset results')\n",
    "pd.set_option(\"display.precision\", 5)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('te dataset results')\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
