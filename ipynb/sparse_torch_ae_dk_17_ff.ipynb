{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:  1.1.0\n",
      "torch:  1.6.0\n",
      "numpy:  1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "import pandas as pd\n",
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"torch: \", torch.__version__)\n",
    "print(\"numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsubuntu_khs_dir = /home/wsubuntu/GitHub/keyhandshapediscovery\n",
      "wsubuntu_data_path = /mnt/SSD_Data/DataPath\n",
      "wsubuntu_experiment_path = /mnt/SSD_Data/vaesae_experiments\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "def get_var_by_comp_name(variableName):\n",
    "    curCompName = socket.gethostname()\n",
    "    retVal = None\n",
    "    if variableName == 'khs_dir':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/home/wsubuntu/GitHub/keyhandshapediscovery'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'data_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/Datasets'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/mnt/SSD_Data/DataPath'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'experiment_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/SPARSE_TORCH'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/mnt/SSD_Data/vaesae_experiments'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "        \n",
    "    print(curCompName + '_' + variableName, '=',  retVal)\n",
    "    if retVal is None:\n",
    "        os.error(5)\n",
    "    return retVal\n",
    "\n",
    "khs_dir = get_var_by_comp_name('khs_dir')\n",
    "data_path = get_var_by_comp_name('data_path')\n",
    "experiment_path = get_var_by_comp_name('experiment_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, khs_dir)\n",
    "import helperFuncs as funcH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 17\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'batchmean','sum'\n",
    "SIGMOID_ACT=False\n",
    "APPLY_LOG_SOFTMAX=False\n",
    "MSE_PLUS_MINUS='+'\n",
    "APPLY_SPARSITY_TO='bottleneck' #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 100  # args['epochs']\n",
    "reg_param = 0.1  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": data_path,\n",
    "    \"experiment\": os.path.join(experiment_path, 'sparse_torch_ae_' + str(EXPERIMENT_ID).zfill(3)),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseAutoencoder - loss_type(cre), device(cpu)\n"
     ]
    }
   ],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=32)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    "        print(\"SparseAutoencoder - loss_type(\" + loss_type +\"), device(\" + self.device + \")\")\n",
    "\n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        if self.loss_type=='cre':\n",
    "            bottleneck = self.enc5(x) \n",
    "        else:\n",
    "            bottleneck = F.relu(self.enc5(x))  \n",
    "        \n",
    "        return bottleneck\n",
    "        \n",
    "    def decode(self, bottleneck):\n",
    "        # decoding\n",
    "        if self.loss_type=='cre':\n",
    "            x = F.relu(self.dec1(F.relu(bottleneck)))\n",
    "        else:\n",
    "            x = F.relu(self.dec1(bottleneck))\n",
    "        \n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x)) \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encode(x)\n",
    "        x = self.decode(bottleneck)\n",
    "        return x, bottleneck\n",
    "\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    rho_val = 1/bt.size(1)\n",
    "    rho_mat = torch.tensor([rho_val] * np.ones(bt.size()), dtype=torch.float32).to(device)\n",
    "    #https://discuss.pytorch.org/t/kl-divergence-produces-negative-values/16791/13\n",
    "    #KLDLoss(p, q), sum(q) needs to equal one\n",
    "    #p = log_softmax(tensor)\n",
    "    loss_ret_1 = F.kl_div(F.log_softmax(bt, dim=1).to(device), rho_mat, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct and apply_log_softmax:  \n",
    "        if print_info:\n",
    "            print(\"1-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    elif sigmoidAct and not apply_log_softmax:     \n",
    "        if print_info:\n",
    "            print(\"2-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(bt.to(device), preds)    \n",
    "    elif not sigmoidAct and apply_log_softmax:\n",
    "        if print_info:\n",
    "            print(\"3-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bottleneck, dim=1).to(device), preds)    \n",
    "    else:#nothing\n",
    "        if print_info:\n",
    "            print(\"4-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(bottleneck.to(device), preds)\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy_old(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct:\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    else:\n",
    "        bt = bottleneck    \n",
    "    _, preds = torch.max(bt, 1)\n",
    "    loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss\n",
    "\n",
    "def sparse_loss_bottleneck(bottleneck, print_info, loss_type):\n",
    "    loss = 0\n",
    "    #if print_info:\n",
    "        #print(i, ' shape=', values.shape)\n",
    "    if loss_type=='l1':\n",
    "        loss += loss_l1(bottleneck)\n",
    "    if loss_type=='l2':\n",
    "        loss += loss_l2(bottleneck)\n",
    "    if loss_type=='kl':\n",
    "        loss += kl_divergence(bottleneck, reduction=LOSS_REDUCTION)\n",
    "    if loss_type=='cre':\n",
    "        loss += loss_crossentropy(bottleneck, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "    if print_info:\n",
    "        print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            if APPLY_SPARSITY_TO=='all':\n",
    "                sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            elif APPLY_SPARSITY_TO=='bottleneck': #all\n",
    "                sp_loss = sparse_loss_bottleneck(bottleneck, print_losses_fit, model.loss_type)\n",
    "            else:\n",
    "                os.exit(4)\n",
    "                \n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            \n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "                \n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_ws :: \n",
      "EXPERIMENT_ID:  17\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  False\n",
      "APPLY_LOG_SOFTMAX :  False\n",
      "APPLY_SPARSITY_TO :  bottleneck\n",
      "total loss = mse_loss + reg_param * sp_loss\n",
      "*****\n",
      " Epoch 0 of 100\n",
      "TrEpoch(000) - 4- False False\n",
      "cre tensor(3.2818, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.281771183013916\n",
      "\n",
      "     acc     bmx     bmn      mse      spr      run\n",
      "0  10.0  111.81 -66.466  186.436  201.117  206.548\n",
      "ValEpoch(000) - \n",
      "     acc      bmx    bmn     run\n",
      "0  10.0  111.866 -66.77  22.129\n",
      "*****\n",
      " Epoch 1 of 100\n",
      "TrEpoch(001) - \n",
      "     acc      bmx     bmn      mse    spr      run\n",
      "0  10.0  144.625 -86.706  117.777  0.076  117.785\n",
      "ValEpoch(001) - \n",
      "     acc      bmx    bmn     run\n",
      "0  10.0  142.954 -85.41  18.491\n",
      "*****\n",
      " Epoch 2 of 100\n",
      "TrEpoch(002) - \n",
      "     acc      bmx     bmn      mse    spr      run\n",
      "0  10.0  153.614 -92.646  108.076  0.031  108.079\n",
      "ValEpoch(002) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  150.288 -90.636  17.515\n",
      "*****\n",
      " Epoch 3 of 100\n",
      "TrEpoch(003) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  160.527 -94.638  98.818  0.011  98.819\n",
      "ValEpoch(003) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  159.542 -94.126  15.065\n",
      "*****\n",
      " Epoch 4 of 100\n",
      "TrEpoch(004) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  164.553 -97.294  86.417  0.005  86.418\n",
      "ValEpoch(004) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  158.953 -92.541  13.978\n",
      "*****\n",
      " Epoch 5 of 100\n",
      "TrEpoch(005) - \n",
      "     acc      bmx    bmn     mse    spr     run\n",
      "0  10.0  163.201 -95.99  82.665  0.003  82.665\n",
      "ValEpoch(005) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  158.562 -92.304  13.655\n",
      "*****\n",
      " Epoch 6 of 100\n",
      "TrEpoch(006) - 4- False False\n",
      "cre tensor(3.7253e-09, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.725290076417309e-09\n",
      "\n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  162.591 -95.972  80.915  0.003  80.915\n",
      "ValEpoch(006) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  157.933 -92.025  13.425\n",
      "*****\n",
      " Epoch 7 of 100\n",
      "TrEpoch(007) - \n",
      "     acc     bmx     bmn     mse    spr     run\n",
      "0  10.0  161.68 -95.383  79.295  0.002  79.295\n",
      "ValEpoch(007) - \n",
      "     acc      bmx     bmn   run\n",
      "0  10.0  157.629 -92.188  13.0\n",
      "*****\n",
      " Epoch 8 of 100\n",
      "TrEpoch(008) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  161.469 -95.902  75.611  0.002  75.611\n",
      "ValEpoch(008) - \n",
      "     acc      bmx    bmn     run\n",
      "0  10.0  156.318 -92.61  12.195\n",
      "*****\n",
      " Epoch 9 of 100\n",
      "TrEpoch(009) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  159.179 -96.607  72.203  0.003  72.204\n",
      "ValEpoch(009) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  156.067 -93.292  12.022\n",
      "*****\n",
      " Epoch 10 of 100\n",
      "TrEpoch(010) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  158.352 -96.627  71.156  0.003  71.157\n",
      "ValEpoch(010) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  152.801 -94.354  11.852\n",
      "*****\n",
      " Epoch 11 of 100\n",
      "TrEpoch(011) - 4- False False\n",
      "cre tensor(0., grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.0\n",
      "\n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  156.684 -99.634  70.501  0.004  70.501\n",
      "ValEpoch(011) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  150.773 -98.039  11.738\n",
      "*****\n",
      " Epoch 12 of 100\n",
      "TrEpoch(012) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  151.883 -104.74  68.612  0.005  68.612\n",
      "ValEpoch(012) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  147.374 -101.453  11.248\n",
      "*****\n",
      " Epoch 13 of 100\n",
      "TrEpoch(013) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  150.733 -107.312  66.312  0.007  66.313\n",
      "ValEpoch(013) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  146.121 -104.354  10.88\n",
      "*****\n",
      " Epoch 14 of 100\n",
      "TrEpoch(014) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  149.534 -110.327  63.786  0.008  63.787\n",
      "ValEpoch(014) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  146.726 -107.064  10.481\n",
      "*****\n",
      " Epoch 15 of 100\n",
      "TrEpoch(015) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  150.756 -113.515  62.105  0.008  62.106\n",
      "ValEpoch(015) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  146.076 -107.705  10.343\n",
      "*****\n",
      " Epoch 16 of 100\n",
      "TrEpoch(016) - 4- False False\n",
      "cre tensor(0., grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.0\n",
      "\n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  150.047 -113.331  61.328  0.007  61.329\n",
      "ValEpoch(016) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  146.025 -108.515  10.248\n",
      "*****\n",
      " Epoch 17 of 100\n",
      "TrEpoch(017) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  149.272 -112.595  60.268  0.007  60.269\n",
      "ValEpoch(017) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  143.974 -108.456  9.954\n",
      "*****\n",
      " Epoch 18 of 100\n",
      "TrEpoch(018) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  148.206 -113.665  58.695  0.007  58.695\n",
      "ValEpoch(018) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  143.832 -109.161  9.749\n",
      "*****\n",
      " Epoch 19 of 100\n",
      "TrEpoch(019) - \n",
      "     acc      bmx    bmn     mse    spr     run\n",
      "0  10.0  149.262 -114.4  57.173  0.007  57.174\n",
      "ValEpoch(019) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  145.194 -111.425  9.511\n",
      "*****\n",
      " Epoch 20 of 100\n",
      "TrEpoch(020) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  150.026 -116.228  56.405  0.006  56.406\n",
      "ValEpoch(020) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  144.094 -111.146  9.367\n",
      "*****\n",
      " Epoch 21 of 100\n",
      "TrEpoch(021) - 4- False False\n",
      "cre tensor(3.9784e-06, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.978385393565986e-06\n",
      "\n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  150.252 -117.14  55.439  0.007  55.439\n",
      "ValEpoch(021) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  143.676 -111.537  9.151\n",
      "*****\n",
      " Epoch 22 of 100\n",
      "TrEpoch(022) - \n",
      "     acc      bmx     bmn     mse    spr    run\n",
      "0  10.0  150.221 -118.45  54.169  0.007  54.17\n",
      "ValEpoch(022) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  143.615 -112.436  9.056\n",
      "*****\n",
      " Epoch 23 of 100\n",
      "TrEpoch(023) - \n",
      "     acc      bmx     bmn     mse    spr     run\n",
      "0  10.0  148.897 -118.38  53.179  0.007  53.179\n",
      "ValEpoch(023) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  142.665 -112.462  8.873\n",
      "*****\n",
      " Epoch 24 of 100\n",
      "TrEpoch(024) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  148.521 -120.166  51.398  0.008  51.399\n",
      "ValEpoch(024) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  142.478 -112.459  8.604\n",
      "*****\n",
      " Epoch 25 of 100\n",
      "TrEpoch(025) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  148.066 -118.902  50.867  0.008  50.868\n",
      "ValEpoch(025) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  141.389 -112.543  8.454\n",
      "*****\n",
      " Epoch 26 of 100\n",
      "TrEpoch(026) - 4- False False\n",
      "cre tensor(3.6135e-07, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.613510557443078e-07\n",
      "\n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  147.521 -120.118  50.007  0.008  50.008\n",
      "ValEpoch(026) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  139.483 -111.726  8.343\n",
      "*****\n",
      " Epoch 27 of 100\n",
      "TrEpoch(027) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  145.594 -120.645  49.091  0.008  49.092\n",
      "ValEpoch(027) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  138.547 -111.321  8.208\n",
      "*****\n",
      " Epoch 28 of 100\n",
      "TrEpoch(028) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  145.039 -119.119  48.627  0.008  48.628\n",
      "ValEpoch(028) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  137.812 -111.068  8.156\n",
      "*****\n",
      " Epoch 29 of 100\n",
      "TrEpoch(029) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  144.484 -119.105  48.154  0.008  48.155\n",
      "ValEpoch(029) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  136.937 -111.327  8.006\n",
      "*****\n",
      " Epoch 30 of 100\n",
      "TrEpoch(030) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  142.834 -118.969  46.883  0.008  46.884\n",
      "ValEpoch(030) - \n",
      "     acc      bmx      bmn   run\n",
      "0  10.0  136.106 -110.757  7.87\n",
      "*****\n",
      " Epoch 31 of 100\n",
      "TrEpoch(031) - 4- False False\n",
      "cre tensor(4.0978e-08, grad_fn=<AddBackward0>)\n",
      "sp_loss: 4.0978164861371624e-08\n",
      "\n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  142.623 -117.773  46.603  0.008  46.604\n",
      "ValEpoch(031) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  135.666 -110.932  7.821\n",
      "*****\n",
      " Epoch 32 of 100\n",
      "TrEpoch(032) - \n",
      "     acc     bmx      bmn     mse    spr     run\n",
      "0  10.0  140.05 -117.112  46.331  0.008  46.331\n",
      "ValEpoch(032) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  134.165 -110.212  7.746\n",
      "*****\n",
      " Epoch 33 of 100\n",
      "TrEpoch(033) - \n",
      "     acc      bmx      bmn     mse    spr    run\n",
      "0  10.0  139.327 -116.245  46.009  0.008  46.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValEpoch(033) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  132.844 -108.902  7.721\n",
      "*****\n",
      " Epoch 34 of 100\n",
      "TrEpoch(034) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  137.339 -115.116  45.378  0.008  45.379\n",
      "ValEpoch(034) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  132.689 -109.418  7.576\n",
      "*****\n",
      " Epoch 35 of 100\n",
      "TrEpoch(035) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  137.703 -115.683  44.831  0.008  44.832\n",
      "ValEpoch(035) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  132.322 -108.754  7.516\n",
      "*****\n",
      " Epoch 36 of 100\n",
      "TrEpoch(036) - 4- False False\n",
      "cre tensor(1.4387e-05, grad_fn=<AddBackward0>)\n",
      "sp_loss: 1.4387497685675044e-05\n",
      "\n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  135.639 -114.831  44.618  0.008  44.619\n",
      "ValEpoch(036) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  130.659 -108.413  7.507\n",
      "*****\n",
      " Epoch 37 of 100\n",
      "TrEpoch(037) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  134.771 -115.004  43.232  0.008  43.232\n",
      "ValEpoch(037) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  129.646 -109.71  7.216\n",
      "*****\n",
      " Epoch 38 of 100\n",
      "TrEpoch(038) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  133.812 -116.695  42.536  0.008  42.537\n",
      "ValEpoch(038) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  128.645 -110.054  7.113\n",
      "*****\n",
      " Epoch 39 of 100\n",
      "TrEpoch(039) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  134.267 -116.025  41.982  0.008  41.983\n",
      "ValEpoch(039) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  129.532 -110.064  7.042\n",
      "*****\n",
      " Epoch 40 of 100\n",
      "TrEpoch(040) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  133.688 -116.417  41.663  0.007  41.664\n",
      "ValEpoch(040) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  130.374 -110.281  7.029\n",
      "*****\n",
      " Epoch 41 of 100\n",
      "TrEpoch(041) - 4- False False\n",
      "cre tensor(7.6740e-07, grad_fn=<AddBackward0>)\n",
      "sp_loss: 7.674003654756234e-07\n",
      "\n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  133.522 -117.178  41.407  0.007  41.408\n",
      "ValEpoch(041) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  129.854 -109.719  6.948\n",
      "*****\n",
      " Epoch 42 of 100\n",
      "TrEpoch(042) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  133.366 -116.398  41.148  0.007  41.148\n",
      "ValEpoch(042) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  129.596 -109.718  6.929\n",
      "*****\n",
      " Epoch 43 of 100\n",
      "TrEpoch(043) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  132.378 -115.656  40.928  0.007  40.929\n",
      "ValEpoch(043) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  128.214 -108.58  6.906\n",
      "*****\n",
      " Epoch 44 of 100\n",
      "TrEpoch(044) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  132.481 -114.231  40.448  0.007  40.449\n",
      "ValEpoch(044) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  128.339 -108.301  6.702\n",
      "*****\n",
      " Epoch 45 of 100\n",
      "TrEpoch(045) - \n",
      "     acc      bmx      bmn   mse    spr     run\n",
      "0  10.0  132.382 -114.372  39.7  0.007  39.701\n",
      "ValEpoch(045) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  127.106 -107.374  6.684\n",
      "*****\n",
      " Epoch 46 of 100\n",
      "TrEpoch(046) - 4- False False\n",
      "cre tensor(1.0058e-07, grad_fn=<AddBackward0>)\n",
      "sp_loss: 1.0058268884449717e-07\n",
      "\n",
      "     acc      bmx      bmn    mse    spr     run\n",
      "0  10.0  131.163 -113.035  39.54  0.008  39.541\n",
      "ValEpoch(046) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  126.765 -107.145  6.659\n",
      "*****\n",
      " Epoch 47 of 100\n",
      "TrEpoch(047) - \n",
      "     acc      bmx      bmn     mse    spr     run\n",
      "0  10.0  130.606 -111.946  39.384  0.008  39.385\n",
      "ValEpoch(047) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  125.783 -106.344  6.643\n",
      "*****\n",
      " Epoch 48 of 100\n",
      "TrEpoch(048) - "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-40a9651c7a19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"*****\\n Epoch {epoch} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mresult_df_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mresult_df_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint_losses_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-0a47c7f60ff3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, dataloader, epoch, print_losses_fit)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmse_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/khs_ws5/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_ws :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"APPLY_LOG_SOFTMAX : \", APPLY_LOG_SOFTMAX)\n",
    "print(\"APPLY_SPARSITY_TO : \", APPLY_SPARSITY_TO)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param * sp_loss\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc      bmx      bmn      mse      spr      run\n",
      "0   10.0  111.810  -66.466  186.436  201.117  206.548\n",
      "1   10.0  144.625  -86.706  117.777    0.076  117.785\n",
      "2   10.0  153.614  -92.646  108.076    0.031  108.079\n",
      "3   10.0  160.527  -94.638   98.818    0.011   98.819\n",
      "4   10.0  164.553  -97.294   86.417    0.005   86.418\n",
      "5   10.0  163.201  -95.990   82.665    0.003   82.665\n",
      "6   10.0  162.591  -95.972   80.915    0.003   80.915\n",
      "7   10.0  161.680  -95.383   79.295    0.002   79.295\n",
      "8   10.0  161.469  -95.902   75.611    0.002   75.611\n",
      "9   10.0  159.179  -96.607   72.203    0.003   72.204\n",
      "10  10.0  158.352  -96.627   71.156    0.003   71.157\n",
      "11  10.0  156.684  -99.634   70.501    0.004   70.501\n",
      "12  10.0  151.883 -104.740   68.612    0.005   68.612\n",
      "13  10.0  150.733 -107.312   66.312    0.007   66.313\n",
      "14  10.0  149.534 -110.327   63.786    0.008   63.787\n",
      "15  10.0  150.756 -113.515   62.105    0.008   62.106\n",
      "16  10.0  150.047 -113.331   61.328    0.007   61.329\n",
      "17  10.0  149.272 -112.595   60.268    0.007   60.269\n",
      "18  10.0  148.206 -113.665   58.695    0.007   58.695\n",
      "19  10.0  149.262 -114.400   57.173    0.007   57.174\n",
      "20  10.0  150.026 -116.228   56.405    0.006   56.406\n",
      "21  10.0  150.252 -117.140   55.439    0.007   55.439\n",
      "22  10.0  150.221 -118.450   54.169    0.007   54.170\n",
      "23  10.0  148.897 -118.380   53.179    0.007   53.179\n",
      "24  10.0  148.521 -120.166   51.398    0.008   51.399\n",
      "25  10.0  148.066 -118.902   50.867    0.008   50.868\n",
      "26  10.0  147.521 -120.118   50.007    0.008   50.008\n",
      "27  10.0  145.594 -120.645   49.091    0.008   49.092\n",
      "28  10.0  145.039 -119.119   48.627    0.008   48.628\n",
      "29  10.0  144.484 -119.105   48.154    0.008   48.155\n",
      "30  10.0  142.834 -118.969   46.883    0.008   46.884\n",
      "31  10.0  142.623 -117.773   46.603    0.008   46.604\n",
      "32  10.0  140.050 -117.112   46.331    0.008   46.331\n",
      "33  10.0  139.327 -116.245   46.009    0.008   46.010\n",
      "34  10.0  137.339 -115.116   45.378    0.008   45.379\n",
      "35  10.0  137.703 -115.683   44.831    0.008   44.832\n",
      "36  10.0  135.639 -114.831   44.618    0.008   44.619\n",
      "37  10.0  134.771 -115.004   43.232    0.008   43.232\n",
      "38  10.0  133.812 -116.695   42.536    0.008   42.537\n",
      "39  10.0  134.267 -116.025   41.982    0.008   41.983\n",
      "40  10.0  133.688 -116.417   41.663    0.007   41.664\n",
      "41  10.0  133.522 -117.178   41.407    0.007   41.408\n",
      "42  10.0  133.366 -116.398   41.148    0.007   41.148\n",
      "43  10.0  132.378 -115.656   40.928    0.007   40.929\n",
      "44  10.0  132.481 -114.231   40.448    0.007   40.449\n",
      "45  10.0  132.382 -114.372   39.700    0.007   39.701\n",
      "46  10.0  131.163 -113.035   39.540    0.008   39.541\n",
      "47  10.0  130.606 -111.946   39.384    0.008   39.385\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc      bmx      bmn     run\n",
      "0   10.0  111.866  -66.770  22.129\n",
      "1   10.0  142.954  -85.410  18.491\n",
      "2   10.0  150.288  -90.636  17.515\n",
      "3   10.0  159.542  -94.126  15.065\n",
      "4   10.0  158.953  -92.541  13.978\n",
      "5   10.0  158.562  -92.304  13.655\n",
      "6   10.0  157.933  -92.025  13.425\n",
      "7   10.0  157.629  -92.188  13.000\n",
      "8   10.0  156.318  -92.610  12.195\n",
      "9   10.0  156.067  -93.292  12.022\n",
      "10  10.0  152.801  -94.354  11.852\n",
      "11  10.0  150.773  -98.039  11.738\n",
      "12  10.0  147.374 -101.453  11.248\n",
      "13  10.0  146.121 -104.354  10.880\n",
      "14  10.0  146.726 -107.064  10.481\n",
      "15  10.0  146.076 -107.705  10.343\n",
      "16  10.0  146.025 -108.515  10.248\n",
      "17  10.0  143.974 -108.456   9.954\n",
      "18  10.0  143.832 -109.161   9.749\n",
      "19  10.0  145.194 -111.425   9.511\n",
      "20  10.0  144.094 -111.146   9.367\n",
      "21  10.0  143.676 -111.537   9.151\n",
      "22  10.0  143.615 -112.436   9.056\n",
      "23  10.0  142.665 -112.462   8.873\n",
      "24  10.0  142.478 -112.459   8.604\n",
      "25  10.0  141.389 -112.543   8.454\n",
      "26  10.0  139.483 -111.726   8.343\n",
      "27  10.0  138.547 -111.321   8.208\n",
      "28  10.0  137.812 -111.068   8.156\n",
      "29  10.0  136.937 -111.327   8.006\n",
      "30  10.0  136.106 -110.757   7.870\n",
      "31  10.0  135.666 -110.932   7.821\n",
      "32  10.0  134.165 -110.212   7.746\n",
      "33  10.0  132.844 -108.902   7.721\n",
      "34  10.0  132.689 -109.418   7.576\n",
      "35  10.0  132.322 -108.754   7.516\n",
      "36  10.0  130.659 -108.413   7.507\n",
      "37  10.0  129.646 -109.710   7.216\n",
      "38  10.0  128.645 -110.054   7.113\n",
      "39  10.0  129.532 -110.064   7.042\n",
      "40  10.0  130.374 -110.281   7.029\n",
      "41  10.0  129.854 -109.719   6.948\n",
      "42  10.0  129.596 -109.718   6.929\n",
      "43  10.0  128.214 -108.580   6.906\n",
      "44  10.0  128.339 -108.301   6.702\n",
      "45  10.0  127.106 -107.374   6.684\n",
      "46  10.0  126.765 -107.145   6.659\n",
      "47  10.0  125.783 -106.344   6.643\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tr acc =  10.0\n",
      "Max va acc =  10.0\n"
     ]
    }
   ],
   "source": [
    "tr_acc = result_df_tr_all.values[:,0].squeeze()\n",
    "va_acc = result_df_va_all.values[:,0].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_acc, color='orange', label='train acc')\n",
    "plt.plot(va_acc, color='red', label='validataion acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Max tr acc = \", np.max(tr_acc))\n",
    "print(\"Max va acc = \", np.max(va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_mse = result_df_tr_all.values[:,3].squeeze()\n",
    "tr_spr_50 = 100*result_df_tr_all.values[:,4].squeeze()\n",
    "va_err = 5*result_df_va_all.values[:,-1].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_mse, color='orange', label='train mse')\n",
    "plt.plot(tr_spr_50, color='red', label='tr spr*100')\n",
    "plt.plot(va_err, color='blue', label='va_err*5')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
