{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/doga/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys, importlib as impL\n",
    "sys.path.insert(1,'/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/vae_torch')\n",
    "sys.path.insert(1,'/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery')\n",
    "import vae_torch_model as vtm\n",
    "import vae_torch as vt\n",
    "#from data_classes import khs_dataset_v2\n",
    "import vae_scripts as vs\n",
    "import sae_torch as st\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import vae_utils as vu\n",
    "import pandas as pd\n",
    "import helperFuncs as funcH\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_err(experiments_folder, exp_base_name,cf_int,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=1):\n",
    "    ae_fold_name = os.path.join(experiments_folder, exp_base_name + str(cf_int).zfill(z_fill_int))\n",
    "    ae_f_name = os.path.join(ae_fold_name, ae_f_name_base)\n",
    "    vfz = np.load(ae_f_name, allow_pickle=True)\n",
    "    loss_log_dict = {}\n",
    "    n = 0\n",
    "    loss_log_dict[data_log_key] = vfz.item().get(data_log_key)\n",
    "    if loss_log_dict[data_log_key] is None:\n",
    "        print(\"cf(\"+str(cf_int)+\") --> loss_log_dict\"+str(data_log_key)+\"] is none\")\n",
    "        return None, None, None\n",
    "    n = len(loss_log_dict[data_log_key])\n",
    "    if verbose>0:\n",
    "        print(str(cf_int), ', ', data_log_key, \" - log is loaded with len: \", n)\n",
    "    if loss_key not in loss_log_dict[data_log_key][0].keys():\n",
    "        return n, None, None\n",
    "\n",
    "    if loss_key in loss_log_dict[data_log_key][0]:\n",
    "        vec_len = len(loss_log_dict[data_log_key])\n",
    "        los_vec_cur = [loss_log_dict[data_log_key][l][loss_key] for l in range(0, vec_len)]\n",
    "        label_str = str(cf_int) + '_' + data_log_key + '_' + loss_key\n",
    "        if verbose>0:\n",
    "            print(label_str, los_vec_cur[-3:], \"\\nmax({:4.2f}),min({:4.2f})\".format(np.max(los_vec_cur), np.min(los_vec_cur)))\n",
    "        return n, np.min(los_vec_cur), np.max(los_vec_cur)\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "impL.reload(vu)\n",
    "experiments_folder='/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/FM/'\n",
    "config_folder = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/configs/'\n",
    "z_fill_int=2\n",
    "loss_key='reconstruction' # sparsity, bottleneck_kmeans, bottleneck_act\n",
    "data_log_keys=['tr_te']  # ['tr_va', 'va', 'te']\n",
    "exp_base_name='exp_conv_ae_simple_is28_cf'\n",
    "ae_f_name_base='ae_ft_conv_ae_simple_is28.npy'\n",
    "#cf_int_arr=[201,202,203,204,205,206,207,208,209,210,211,212,213,214,216,217,218]\n",
    "#cf_int_arr=[201,204,205,207,213,214]\n",
    "#cf_int_arr=[201,204,205,216,217,218]\n",
    "#cf_int_arr=[220,221,222,223,224,225,226,227]\n",
    "cf_int_arr=np.asarray(range(220,249), dtype=int)\n",
    "df1 = pd.DataFrame(index=cf_int_arr, columns=['spMethod','spW','spR','kl_div','bact','sigm','logsm','lact','rcErr','lr','rcRed'])\n",
    "df2 = pd.DataFrame(index=cf_int_arr, columns=['n','bActMin','bActMax','bErrMin','bErrMax','kmMin','kmMax','rErrMax','rErrMin'])\n",
    "df3 = pd.DataFrame(index=cf_int_arr, columns=['n','bActMin','bActMax','bErrMin','bErrMax','kmMin','kmMax','rErrMax','rErrMin'])\n",
    "df4 = pd.DataFrame(index=cf_int_arr, columns=['kl_div','bact','sigm','logsm','lr', 'n','bActMax','bErrMin','bErrDif','kmMax','rErrDif'])\n",
    "for i in range(0,len(cf_int_arr)):\n",
    "    cf = cf_int_arr[i]\n",
    "    #load model yaml as config\n",
    "    config_file = os.path.join(config_folder, 'conf_autoencoder_'+str(cf)+'.yaml')\n",
    "    CONF_PARAMS_ = funcH.CustomConfigParser(config_file=config_file)\n",
    "    df1.iloc[i]['spW'] = float(CONF_PARAMS_.MODEL.SPARSITY_WEIGHT)\n",
    "    if df1.iloc[i]['spW'] > 0:\n",
    "        df1.iloc[i]['spMethod'] = CONF_PARAMS_.MODEL.SPARSITY_ERROR\n",
    "        df1.iloc[i]['spR'] = CONF_PARAMS_.MODEL.SPARSITY_REDUCTION\n",
    "    else:\n",
    "        df1.iloc[i]['spW'] = None\n",
    "    df1.iloc[i]['kl_div'] = CONF_PARAMS_.MODEL.KL_DIV_RHO if 'kl_' in str(CONF_PARAMS_.MODEL.SPARSITY_ERROR) else None\n",
    "    df4.iloc[i]['kl_div'] = df1.iloc[i]['kl_div']\n",
    "    try:\n",
    "        df1.iloc[i]['bact'] = (CONF_PARAMS_.MODEL.LAYERS.encoder.l04_act).replace('type: ','').replace(',dim:','')\n",
    "        df4.iloc[i]['bact'] = df1.iloc[i]['bact']\n",
    "    except:\n",
    "        pass\n",
    "    df1.iloc[i]['sigm'] = CONF_PARAMS_.MODEL.KL_SIGMOID\n",
    "    df4.iloc[i]['sigm'] = df1.iloc[i]['sigm']\n",
    "    df1.iloc[i]['logsm'] = CONF_PARAMS_.MODEL.KL_LOGSOFTMAX\n",
    "    df4.iloc[i]['logsm'] = df1.iloc[i]['logsm']\n",
    "    try:\n",
    "        df1.iloc[i]['lact'] = CONF_PARAMS_.MODEL.LAYERS.decoder.l01_act.replace('type: ','')\n",
    "    except:\n",
    "        pass\n",
    "    df1.iloc[i]['rcErr'] = CONF_PARAMS_.MODEL.RECONSTRUCTION_ERROR_FUNCTION\n",
    "    df1.iloc[i]['lr'] = CONF_PARAMS_.MODEL.LEARNING_RATE\n",
    "    df4.iloc[i]['lr'] = df1.iloc[i]['lr']\n",
    "    df1.iloc[i]['rcRed'] = CONF_PARAMS_.MODEL.RECONSTRUCTION_ERROR_REDUCTION\n",
    "    \n",
    "    try:\n",
    "        data_log_key = 'tr_te'\n",
    "        loss_key = 'reconstruction' # reconstruction bottleneck_kmeans bottleneck_act sparsity\n",
    "        n, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df2.iloc[i]['n'] = n\n",
    "        df4.iloc[i]['n'] = df2.iloc[i]['n']\n",
    "\n",
    "        df2.iloc[i]['rErrMin'] = mn\n",
    "        df2.iloc[i]['rErrMax'] = mx\n",
    "        df4.iloc[i]['rErrDif'] = df2.iloc[i]['rErrMax']-df2.iloc[i]['rErrMin']\n",
    "            \n",
    "        loss_key = 'bottleneck_kmeans' # bottleneck_act sparsity\n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df2.iloc[i]['kmMin'] = mn\n",
    "        df2.iloc[i]['kmMax'] = mx\n",
    "\n",
    "        loss_key = 'bottleneck_act' #  sparsity\n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df2.iloc[i]['bActMin'] = mn\n",
    "        df2.iloc[i]['bActMax'] = mx if mx!=mn else '_n*c_'\n",
    "        df4.iloc[i]['bActMax'] = df2.iloc[i]['bActMax']\n",
    "\n",
    "        loss_key = 'sparsity' #  \n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df2.iloc[i]['bErrMin'] = mn\n",
    "        df2.iloc[i]['bErrMax'] = mx if mx!=mn else '_n*c_'\n",
    "        df4.iloc[i]['bErrMin'] = df2.iloc[i]['bErrMin']\n",
    "\n",
    "        try:\n",
    "            df4.iloc[i]['bErrDif'] = df2.iloc[i]['bErrMax']-df2.iloc[i]['bErrMin']\n",
    "        except:\n",
    "            df4.iloc[i]['bErrDif'] = 0\n",
    "        data_log_key = 'te'\n",
    "        loss_key = 'reconstruction' # reconstruction bottleneck_kmeans bottleneck_act sparsity\n",
    "        n, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df3.iloc[i]['n'] = n\n",
    "\n",
    "        df3.iloc[i]['rErrMin'] = mn\n",
    "        df3.iloc[i]['rErrMax'] = mx\n",
    "\n",
    "        loss_key = 'bottleneck_kmeans' # bottleneck_act sparsity\n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df3.iloc[i]['kmMin'] = mn\n",
    "        df3.iloc[i]['kmMax'] = mx\n",
    "        df4.iloc[i]['kmMax'] = df2.iloc[i]['kmMax']\n",
    "\n",
    "        loss_key = 'bottleneck_act' #  sparsity\n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df3.iloc[i]['bActMin'] = mn\n",
    "        df3.iloc[i]['bActMax'] = mx if mx!=mn else '_n*c_'\n",
    "\n",
    "        loss_key = 'sparsity' #  \n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df3.iloc[i]['bErrMin'] = mn\n",
    "        df3.iloc[i]['bErrMax'] = mx if mx!=mn else '_n*c_'\n",
    "    except:\n",
    "        print(\"no data available for d3 - \", cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments explanations\n",
      "          spMethod    spW        spR  kl_div  bact   sigm  logsm lact rcErr      lr rcRed\n",
      "220  kl_divergence  0.001  batchmean  0.0001  ReLu   True   True  NaN   MSE    0.01  mean\n",
      "221  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE    0.01  mean\n",
      "222  kl_divergence  0.001  batchmean  0.0001  ReLu  False  False  NaN   MSE    0.01  mean\n",
      "223  kl_divergence  0.001  batchmean  0.0001  ReLu  False   True  NaN   MSE    0.01  mean\n",
      "224  kl_divergence  0.001  batchmean  0.0001   NaN   True   True  NaN   MSE    0.01  mean\n",
      "225  kl_divergence  0.001  batchmean  0.0001   NaN   True  False  NaN   MSE    0.01  mean\n",
      "226  kl_divergence  0.001  batchmean  0.0001   NaN  False  False  NaN   MSE    0.01  mean\n",
      "227  kl_divergence  0.001  batchmean  0.0001   NaN  False   True  NaN   MSE    0.01  mean\n",
      "228  kl_divergence  0.001  batchmean  0.0001  ReLu   True   True  NaN   MSE   0.001  mean\n",
      "229  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE   0.001  mean\n",
      "230  kl_divergence  0.001  batchmean  0.0001  ReLu  False  False  NaN   MSE   0.001  mean\n",
      "231  kl_divergence  0.001  batchmean  0.0001  ReLu  False   True  NaN   MSE   0.001  mean\n",
      "232  kl_divergence  0.001  batchmean  0.0001   NaN   True   True  NaN   MSE   0.001  mean\n",
      "233  kl_divergence  0.001  batchmean  0.0001   NaN   True  False  NaN   MSE   0.001  mean\n",
      "234  kl_divergence  0.001  batchmean  0.0001   NaN  False  False  NaN   MSE   0.001  mean\n",
      "235  kl_divergence  0.001  batchmean  0.0001   NaN  False   True  NaN   MSE   0.001  mean\n",
      "236  kl_divergence  0.001  batchmean  0.0001  ReLu   True   True  NaN   MSE  0.0001  mean\n",
      "237  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE  0.0001  mean\n",
      "238  kl_divergence  0.001  batchmean  0.0001  ReLu  False  False  NaN   MSE  0.0001  mean\n",
      "239  kl_divergence  0.001  batchmean  0.0001  ReLu  False   True  NaN   MSE  0.0001  mean\n",
      "240  kl_divergence  0.001  batchmean  0.0001   NaN   True   True  NaN   MSE  0.0001  mean\n",
      "241  kl_divergence  0.001  batchmean  0.0001   NaN   True  False  NaN   MSE  0.0001  mean\n",
      "242  kl_divergence  0.001  batchmean  0.0001   NaN  False  False  NaN   MSE  0.0001  mean\n",
      "243  kl_divergence  0.001  batchmean  0.0001   NaN  False   True  NaN   MSE  0.0001  mean\n",
      "244  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE  0.0001  mean\n",
      "245  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE  0.0001  mean\n",
      "246  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE  0.0001  mean\n",
      "247  kl_divergence  0.001        sum  0.0001  ReLu   True  False  NaN   MSE  0.0001  mean\n",
      "248  kl_divergence  0.001        sum  0.0001  ReLu   True   True  NaN   MSE  0.0001  mean\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.precision\", 2)\n",
    "print('experiments explanations')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_te dataset results\n",
      "       n bActMin bActMax     bErrMin     bErrMax   kmMin   kmMax rErrMax rErrMin\n",
      "220    5      10   _n*c_    -0.32354    -0.23029      10  12.312  50.441  48.848\n",
      "221    5      10   _n*c_      1870.3      1871.8     8.5      10  50.349   47.77\n",
      "222    5      10   _n*c_      1657.3      1664.6      10      10  50.513  49.032\n",
      "223    5      10   _n*c_     -5.1343     -3.7721   9.405      10  50.343  48.716\n",
      "224    5      10   _n*c_    -0.39536    -0.37654      10  13.383  50.938  48.591\n",
      "225    5      10   _n*c_      1855.1        1858      10      10  50.528  48.689\n",
      "226    5      10   _n*c_      1553.8      1568.6      10      10  51.014  48.405\n",
      "227    5      10   _n*c_     -6.7183     -5.8667      10      10  50.648  48.296\n",
      "228    5      10   _n*c_     -8.0924     -7.4322  16.202  20.808  39.162  38.195\n",
      "229    5      10   _n*c_      1909.7      1917.5  16.725  20.722  39.092   38.09\n",
      "230    5      10   _n*c_      1838.4      1921.1  16.733   20.76  39.351  38.005\n",
      "231    5      10   _n*c_ -1.0847e+14 -1.2787e+11  14.983  19.903  96.826  96.826\n",
      "232    5      10   _n*c_     -22.648     -20.565  16.318  22.788  39.272   37.56\n",
      "233    5      10   _n*c_      1731.6      1799.1  17.123  20.798  39.524  38.283\n",
      "234    5      10   _n*c_     -794.11      85.705  17.243  20.993  39.134   37.93\n",
      "235    5      10   _n*c_ -6.0747e+12 -2.2776e+11  13.137   19.53  96.826  96.826\n",
      "236    5      10   _n*c_     -7.8868     -6.3341    17.5  21.415  54.816  48.004\n",
      "237    5      10   _n*c_      1916.2      1923.8  16.198   20.98  54.984  48.279\n",
      "238    5      10   _n*c_      1908.1      1938.1  17.475  19.625  54.798  48.242\n",
      "239    5      10   _n*c_ -1.5863e+09      -888.2  14.655  20.065  54.587  39.525\n",
      "240    5      10   _n*c_     -17.817      -14.16  15.197  20.618  54.031  47.795\n",
      "241    5      10   _n*c_      1822.7      1839.6  16.662   19.31  53.875  47.722\n",
      "242    5      10   _n*c_      490.19      1447.6  16.782  19.717  54.693  47.922\n",
      "243    5      10   _n*c_ -3.0931e+09      -832.6   14.67  19.762  54.191  41.644\n",
      "244    1      10   _n*c_     -243.08       _n*c_  17.433  17.433  183.37  183.37\n",
      "245    5  16.805    25.3     -414.93     -414.09  32.313  40.622  111.67   74.83\n",
      "246    5  17.812  19.163     -6403.6     -6385.9  40.177  44.208  108.08   69.56\n",
      "247   32  18.542  29.425      -13196      -12946  34.988  49.237  105.07  43.716\n",
      "248  100  17.565   37.96      154.99      1081.9  38.312  59.717  98.586  33.707\n"
     ]
    }
   ],
   "source": [
    "print('tr_te dataset results')\n",
    "pd.set_option(\"display.precision\", 5)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te dataset results\n",
      "       n bActMin bActMax     bErrMin     bErrMax  kmMin  kmMax rErrMax rErrMin\n",
      "220    5      10   _n*c_   -0.054498    -0.03879     10  13.23  8.4548  8.1881\n",
      "221    5      10   _n*c_      315.04      315.29     10  10.83  8.4399  8.0067\n",
      "222    5      10   _n*c_      279.16      280.39     10     10   8.466   8.218\n",
      "223    5      10   _n*c_    -0.86485    -0.63538   8.95     10  8.4391  8.1659\n",
      "224    5      10   _n*c_   -0.066596   -0.063425     10  13.14  8.5389  8.1439\n",
      "225    5      10   _n*c_      312.47      312.97     10     10  8.4703   8.163\n",
      "226    5      10   _n*c_      261.73      264.21     10     10  8.5542   8.113\n",
      "227    5      10   _n*c_     -1.1316     -0.9882     10     10  8.4889  8.0961\n",
      "228    5      10   _n*c_     -1.3647     -1.2535  15.52  20.41  6.5716  6.4089\n",
      "229    5      10   _n*c_      321.68      323.01  17.81  20.29   6.561  6.3919\n",
      "230    5      10   _n*c_      309.67      323.61   17.1   21.3  6.6036  6.3761\n",
      "231    5      10   _n*c_ -1.8278e+13 -2.1547e+10  17.61  21.45  16.269  16.269\n",
      "232    5      10   _n*c_      -3.815     -3.4637  18.25  21.02  6.5901  6.3038\n",
      "233    5      10   _n*c_      291.67      303.03     17  20.13  6.6321  6.4239\n",
      "234    5      10   _n*c_     -133.71       14.47  18.16   20.7  6.5667  6.3642\n",
      "235    5      10   _n*c_ -1.0236e+12 -3.8378e+10  19.85   21.4  16.269  16.269\n",
      "236    5      10   _n*c_     -1.3298     -1.0675  17.38  20.12  9.2033  8.0605\n",
      "237    5      10   _n*c_      322.78      324.06  17.63  20.36  9.2327  8.1064\n",
      "238    5      10   _n*c_      321.42      326.46  16.99  19.17  9.2007  8.1011\n",
      "239    5      10   _n*c_  -2.673e+08     -149.36  14.46  19.58  9.1655   6.632\n",
      "240    5      10   _n*c_     -3.0021     -2.3849  15.02  20.54  9.0713  8.0237\n",
      "241    5      10   _n*c_      307.02      309.87  15.23  18.88   9.045  8.0111\n",
      "242    5      10   _n*c_      82.564      243.84  15.66  19.19  9.1813   8.045\n",
      "243    5      10   _n*c_  -5.212e+08     -140.07  16.74  21.25  9.0977  6.9918\n",
      "244    1      10   _n*c_     -40.581       _n*c_  20.89  20.89   30.54   30.54\n",
      "245    5   16.46   27.35     -69.273     -69.133  35.84  41.27  18.607  12.541\n",
      "246    5   17.27   18.59       -1069       -1066  37.85  42.21  18.017   11.64\n",
      "247   32   18.72   30.13     -2199.5     -2157.9  37.98  48.03  17.515  7.3825\n",
      "248  100   11.18    33.4      25.731      180.14   38.5  57.59  16.446  5.7729\n"
     ]
    }
   ],
   "source": [
    "print('te dataset results')\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picky results\n",
      "     kl_div  bact   sigm  logsm      lr    n bActMax     bErrMin     bErrDif   kmMax  rErrDif\n",
      "220  0.0001  ReLu   True   True    0.01    5   _n*c_    -0.32354     0.09325  12.312   1.5933\n",
      "221  0.0001  ReLu   True  False    0.01    5   _n*c_      1870.3      1.5248      10   2.5791\n",
      "222  0.0001  ReLu  False  False    0.01    5   _n*c_      1657.3      7.3107      10   1.4812\n",
      "223  0.0001  ReLu  False   True    0.01    5   _n*c_     -5.1343      1.3623      10   1.6265\n",
      "224  0.0001   NaN   True   True    0.01    5   _n*c_    -0.39536    0.018824  13.383   2.3469\n",
      "225  0.0001   NaN   True  False    0.01    5   _n*c_      1855.1      2.9665      10   1.8385\n",
      "226  0.0001   NaN  False  False    0.01    5   _n*c_      1553.8      14.737      10   2.6093\n",
      "227  0.0001   NaN  False   True    0.01    5   _n*c_     -6.7183     0.85159      10   2.3518\n",
      "228  0.0001  ReLu   True   True   0.001    5   _n*c_     -8.0924     0.66022  20.808  0.96679\n",
      "229  0.0001  ReLu   True  False   0.001    5   _n*c_      1909.7      7.8693  20.722   1.0019\n",
      "230  0.0001  ReLu  False  False   0.001    5   _n*c_      1838.4      82.706   20.76   1.3462\n",
      "231  0.0001  ReLu  False   True   0.001    5   _n*c_ -1.0847e+14  1.0834e+14  19.903        0\n",
      "232  0.0001   NaN   True   True   0.001    5   _n*c_     -22.648      2.0829  22.788   1.7114\n",
      "233  0.0001   NaN   True  False   0.001    5   _n*c_      1731.6       67.42  20.798   1.2416\n",
      "234  0.0001   NaN  False  False   0.001    5   _n*c_     -794.11      879.81  20.993   1.2038\n",
      "235  0.0001   NaN  False   True   0.001    5   _n*c_ -6.0747e+12  5.8469e+12   19.53        0\n",
      "236  0.0001  ReLu   True   True  0.0001    5   _n*c_     -7.8868      1.5527  21.415   6.8126\n",
      "237  0.0001  ReLu   True  False  0.0001    5   _n*c_      1916.2      7.5543   20.98    6.705\n",
      "238  0.0001  ReLu  False  False  0.0001    5   _n*c_      1908.1       29.96  19.625   6.5564\n",
      "239  0.0001  ReLu  False   True  0.0001    5   _n*c_ -1.5863e+09  1.5863e+09  20.065   15.062\n",
      "240  0.0001   NaN   True   True  0.0001    5   _n*c_     -17.817      3.6563  20.618   6.2358\n",
      "241  0.0001   NaN   True  False  0.0001    5   _n*c_      1822.7      16.902   19.31   6.1531\n",
      "242  0.0001   NaN  False  False  0.0001    5   _n*c_      490.19      957.44  19.717   6.7716\n",
      "243  0.0001   NaN  False   True  0.0001    5   _n*c_ -3.0931e+09  3.0931e+09  19.762   12.547\n",
      "244  0.0001  ReLu   True  False  0.0001    1   _n*c_     -243.08           0  17.433        0\n",
      "245  0.0001  ReLu   True  False  0.0001    5    25.3     -414.93     0.84323  40.622   36.838\n",
      "246  0.0001  ReLu   True  False  0.0001    5  19.163     -6403.6       17.76  44.208   38.515\n",
      "247  0.0001  ReLu   True  False  0.0001   32  29.425      -13196       249.8  49.237   61.355\n",
      "248  0.0001  ReLu   True   True  0.0001  100   37.96      154.99      926.89  59.717   64.878\n"
     ]
    }
   ],
   "source": [
    "print('picky results')\n",
    "print(df4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
