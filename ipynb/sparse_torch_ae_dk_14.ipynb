{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:  0.23.4\n",
      "torch:  1.4.0\n",
      "numpy:  1.17.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "import pandas as pd\n",
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"torch: \", torch.__version__)\n",
    "print(\"numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doga-MSISSD_khs_dir = /mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery\n",
      "doga-MSISSD_data_path = /mnt/USB_HDD_1TB/Datasets\n",
      "doga-MSISSD_experiment_path = /mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/SPARSE_TORCH\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "def get_var_by_comp_name(variableName):\n",
    "    curCompName = socket.gethostname()\n",
    "    retVal = None\n",
    "    if variableName == 'khs_dir':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/home/wsubuntu/GitHub/keyhandshapediscovery'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'data_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/Datasets'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/mnt/SSD_Data/DataPath'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'experiment_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/SPARSE_TORCH'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/mnt/SSD_Data/vaesae_experiments'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "        \n",
    "    print(curCompName + '_' + variableName, '=',  retVal)\n",
    "    if retVal is None:\n",
    "        os.error(5)\n",
    "    return retVal\n",
    "\n",
    "khs_dir = get_var_by_comp_name('khs_dir')\n",
    "data_path = get_var_by_comp_name('data_path')\n",
    "experiment_path = get_var_by_comp_name('experiment_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, khs_dir)\n",
    "import helperFuncs as funcH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 14\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'batchmean','sum'\n",
    "SIGMOID_ACT=False\n",
    "APPLY_LOG_SOFTMAX=False\n",
    "MSE_PLUS_MINUS='+'\n",
    "APPLY_SPARSITY_TO='bottleneck' #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 100  # args['epochs']\n",
    "reg_param = 0.001  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": data_path,\n",
    "    \"experiment\": os.path.join(experiment_path, 'sparse_torch_ae_' + str(EXPERIMENT_ID).zfill(3)),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=32)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    "\n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        bottleneck = F.relu(self.enc5(x))  \n",
    "        return bottleneck\n",
    "        \n",
    "    def decode(self, bottleneck):\n",
    "        # decoding\n",
    "        x = F.relu(self.dec1(bottleneck))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x)) \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encode(x)\n",
    "        x = self.decode(bottleneck)\n",
    "        return x, bottleneck\n",
    "\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    rho_val = 1/bt.size(1)\n",
    "    rho_mat = torch.tensor([rho_val] * np.ones(bt.size()), dtype=torch.float32).to(device)\n",
    "    #https://discuss.pytorch.org/t/kl-divergence-produces-negative-values/16791/13\n",
    "    #KLDLoss(p, q), sum(q) needs to equal one\n",
    "    #p = log_softmax(tensor)\n",
    "    loss_ret_1 = F.kl_div(F.log_softmax(bt, dim=1).to(device), rho_mat, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction, apply_log_softmax):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    _, preds = torch.max(bottleneck, 1)\n",
    "    if sigmoidAct and apply_log_softmax:        \n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    elif sigmoidAct and not apply_log_softmax:     \n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        loss_ret_1 = loss_fun(bt.to(device), preds)    \n",
    "    elif not sigmoidAct and apply_log_softmax:\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bottleneck, dim=1).to(device), preds)    \n",
    "    else:#nothing\n",
    "        loss_ret_1 = loss_fun(bottleneck.to(device), preds)\n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss\n",
    "\n",
    "def sparse_loss_bottleneck(bottleneck, print_info, loss_type):\n",
    "    loss = 0\n",
    "    #if print_info:\n",
    "        #print(i, ' shape=', values.shape)\n",
    "    if loss_type=='l1':\n",
    "        loss += loss_l1(bottleneck)\n",
    "    if loss_type=='l2':\n",
    "        loss += loss_l2(bottleneck)\n",
    "    if loss_type=='kl':\n",
    "        loss += kl_divergence(bottleneck, reduction=LOSS_REDUCTION)\n",
    "    if loss_type=='cre':\n",
    "        loss += loss_crossentropy(bottleneck, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX)\n",
    "    if print_info:\n",
    "        print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            if APPLY_SPARSITY_TO=='all':\n",
    "                sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            elif APPLY_SPARSITY_TO=='bottleneck': #all\n",
    "                sp_loss = sparse_loss_bottleneck(bottleneck, print_losses_fit, model.loss_type)\n",
    "            else:\n",
    "                os.exit(4)\n",
    "                \n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            \n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "                \n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_dgmsissd :: \n",
      "EXPERIMENT_ID:  14\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  False\n",
      "APPLY_LOG_SOFTMAX :  False\n",
      "APPLY_SPARSITY_TO :  bottleneck\n",
      "total loss = mse_loss + reg_param * sp_loss\n",
      "*****\n",
      " Epoch 0 of 100\n",
      "TrEpoch(000) - cre tensor(3.3364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.3363630771636963\n",
      "\n",
      "     acc     bmx  bmn      mse      spr      run\n",
      "0  10.0  74.534  0.0  157.746  341.215  158.087\n",
      "ValEpoch(000) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  77.432  0.0  19.191\n",
      "*****\n",
      " Epoch 1 of 100\n",
      "TrEpoch(001) - \n",
      "     acc     bmx  bmn      mse    spr      run\n",
      "0  10.0  92.454  0.0  101.447  5.709  101.452\n",
      "ValEpoch(001) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  94.759  0.0  15.214\n",
      "*****\n",
      " Epoch 2 of 100\n",
      "TrEpoch(002) - \n",
      "     acc      bmx  bmn     mse    spr     run\n",
      "0  10.0  102.618  0.0  86.471  3.311  86.474\n",
      "ValEpoch(002) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  99.569  0.0  13.606\n",
      "*****\n",
      " Epoch 3 of 100\n",
      "TrEpoch(003) - \n",
      "     acc      bmx  bmn     mse    spr     run\n",
      "0  10.0  103.359  0.0  78.389  3.021  78.392\n",
      "ValEpoch(003) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  99.648  0.0  12.711\n",
      "*****\n",
      " Epoch 4 of 100\n",
      "TrEpoch(004) - \n",
      "     acc      bmx  bmn     mse  spr     run\n",
      "0  10.0  103.212  0.0  73.951  3.2  73.954\n",
      "ValEpoch(004) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  100.509  0.0  11.972\n",
      "*****\n",
      " Epoch 5 of 100\n",
      "TrEpoch(005) - \n",
      "     acc      bmx  bmn     mse    spr     run\n",
      "0  10.0  103.524  0.0  70.188  3.052  70.191\n",
      "ValEpoch(005) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  100.011  0.0  11.309\n",
      "*****\n",
      " Epoch 6 of 100\n",
      "TrEpoch(006) - cre tensor(0.0162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.016192257404327393\n",
      "\n",
      "     acc      bmx  bmn     mse    spr     run\n",
      "0  10.0  104.758  0.0  66.149  2.647  66.152\n",
      "ValEpoch(006) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  101.399  0.0  10.726\n",
      "*****\n",
      " Epoch 7 of 100\n",
      "TrEpoch(007) - \n",
      "     acc      bmx  bmn     mse    spr     run\n",
      "0  10.0  104.966  0.0  62.671  2.322  62.673\n",
      "ValEpoch(007) - \n",
      "     acc      bmx  bmn     run\n",
      "0  10.0  100.957  0.0  10.382\n",
      "*****\n",
      " Epoch 8 of 100\n",
      "TrEpoch(008) - \n",
      "     acc      bmx  bmn     mse    spr     run\n",
      "0  10.0  104.192  0.0  60.582  2.159  60.585\n",
      "ValEpoch(008) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  99.353  0.0  10.069\n",
      "*****\n",
      " Epoch 9 of 100\n",
      "TrEpoch(009) - \n",
      "     acc      bmx  bmn    mse    spr     run\n",
      "0  10.0  102.609  0.0  59.69  2.141  59.692\n",
      "ValEpoch(009) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  98.501  0.0  9.961\n",
      "*****\n",
      " Epoch 10 of 100\n",
      "TrEpoch(010) - \n",
      "     acc      bmx  bmn     mse    spr     run\n",
      "0  10.0  100.667  0.0  59.015  2.128  59.017\n",
      "ValEpoch(010) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  97.514  0.0  9.856\n",
      "*****\n",
      " Epoch 11 of 100\n",
      "TrEpoch(011) - cre tensor(3.9458e-05, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.9458274841308594e-05\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  99.484  0.0  57.026  2.163  57.028\n",
      "ValEpoch(011) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  95.217  0.0  9.381\n",
      "*****\n",
      " Epoch 12 of 100\n",
      "TrEpoch(012) - "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9103f6553ed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"*****\\n Epoch {epoch} of {epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mresult_df_tr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mresult_df_va\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint_losses_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-0a47c7f60ff3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, dataloader, epoch, print_losses_fit)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0msp_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mAPPLY_SPARSITY_TO\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'bottleneck'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0msp_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_loss_bottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_losses_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-99bd9b1cc480>\u001b[0m in \u001b[0;36msparse_loss_bottleneck\u001b[0;34m(bottleneck, print_info, loss_type)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mkl_divergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS_REDUCTION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'cre'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoidAct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSIGMOID_ACT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOSS_REDUCTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_log_softmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAPPLY_LOG_SOFTMAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprint_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0107871ad858>\u001b[0m in \u001b[0;36mloss_crossentropy\u001b[0;34m(bottleneck, sigmoidAct, reduction, apply_log_softmax)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoidAct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_log_softmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msigmoidAct\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mapply_log_softmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m    909\u001b[0m     def __init__(self, weight=None, size_average=None, ignore_index=-100,\n\u001b[1;32m    910\u001b[0m                  reduce=None, reduction='mean'):\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_WeightedLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_WeightedLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state_dict_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m    576\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mremove_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_dgmsissd :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"APPLY_LOG_SOFTMAX : \", APPLY_LOG_SOFTMAX)\n",
    "print(\"APPLY_SPARSITY_TO : \", APPLY_SPARSITY_TO)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param * sp_loss\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc      bmx  bmn      mse      spr      run\n",
      "0   10.0   74.534  0.0  157.746  341.215  158.087\n",
      "1   10.0   92.454  0.0  101.447    5.709  101.452\n",
      "2   10.0  102.618  0.0   86.471    3.311   86.474\n",
      "3   10.0  103.359  0.0   78.389    3.021   78.392\n",
      "4   10.0  103.212  0.0   73.951    3.200   73.954\n",
      "5   10.0  103.524  0.0   70.188    3.052   70.191\n",
      "6   10.0  104.758  0.0   66.149    2.647   66.152\n",
      "7   10.0  104.966  0.0   62.671    2.322   62.673\n",
      "8   10.0  104.192  0.0   60.582    2.159   60.585\n",
      "9   10.0  102.609  0.0   59.690    2.141   59.692\n",
      "10  10.0  100.667  0.0   59.015    2.128   59.017\n",
      "11  10.0   99.484  0.0   57.026    2.163   57.028\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc      bmx  bmn     run\n",
      "0   10.0   77.432  0.0  19.191\n",
      "1   10.0   94.759  0.0  15.214\n",
      "2   10.0   99.569  0.0  13.606\n",
      "3   10.0   99.648  0.0  12.711\n",
      "4   10.0  100.509  0.0  11.972\n",
      "5   10.0  100.011  0.0  11.309\n",
      "6   10.0  101.399  0.0  10.726\n",
      "7   10.0  100.957  0.0  10.382\n",
      "8   10.0   99.353  0.0  10.069\n",
      "9   10.0   98.501  0.0   9.961\n",
      "10  10.0   97.514  0.0   9.856\n",
      "11  10.0   95.217  0.0   9.381\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tr acc =  10.0\n",
      "Max va acc =  10.0\n"
     ]
    }
   ],
   "source": [
    "tr_acc = result_df_tr_all.values[:,0].squeeze()\n",
    "va_acc = result_df_va_all.values[:,0].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_acc, color='orange', label='train acc')\n",
    "plt.plot(va_acc, color='red', label='validataion acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Max tr acc = \", np.max(tr_acc))\n",
    "print(\"Max va acc = \", np.max(va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_mse = result_df_tr_all.values[:,3].squeeze()\n",
    "tr_spr_50 = 100*result_df_tr_all.values[:,4].squeeze()\n",
    "va_err = 5*result_df_va_all.values[:,-1].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_mse, color='orange', label='train mse')\n",
    "plt.plot(tr_spr_50, color='red', label='tr spr*100')\n",
    "plt.plot(va_err, color='blue', label='va_err*5')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
