{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:  1.1.0\n",
      "torch:  1.6.0\n",
      "numpy:  1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "import pandas as pd\n",
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"torch: \", torch.__version__)\n",
    "print(\"numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsubuntu_khs_dir = /home/wsubuntu/GitHub/keyhandshapediscovery\n",
      "wsubuntu_data_path = /mnt/SSD_Data/DataPath\n",
      "wsubuntu_experiment_path = /mnt/SSD_Data/vaesae_experiments\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "def get_var_by_comp_name(variableName):\n",
    "    curCompName = socket.gethostname()\n",
    "    retVal = None\n",
    "    if variableName == 'khs_dir':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/home/wsubuntu/GitHub/keyhandshapediscovery'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'data_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/Datasets'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/mnt/SSD_Data/DataPath'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'experiment_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/SPARSE_TORCH'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/mnt/SSD_Data/vaesae_experiments'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "        \n",
    "    print(curCompName + '_' + variableName, '=',  retVal)\n",
    "    if retVal is None:\n",
    "        os.error(5)\n",
    "    return retVal\n",
    "\n",
    "khs_dir = get_var_by_comp_name('khs_dir')\n",
    "data_path = get_var_by_comp_name('data_path')\n",
    "experiment_path = get_var_by_comp_name('experiment_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, khs_dir)\n",
    "import helperFuncs as funcH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 27\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'batchmean','sum'\n",
    "SIGMOID_ACT=False\n",
    "APPLY_LOG_SOFTMAX=False\n",
    "MSE_PLUS_MINUS='+'\n",
    "APPLY_SPARSITY_TO='bottleneck' #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 100  # args['epochs']\n",
    "reg_param = 0.001  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": data_path,\n",
    "    \"experiment\": os.path.join(experiment_path, 'sparse_torch_ae_' + str(EXPERIMENT_ID).zfill(3)),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseAutoencoder - loss_type(cre), device(cpu)\n"
     ]
    }
   ],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=32)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    "        print(\"SparseAutoencoder - loss_type(\" + loss_type +\"), device(\" + self.device + \")\")\n",
    "\n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        #if self.loss_type=='cre':\n",
    "        #    bottleneck = self.enc5(x) \n",
    "        #else:\n",
    "        bottleneck = F.relu(self.enc5(x))  \n",
    "        \n",
    "        return bottleneck\n",
    "        \n",
    "    def decode(self, bottleneck):\n",
    "        # decoding\n",
    "        #if self.loss_type=='cre':\n",
    "        #    x = F.relu(self.dec1(F.relu(bottleneck)))\n",
    "        #else:\n",
    "        x = F.relu(self.dec1(bottleneck))\n",
    "        \n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x)) \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encode(x)\n",
    "        x = self.decode(bottleneck)\n",
    "        return x, bottleneck\n",
    "\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    rho_val = 1/bt.size(1)\n",
    "    rho_mat = torch.tensor([rho_val] * np.ones(bt.size()), dtype=torch.float32).to(device)\n",
    "    #https://discuss.pytorch.org/t/kl-divergence-produces-negative-values/16791/13\n",
    "    #KLDLoss(p, q), sum(q) needs to equal one\n",
    "    #p = log_softmax(tensor)\n",
    "    loss_ret_1 = F.kl_div(F.log_softmax(bt, dim=1).to(device), rho_mat, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct and apply_log_softmax:  \n",
    "        if print_info:\n",
    "            print(\"1-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    elif sigmoidAct and not apply_log_softmax:     \n",
    "        if print_info:\n",
    "            print(\"2-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(bt.to(device), preds)    \n",
    "    elif not sigmoidAct and apply_log_softmax:\n",
    "        if print_info:\n",
    "            print(\"3-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bottleneck, dim=1).to(device), preds)    \n",
    "    else:#nothing\n",
    "        if print_info:\n",
    "            print(\"4-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(bottleneck.to(device), preds)\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy_old(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct:\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    else:\n",
    "        bt = bottleneck    \n",
    "    _, preds = torch.max(bt, 1)\n",
    "    loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss\n",
    "\n",
    "def sparse_loss_bottleneck(bottleneck, print_info, loss_type):\n",
    "    loss = 0\n",
    "    #if print_info:\n",
    "        #print(i, ' shape=', values.shape)\n",
    "    if loss_type=='l1':\n",
    "        loss += loss_l1(bottleneck)\n",
    "    if loss_type=='l2':\n",
    "        loss += loss_l2(bottleneck)\n",
    "    if loss_type=='kl':\n",
    "        loss += kl_divergence(bottleneck, reduction=LOSS_REDUCTION)\n",
    "    if loss_type=='cre':\n",
    "        loss += loss_crossentropy(bottleneck, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "    if print_info:\n",
    "        print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            if APPLY_SPARSITY_TO=='all':\n",
    "                sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            elif APPLY_SPARSITY_TO=='bottleneck': #all\n",
    "                sp_loss = sparse_loss_bottleneck(bottleneck, print_losses_fit, model.loss_type)\n",
    "            else:\n",
    "                os.exit(4)\n",
    "                \n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            \n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "                \n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_ws :: \n",
      "EXPERIMENT_ID:  27\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  False\n",
      "APPLY_LOG_SOFTMAX :  False\n",
      "APPLY_SPARSITY_TO :  bottleneck\n",
      "total loss = mse_loss + reg_param(0.001) * sp_loss\n",
      "*****\n",
      " Epoch 0 of 100\n",
      "TrEpoch(000) - 4- False False\n",
      "cre tensor(3.2875, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.287532329559326\n",
      "\n",
      "     acc     bmx  bmn      mse      spr      run\n",
      "0  10.0  77.021  0.0  150.708  334.568  151.043\n",
      "ValEpoch(000) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  75.509  0.0  18.407\n",
      "*****\n",
      " Epoch 1 of 100\n",
      "TrEpoch(001) - \n",
      "     acc     bmx  bmn      mse    spr      run\n",
      "0  10.0  83.415  0.0  104.233  4.809  104.238\n",
      "ValEpoch(001) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  85.049  0.0  15.982\n",
      "*****\n",
      " Epoch 2 of 100\n",
      "TrEpoch(002) - \n",
      "     acc     bmx  bmn     mse   spr     run\n",
      "0  10.0  91.695  0.0  84.834  2.91  84.836\n",
      "ValEpoch(002) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  87.592  0.0  13.367\n",
      "*****\n",
      " Epoch 3 of 100\n",
      "TrEpoch(003) - \n",
      "     acc     bmx  bmn    mse    spr     run\n",
      "0  10.0  90.201  0.0  78.06  2.807  78.063\n",
      "ValEpoch(003) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  86.079  0.0  12.674\n",
      "*****\n",
      " Epoch 4 of 100\n",
      "TrEpoch(004) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  89.298  0.0  73.643  2.477  73.646\n",
      "ValEpoch(004) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  88.085  0.0  11.91\n",
      "*****\n",
      " Epoch 5 of 100\n",
      "TrEpoch(005) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  93.021  0.0  69.797  2.031  69.799\n",
      "ValEpoch(005) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  90.819  0.0  11.437\n",
      "*****\n",
      " Epoch 6 of 100\n",
      "TrEpoch(006) - 4- False False\n",
      "cre tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.00012979315943084657\n",
      "\n",
      "     acc     bmx  bmn    mse    spr     run\n",
      "0  10.0  94.678  0.0  66.24  1.598  66.242\n",
      "ValEpoch(006) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  91.628  0.0  10.879\n",
      "*****\n",
      " Epoch 7 of 100\n",
      "TrEpoch(007) - \n",
      "     acc     bmx  bmn     mse    spr    run\n",
      "0  10.0  95.276  0.0  63.928  1.532  63.93\n",
      "ValEpoch(007) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  91.468  0.0  10.589\n",
      "*****\n",
      " Epoch 8 of 100\n",
      "TrEpoch(008) - \n",
      "     acc     bmx  bmn    mse    spr     run\n",
      "0  10.0  94.493  0.0  61.27  1.528  61.271\n",
      "ValEpoch(008) - \n",
      "     acc     bmx  bmn     run\n",
      "0  10.0  90.637  0.0  10.095\n",
      "*****\n",
      " Epoch 9 of 100\n",
      "TrEpoch(009) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  93.688  0.0  59.866  1.502  59.868\n",
      "ValEpoch(009) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  90.289  0.0  9.989\n",
      "*****\n",
      " Epoch 10 of 100\n",
      "TrEpoch(010) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  92.726  0.0  59.181  1.498  59.182\n",
      "ValEpoch(010) - \n",
      "     acc    bmx  bmn    run\n",
      "0  10.0  89.45  0.0  9.795\n",
      "*****\n",
      " Epoch 11 of 100\n",
      "TrEpoch(011) - 4- False False\n",
      "cre tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.00019061812781728804\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  92.244  0.0  57.268  1.424  57.269\n",
      "ValEpoch(011) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  89.916  0.0  9.508\n",
      "*****\n",
      " Epoch 12 of 100\n",
      "TrEpoch(012) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  92.301  0.0  55.535  1.339  55.537\n",
      "ValEpoch(012) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  89.976  0.0  9.215\n",
      "*****\n",
      " Epoch 13 of 100\n",
      "TrEpoch(013) - \n",
      "     acc     bmx  bmn    mse    spr     run\n",
      "0  10.0  91.872  0.0  54.32  1.257  54.321\n",
      "ValEpoch(013) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  89.353  0.0  8.838\n",
      "*****\n",
      " Epoch 14 of 100\n",
      "TrEpoch(014) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  91.545  0.0  51.546  1.214  51.547\n",
      "ValEpoch(014) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  88.732  0.0  8.452\n",
      "*****\n",
      " Epoch 15 of 100\n",
      "TrEpoch(015) - \n",
      "     acc     bmx  bmn    mse    spr     run\n",
      "0  10.0  90.692  0.0  49.91  1.203  49.911\n",
      "ValEpoch(015) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  87.839  0.0  8.321\n",
      "*****\n",
      " Epoch 16 of 100\n",
      "TrEpoch(016) - 4- False False\n",
      "cre tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.0007505625835619867\n",
      "\n",
      "     acc    bmx  bmn     mse    spr     run\n",
      "0  10.0  90.82  0.0  49.375  1.175  49.376\n",
      "ValEpoch(016) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  86.789  0.0  8.263\n",
      "*****\n",
      " Epoch 17 of 100\n",
      "TrEpoch(017) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  88.667  0.0  49.014  1.203  49.015\n",
      "ValEpoch(017) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  85.847  0.0  8.209\n",
      "*****\n",
      " Epoch 18 of 100\n",
      "TrEpoch(018) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  88.402  0.0  47.932  1.186  47.934\n",
      "ValEpoch(018) - \n",
      "     acc    bmx  bmn   run\n",
      "0  10.0  85.42  0.0  7.92\n",
      "*****\n",
      " Epoch 19 of 100\n",
      "TrEpoch(019) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  87.858  0.0  46.735  1.161  46.736\n",
      "ValEpoch(019) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  85.767  0.0  7.792\n",
      "*****\n",
      " Epoch 20 of 100\n",
      "TrEpoch(020) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  87.236  0.0  46.196  1.133  46.197\n",
      "ValEpoch(020) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  84.872  0.0  7.744\n",
      "*****\n",
      " Epoch 21 of 100\n",
      "TrEpoch(021) - 4- False False\n",
      "cre tensor(4.5373e-06, grad_fn=<AddBackward0>)\n",
      "sp_loss: 4.53733127869782e-06\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  87.174  0.0  45.862  1.155  45.863\n",
      "ValEpoch(021) - \n",
      "     acc    bmx  bmn    run\n",
      "0  10.0  83.97  0.0  7.668\n",
      "*****\n",
      " Epoch 22 of 100\n",
      "TrEpoch(022) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  87.198  0.0  45.574  1.187  45.575\n",
      "ValEpoch(022) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  84.017  0.0  7.633\n",
      "*****\n",
      " Epoch 23 of 100\n",
      "TrEpoch(023) - \n",
      "     acc     bmx  bmn    mse    spr     run\n",
      "0  10.0  86.905  0.0  45.03  1.184  45.031\n",
      "ValEpoch(023) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  83.216  0.0  7.497\n",
      "*****\n",
      " Epoch 24 of 100\n",
      "TrEpoch(024) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  86.073  0.0  44.155  1.207  44.156\n",
      "ValEpoch(024) - \n",
      "     acc     bmx  bmn   run\n",
      "0  10.0  82.991  0.0  7.36\n",
      "*****\n",
      " Epoch 25 of 100\n",
      "TrEpoch(025) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  85.405  0.0  43.702  1.213  43.703\n",
      "ValEpoch(025) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  82.025  0.0  7.344\n",
      "*****\n",
      " Epoch 26 of 100\n",
      "TrEpoch(026) - 4- False False\n",
      "cre tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.0006616358878090978\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  84.672  0.0  43.343  1.204  43.344\n",
      "ValEpoch(026) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  81.619  0.0  7.243\n",
      "*****\n",
      " Epoch 27 of 100\n",
      "TrEpoch(027) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  84.268  0.0  42.983  1.215  42.985\n",
      "ValEpoch(027) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  80.554  0.0  7.232\n",
      "*****\n",
      " Epoch 28 of 100\n",
      "TrEpoch(028) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  82.933  0.0  42.792  1.227  42.793\n",
      "ValEpoch(028) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  80.161  0.0  7.199\n",
      "*****\n",
      " Epoch 29 of 100\n",
      "TrEpoch(029) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  82.598  0.0  42.626  1.259  42.627\n",
      "ValEpoch(029) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  79.584  0.0  7.173\n",
      "*****\n",
      " Epoch 30 of 100\n",
      "TrEpoch(030) - \n",
      "     acc     bmx  bmn    mse    spr     run\n",
      "0  10.0  81.787  0.0  42.48  1.286  42.481\n",
      "ValEpoch(030) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  78.662  0.0  7.145\n",
      "*****\n",
      " Epoch 31 of 100\n",
      "TrEpoch(031) - 4- False False\n",
      "cre tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.0002883143606595695\n",
      "\n",
      "     acc     bmx  bmn    mse    spr     run\n",
      "0  10.0  80.848  0.0  42.34  1.307  42.342\n",
      "ValEpoch(031) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  77.968  0.0  7.106\n",
      "*****\n",
      " Epoch 32 of 100\n",
      "TrEpoch(032) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  80.492  0.0  42.197  1.321  42.198\n",
      "ValEpoch(032) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  77.773  0.0  7.093\n",
      "*****\n",
      " Epoch 33 of 100\n",
      "TrEpoch(033) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  80.152  0.0  42.054  1.342  42.056\n",
      "ValEpoch(033) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  76.855  0.0  7.077\n",
      "*****\n",
      " Epoch 34 of 100\n",
      "TrEpoch(034) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  79.421  0.0  41.915  1.339  41.916\n",
      "ValEpoch(034) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  75.958  0.0  7.045\n",
      "*****\n",
      " Epoch 35 of 100\n",
      "TrEpoch(035) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  77.886  0.0  41.748  1.328  41.749\n",
      "ValEpoch(035) - \n",
      "     acc     bmx  bmn   run\n",
      "0  10.0  75.707  0.0  7.03\n",
      "*****\n",
      " Epoch 36 of 100\n",
      "TrEpoch(036) - 4- False False\n",
      "cre tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.0003326514852233231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  77.801  0.0  41.554  1.323  41.555\n",
      "ValEpoch(036) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  74.552  0.0  6.989\n",
      "*****\n",
      " Epoch 37 of 100\n",
      "TrEpoch(037) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  77.152  0.0  41.336  1.308  41.338\n",
      "ValEpoch(037) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  74.626  0.0  6.952\n",
      "*****\n",
      " Epoch 38 of 100\n",
      "TrEpoch(038) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  77.347  0.0  40.844  1.268  40.845\n",
      "ValEpoch(038) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  73.655  0.0  6.787\n",
      "*****\n",
      " Epoch 39 of 100\n",
      "TrEpoch(039) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  75.885  0.0  39.737  1.261  39.739\n",
      "ValEpoch(039) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  73.268  0.0  6.647\n",
      "*****\n",
      " Epoch 40 of 100\n",
      "TrEpoch(040) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  75.437  0.0  39.364  1.249  39.366\n",
      "ValEpoch(040) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  72.848  0.0  6.624\n",
      "*****\n",
      " Epoch 41 of 100\n",
      "TrEpoch(041) - 4- False False\n",
      "cre tensor(3.6057e-05, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.605651727411896e-05\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  75.003  0.0  39.172  1.234  39.174\n",
      "ValEpoch(041) - \n",
      "     acc     bmx  bmn   run\n",
      "0  10.0  72.371  0.0  6.51\n",
      "*****\n",
      " Epoch 42 of 100\n",
      "TrEpoch(042) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  74.139  0.0  38.454  1.243  38.455\n",
      "ValEpoch(042) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  71.693  0.0  6.454\n",
      "*****\n",
      " Epoch 43 of 100\n",
      "TrEpoch(043) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  74.419  0.0  38.001  1.247  38.002\n",
      "ValEpoch(043) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  71.122  0.0  6.397\n",
      "*****\n",
      " Epoch 44 of 100\n",
      "TrEpoch(044) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  73.776  0.0  37.874  1.253  37.875\n",
      "ValEpoch(044) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  70.874  0.0  6.385\n",
      "*****\n",
      " Epoch 45 of 100\n",
      "TrEpoch(045) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  72.809  0.0  37.757  1.259  37.758\n",
      "ValEpoch(045) - \n",
      "     acc     bmx  bmn   run\n",
      "0  10.0  70.198  0.0  6.36\n",
      "*****\n",
      " Epoch 46 of 100\n",
      "TrEpoch(046) - 4- False False\n",
      "cre tensor(9.9909e-05, grad_fn=<AddBackward0>)\n",
      "sp_loss: 9.99085750663653e-05\n",
      "\n",
      "     acc     bmx  bmn     mse   spr     run\n",
      "0  10.0  71.884  0.0  37.625  1.26  37.626\n",
      "ValEpoch(046) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  69.532  0.0  6.233\n",
      "*****\n",
      " Epoch 47 of 100\n",
      "TrEpoch(047) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  70.833  0.0  36.825  1.262  36.826\n",
      "ValEpoch(047) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  68.997  0.0  6.207\n",
      "*****\n",
      " Epoch 48 of 100\n",
      "TrEpoch(048) - \n",
      "     acc     bmx  bmn     mse   spr     run\n",
      "0  10.0  70.694  0.0  36.702  1.26  36.704\n",
      "ValEpoch(048) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  68.373  0.0  6.196\n",
      "*****\n",
      " Epoch 49 of 100\n",
      "TrEpoch(049) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  68.735  0.0  36.605  1.268  36.607\n",
      "ValEpoch(049) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  67.562  0.0  6.185\n",
      "*****\n",
      " Epoch 50 of 100\n",
      "TrEpoch(050) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  68.973  0.0  36.258  1.273  36.259\n",
      "ValEpoch(050) - \n",
      "     acc     bmx  bmn   run\n",
      "0  10.0  67.036  0.0  6.05\n",
      "*****\n",
      " Epoch 51 of 100\n",
      "TrEpoch(051) - 4- False False\n",
      "cre tensor(8.9877e-05, grad_fn=<AddBackward0>)\n",
      "sp_loss: 8.987660839920864e-05\n",
      "\n",
      "     acc     bmx  bmn     mse   spr     run\n",
      "0  10.0  68.602  0.0  35.734  1.27  35.735\n",
      "ValEpoch(051) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  66.625  0.0  6.037\n",
      "*****\n",
      " Epoch 52 of 100\n",
      "TrEpoch(052) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  68.616  0.0  35.635  1.253  35.636\n",
      "ValEpoch(052) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  65.663  0.0  6.022\n",
      "*****\n",
      " Epoch 53 of 100\n",
      "TrEpoch(053) - \n",
      "     acc    bmx  bmn     mse   spr    run\n",
      "0  10.0  67.46  0.0  35.529  1.24  35.53\n",
      "ValEpoch(053) - \n",
      "     acc     bmx  bmn   run\n",
      "0  10.0  66.012  0.0  6.01\n",
      "*****\n",
      " Epoch 54 of 100\n",
      "TrEpoch(054) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  67.141  0.0  35.436  1.232  35.437\n",
      "ValEpoch(054) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  65.212  0.0  5.992\n",
      "*****\n",
      " Epoch 55 of 100\n",
      "TrEpoch(055) - \n",
      "     acc     bmx  bmn     mse    spr    run\n",
      "0  10.0  67.167  0.0  35.339  1.214  35.34\n",
      "ValEpoch(055) - \n",
      "     acc    bmx  bmn    run\n",
      "0  10.0  64.97  0.0  5.976\n",
      "*****\n",
      " Epoch 56 of 100\n",
      "TrEpoch(056) - 4- False False\n",
      "cre tensor(4.4455e-05, grad_fn=<AddBackward0>)\n",
      "sp_loss: 4.445476588443853e-05\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  66.619  0.0  34.972  1.199  34.973\n",
      "ValEpoch(056) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  64.474  0.0  5.934\n",
      "*****\n",
      " Epoch 57 of 100\n",
      "TrEpoch(057) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  66.361  0.0  34.786  1.177  34.787\n",
      "ValEpoch(057) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  64.599  0.0  5.895\n",
      "*****\n",
      " Epoch 58 of 100\n",
      "TrEpoch(058) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  65.969  0.0  34.658  1.129  34.659\n",
      "ValEpoch(058) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  64.214  0.0  5.868\n",
      "*****\n",
      " Epoch 59 of 100\n",
      "TrEpoch(059) - \n",
      "     acc     bmx  bmn    mse    spr     run\n",
      "0  10.0  65.698  0.0  34.26  1.096  34.261\n",
      "ValEpoch(059) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  64.472  0.0  5.796\n",
      "*****\n",
      " Epoch 60 of 100\n",
      "TrEpoch(060) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  65.619  0.0  34.126  1.073  34.127\n",
      "ValEpoch(060) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  64.266  0.0  5.782\n",
      "*****\n",
      " Epoch 61 of 100\n",
      "TrEpoch(061) - 4- False False\n",
      "cre tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.001878047944046557\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  65.426  0.0  33.791  1.049  33.792\n",
      "ValEpoch(061) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  63.911  0.0  5.685\n",
      "*****\n",
      " Epoch 62 of 100\n",
      "TrEpoch(062) - \n",
      "     acc    bmx  bmn     mse    spr     run\n",
      "0  10.0  64.97  0.0  33.452  1.006  33.453\n",
      "ValEpoch(062) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  63.622  0.0  5.666\n",
      "*****\n",
      " Epoch 63 of 100\n",
      "TrEpoch(063) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  64.337  0.0  33.373  1.002  33.374\n",
      "ValEpoch(063) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  63.652  0.0  5.652\n",
      "*****\n",
      " Epoch 64 of 100\n",
      "TrEpoch(064) - \n",
      "     acc     bmx  bmn     mse   spr     run\n",
      "0  10.0  64.294  0.0  33.295  1.01  33.296\n",
      "ValEpoch(064) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  63.092  0.0  5.652\n",
      "*****\n",
      " Epoch 65 of 100\n",
      "TrEpoch(065) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  63.954  0.0  33.215  0.989  33.216\n",
      "ValEpoch(065) - \n",
      "     acc     bmx  bmn   run\n",
      "0  10.0  62.796  0.0  5.64\n",
      "*****\n",
      " Epoch 66 of 100\n",
      "TrEpoch(066) - 4- False False\n",
      "cre tensor(0.0001, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.00013965973630547523\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  63.824  0.0  33.148  0.967  33.149\n",
      "ValEpoch(066) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  62.193  0.0  5.622\n",
      "*****\n",
      " Epoch 67 of 100\n",
      "TrEpoch(067) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  63.131  0.0  33.084  0.973  33.085\n",
      "ValEpoch(067) - \n",
      "     acc    bmx  bmn    run\n",
      "0  10.0  62.31  0.0  5.615\n",
      "*****\n",
      " Epoch 68 of 100\n",
      "TrEpoch(068) - \n",
      "     acc     bmx  bmn     mse   spr     run\n",
      "0  10.0  62.945  0.0  33.027  0.97  33.028\n",
      "ValEpoch(068) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  61.791  0.0  5.621\n",
      "*****\n",
      " Epoch 69 of 100\n",
      "TrEpoch(069) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  62.747  0.0  32.961  0.969  32.962\n",
      "ValEpoch(069) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  60.975  0.0  5.604\n",
      "*****\n",
      " Epoch 70 of 100\n",
      "TrEpoch(070) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  62.642  0.0  32.905  0.965  32.906\n",
      "ValEpoch(070) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  60.763  0.0  5.596\n",
      "*****\n",
      " Epoch 71 of 100\n",
      "TrEpoch(071) - 4- False False\n",
      "cre tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.0001706853654468432\n",
      "\n",
      "     acc     bmx  bmn     mse   spr     run\n",
      "0  10.0  61.922  0.0  32.851  0.97  32.852\n",
      "ValEpoch(071) - \n",
      "     acc     bmx  bmn   run\n",
      "0  10.0  61.115  0.0  5.58\n",
      "*****\n",
      " Epoch 72 of 100\n",
      "TrEpoch(072) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  62.197  0.0  32.797  0.963  32.798\n",
      "ValEpoch(072) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  60.439  0.0  5.569\n",
      "*****\n",
      " Epoch 73 of 100\n",
      "TrEpoch(073) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  61.308  0.0  32.728  0.965  32.729\n",
      "ValEpoch(073) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  60.623  0.0  5.577\n",
      "*****\n",
      " Epoch 74 of 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrEpoch(074) - \n",
      "     acc     bmx  bmn     mse   spr     run\n",
      "0  10.0  61.113  0.0  32.667  0.97  32.668\n",
      "ValEpoch(074) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  59.913  0.0  5.563\n",
      "*****\n",
      " Epoch 75 of 100\n",
      "TrEpoch(075) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  60.982  0.0  32.612  0.983  32.613\n",
      "ValEpoch(075) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  59.965  0.0  5.538\n",
      "*****\n",
      " Epoch 76 of 100\n",
      "TrEpoch(076) - 4- False False\n",
      "cre tensor(0.0017, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.001714541343972087\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  60.664  0.0  32.525  0.976  32.526\n",
      "ValEpoch(076) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  59.309  0.0  5.528\n",
      "*****\n",
      " Epoch 77 of 100\n",
      "TrEpoch(077) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  60.534  0.0  32.235  0.973  32.236\n",
      "ValEpoch(077) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  59.414  0.0  5.483\n",
      "*****\n",
      " Epoch 78 of 100\n",
      "TrEpoch(078) - \n",
      "     acc    bmx  bmn     mse    spr     run\n",
      "0  10.0  59.99  0.0  32.125  0.973  32.126\n",
      "ValEpoch(078) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  59.753  0.0  5.459\n",
      "*****\n",
      " Epoch 79 of 100\n",
      "TrEpoch(079) - \n",
      "     acc    bmx  bmn     mse    spr     run\n",
      "0  10.0  60.88  0.0  32.035  0.952  32.036\n",
      "ValEpoch(079) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  59.137  0.0  5.455\n",
      "*****\n",
      " Epoch 80 of 100\n",
      "TrEpoch(080) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  59.996  0.0  31.962  0.959  31.963\n",
      "ValEpoch(080) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  59.498  0.0  5.432\n",
      "*****\n",
      " Epoch 81 of 100\n",
      "TrEpoch(081) - 4- False False\n",
      "cre tensor(3.8241e-05, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.824062514468096e-05\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  60.447  0.0  31.894  0.956  31.895\n",
      "ValEpoch(081) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  59.176  0.0  5.433\n",
      "*****\n",
      " Epoch 82 of 100\n",
      "TrEpoch(082) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  60.158  0.0  31.834  0.947  31.835\n",
      "ValEpoch(082) - \n",
      "     acc     bmx  bmn   run\n",
      "0  10.0  59.117  0.0  5.43\n",
      "*****\n",
      " Epoch 83 of 100\n",
      "TrEpoch(083) - \n",
      "     acc    bmx  bmn     mse    spr     run\n",
      "0  10.0  59.64  0.0  31.774  0.967  31.775\n",
      "ValEpoch(083) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  59.297  0.0  5.429\n",
      "*****\n",
      " Epoch 84 of 100\n",
      "TrEpoch(084) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  59.337  0.0  31.714  0.946  31.715\n",
      "ValEpoch(084) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  58.448  0.0  5.397\n",
      "*****\n",
      " Epoch 85 of 100\n",
      "TrEpoch(085) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  59.293  0.0  31.664  0.942  31.665\n",
      "ValEpoch(085) - \n",
      "     acc     bmx  bmn   run\n",
      "0  10.0  58.399  0.0  5.39\n",
      "*****\n",
      " Epoch 86 of 100\n",
      "TrEpoch(086) - 4- False False\n",
      "cre tensor(0.0004, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.00037525867810472846\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  59.129  0.0  31.611  0.936  31.612\n",
      "ValEpoch(086) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  58.055  0.0  5.403\n",
      "*****\n",
      " Epoch 87 of 100\n",
      "TrEpoch(087) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  58.892  0.0  31.555  0.937  31.556\n",
      "ValEpoch(087) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  57.868  0.0  5.387\n",
      "*****\n",
      " Epoch 88 of 100\n",
      "TrEpoch(088) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  58.195  0.0  31.511  0.943  31.512\n",
      "ValEpoch(088) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  57.745  0.0  5.371\n",
      "*****\n",
      " Epoch 89 of 100\n",
      "TrEpoch(089) - \n",
      "     acc     bmx  bmn     mse    spr   run\n",
      "0  10.0  58.069  0.0  31.399  0.933  31.4\n",
      "ValEpoch(089) - \n",
      "     acc     bmx  bmn   run\n",
      "0  10.0  57.643  0.0  5.36\n",
      "*****\n",
      " Epoch 90 of 100\n",
      "TrEpoch(090) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  57.929  0.0  31.304  0.925  31.305\n",
      "ValEpoch(090) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  57.183  0.0  5.336\n",
      "*****\n",
      " Epoch 91 of 100\n",
      "TrEpoch(091) - 4- False False\n",
      "cre tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.0009308315347880125\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  57.703  0.0  31.252  0.927  31.253\n",
      "ValEpoch(091) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  56.865  0.0  5.324\n",
      "*****\n",
      " Epoch 92 of 100\n",
      "TrEpoch(092) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  57.419  0.0  31.198  0.928  31.199\n",
      "ValEpoch(092) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  57.066  0.0  5.325\n",
      "*****\n",
      " Epoch 93 of 100\n",
      "TrEpoch(093) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  57.104  0.0  31.158  0.908  31.159\n",
      "ValEpoch(093) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  56.893  0.0  5.323\n",
      "*****\n",
      " Epoch 94 of 100\n",
      "TrEpoch(094) - \n",
      "     acc     bmx  bmn     mse   spr     run\n",
      "0  10.0  57.022  0.0  31.117  0.92  31.118\n",
      "ValEpoch(094) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  56.954  0.0  5.325\n",
      "*****\n",
      " Epoch 95 of 100\n",
      "TrEpoch(095) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  56.954  0.0  31.075  0.904  31.076\n",
      "ValEpoch(095) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  56.281  0.0  5.359\n",
      "*****\n",
      " Epoch 96 of 100\n",
      "TrEpoch(096) - 4- False False\n",
      "cre tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "sp_loss: 0.0009861422004178166\n",
      "\n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  56.813  0.0  31.032  0.909  31.033\n",
      "ValEpoch(096) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  56.434  0.0  5.294\n",
      "*****\n",
      " Epoch 97 of 100\n",
      "TrEpoch(097) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  56.793  0.0  30.991  0.894  30.992\n",
      "ValEpoch(097) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  56.053  0.0  5.288\n",
      "*****\n",
      " Epoch 98 of 100\n",
      "TrEpoch(098) - \n",
      "     acc     bmx  bmn     mse    spr     run\n",
      "0  10.0  56.216  0.0  30.962  0.914  30.963\n",
      "ValEpoch(098) - \n",
      "     acc     bmx  bmn    run\n",
      "0  10.0  55.876  0.0  5.309\n",
      "*****\n",
      " Epoch 99 of 100\n",
      "TrEpoch(099) - \n",
      "     acc     bmx  bmn     mse    spr    run\n",
      "0  10.0  56.585  0.0  30.909  0.906  30.91\n",
      "ValEpoch(099) - \n",
      "     acc   bmx  bmn    run\n",
      "0  10.0  55.7  0.0  5.284\n",
      "4.26e+02 minutes\n"
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_ws :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"APPLY_LOG_SOFTMAX : \", APPLY_LOG_SOFTMAX)\n",
    "print(\"APPLY_SPARSITY_TO : \", APPLY_SPARSITY_TO)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param(\"+ str(reg_param) +\") * sp_loss\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc     bmx  bmn      mse      spr      run\n",
      "0   10.0  77.021  0.0  150.708  334.568  151.043\n",
      "1   10.0  83.415  0.0  104.233    4.809  104.238\n",
      "2   10.0  91.695  0.0   84.834    2.910   84.836\n",
      "3   10.0  90.201  0.0   78.060    2.807   78.063\n",
      "4   10.0  89.298  0.0   73.643    2.477   73.646\n",
      "5   10.0  93.021  0.0   69.797    2.031   69.799\n",
      "6   10.0  94.678  0.0   66.240    1.598   66.242\n",
      "7   10.0  95.276  0.0   63.928    1.532   63.930\n",
      "8   10.0  94.493  0.0   61.270    1.528   61.271\n",
      "9   10.0  93.688  0.0   59.866    1.502   59.868\n",
      "10  10.0  92.726  0.0   59.181    1.498   59.182\n",
      "11  10.0  92.244  0.0   57.268    1.424   57.269\n",
      "12  10.0  92.301  0.0   55.535    1.339   55.537\n",
      "13  10.0  91.872  0.0   54.320    1.257   54.321\n",
      "14  10.0  91.545  0.0   51.546    1.214   51.547\n",
      "15  10.0  90.692  0.0   49.910    1.203   49.911\n",
      "16  10.0  90.820  0.0   49.375    1.175   49.376\n",
      "17  10.0  88.667  0.0   49.014    1.203   49.015\n",
      "18  10.0  88.402  0.0   47.932    1.186   47.934\n",
      "19  10.0  87.858  0.0   46.735    1.161   46.736\n",
      "20  10.0  87.236  0.0   46.196    1.133   46.197\n",
      "21  10.0  87.174  0.0   45.862    1.155   45.863\n",
      "22  10.0  87.198  0.0   45.574    1.187   45.575\n",
      "23  10.0  86.905  0.0   45.030    1.184   45.031\n",
      "24  10.0  86.073  0.0   44.155    1.207   44.156\n",
      "25  10.0  85.405  0.0   43.702    1.213   43.703\n",
      "26  10.0  84.672  0.0   43.343    1.204   43.344\n",
      "27  10.0  84.268  0.0   42.983    1.215   42.985\n",
      "28  10.0  82.933  0.0   42.792    1.227   42.793\n",
      "29  10.0  82.598  0.0   42.626    1.259   42.627\n",
      "30  10.0  81.787  0.0   42.480    1.286   42.481\n",
      "31  10.0  80.848  0.0   42.340    1.307   42.342\n",
      "32  10.0  80.492  0.0   42.197    1.321   42.198\n",
      "33  10.0  80.152  0.0   42.054    1.342   42.056\n",
      "34  10.0  79.421  0.0   41.915    1.339   41.916\n",
      "35  10.0  77.886  0.0   41.748    1.328   41.749\n",
      "36  10.0  77.801  0.0   41.554    1.323   41.555\n",
      "37  10.0  77.152  0.0   41.336    1.308   41.338\n",
      "38  10.0  77.347  0.0   40.844    1.268   40.845\n",
      "39  10.0  75.885  0.0   39.737    1.261   39.739\n",
      "40  10.0  75.437  0.0   39.364    1.249   39.366\n",
      "41  10.0  75.003  0.0   39.172    1.234   39.174\n",
      "42  10.0  74.139  0.0   38.454    1.243   38.455\n",
      "43  10.0  74.419  0.0   38.001    1.247   38.002\n",
      "44  10.0  73.776  0.0   37.874    1.253   37.875\n",
      "45  10.0  72.809  0.0   37.757    1.259   37.758\n",
      "46  10.0  71.884  0.0   37.625    1.260   37.626\n",
      "47  10.0  70.833  0.0   36.825    1.262   36.826\n",
      "48  10.0  70.694  0.0   36.702    1.260   36.704\n",
      "49  10.0  68.735  0.0   36.605    1.268   36.607\n",
      "50  10.0  68.973  0.0   36.258    1.273   36.259\n",
      "51  10.0  68.602  0.0   35.734    1.270   35.735\n",
      "52  10.0  68.616  0.0   35.635    1.253   35.636\n",
      "53  10.0  67.460  0.0   35.529    1.240   35.530\n",
      "54  10.0  67.141  0.0   35.436    1.232   35.437\n",
      "55  10.0  67.167  0.0   35.339    1.214   35.340\n",
      "56  10.0  66.619  0.0   34.972    1.199   34.973\n",
      "57  10.0  66.361  0.0   34.786    1.177   34.787\n",
      "58  10.0  65.969  0.0   34.658    1.129   34.659\n",
      "59  10.0  65.698  0.0   34.260    1.096   34.261\n",
      "60  10.0  65.619  0.0   34.126    1.073   34.127\n",
      "61  10.0  65.426  0.0   33.791    1.049   33.792\n",
      "62  10.0  64.970  0.0   33.452    1.006   33.453\n",
      "63  10.0  64.337  0.0   33.373    1.002   33.374\n",
      "64  10.0  64.294  0.0   33.295    1.010   33.296\n",
      "65  10.0  63.954  0.0   33.215    0.989   33.216\n",
      "66  10.0  63.824  0.0   33.148    0.967   33.149\n",
      "67  10.0  63.131  0.0   33.084    0.973   33.085\n",
      "68  10.0  62.945  0.0   33.027    0.970   33.028\n",
      "69  10.0  62.747  0.0   32.961    0.969   32.962\n",
      "70  10.0  62.642  0.0   32.905    0.965   32.906\n",
      "71  10.0  61.922  0.0   32.851    0.970   32.852\n",
      "72  10.0  62.197  0.0   32.797    0.963   32.798\n",
      "73  10.0  61.308  0.0   32.728    0.965   32.729\n",
      "74  10.0  61.113  0.0   32.667    0.970   32.668\n",
      "75  10.0  60.982  0.0   32.612    0.983   32.613\n",
      "76  10.0  60.664  0.0   32.525    0.976   32.526\n",
      "77  10.0  60.534  0.0   32.235    0.973   32.236\n",
      "78  10.0  59.990  0.0   32.125    0.973   32.126\n",
      "79  10.0  60.880  0.0   32.035    0.952   32.036\n",
      "80  10.0  59.996  0.0   31.962    0.959   31.963\n",
      "81  10.0  60.447  0.0   31.894    0.956   31.895\n",
      "82  10.0  60.158  0.0   31.834    0.947   31.835\n",
      "83  10.0  59.640  0.0   31.774    0.967   31.775\n",
      "84  10.0  59.337  0.0   31.714    0.946   31.715\n",
      "85  10.0  59.293  0.0   31.664    0.942   31.665\n",
      "86  10.0  59.129  0.0   31.611    0.936   31.612\n",
      "87  10.0  58.892  0.0   31.555    0.937   31.556\n",
      "88  10.0  58.195  0.0   31.511    0.943   31.512\n",
      "89  10.0  58.069  0.0   31.399    0.933   31.400\n",
      "90  10.0  57.929  0.0   31.304    0.925   31.305\n",
      "91  10.0  57.703  0.0   31.252    0.927   31.253\n",
      "92  10.0  57.419  0.0   31.198    0.928   31.199\n",
      "93  10.0  57.104  0.0   31.158    0.908   31.159\n",
      "94  10.0  57.022  0.0   31.117    0.920   31.118\n",
      "95  10.0  56.954  0.0   31.075    0.904   31.076\n",
      "96  10.0  56.813  0.0   31.032    0.909   31.033\n",
      "97  10.0  56.793  0.0   30.991    0.894   30.992\n",
      "98  10.0  56.216  0.0   30.962    0.914   30.963\n",
      "99  10.0  56.585  0.0   30.909    0.906   30.910\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc     bmx  bmn     run\n",
      "0   10.0  75.509  0.0  18.407\n",
      "1   10.0  85.049  0.0  15.982\n",
      "2   10.0  87.592  0.0  13.367\n",
      "3   10.0  86.079  0.0  12.674\n",
      "4   10.0  88.085  0.0  11.910\n",
      "5   10.0  90.819  0.0  11.437\n",
      "6   10.0  91.628  0.0  10.879\n",
      "7   10.0  91.468  0.0  10.589\n",
      "8   10.0  90.637  0.0  10.095\n",
      "9   10.0  90.289  0.0   9.989\n",
      "10  10.0  89.450  0.0   9.795\n",
      "11  10.0  89.916  0.0   9.508\n",
      "12  10.0  89.976  0.0   9.215\n",
      "13  10.0  89.353  0.0   8.838\n",
      "14  10.0  88.732  0.0   8.452\n",
      "15  10.0  87.839  0.0   8.321\n",
      "16  10.0  86.789  0.0   8.263\n",
      "17  10.0  85.847  0.0   8.209\n",
      "18  10.0  85.420  0.0   7.920\n",
      "19  10.0  85.767  0.0   7.792\n",
      "20  10.0  84.872  0.0   7.744\n",
      "21  10.0  83.970  0.0   7.668\n",
      "22  10.0  84.017  0.0   7.633\n",
      "23  10.0  83.216  0.0   7.497\n",
      "24  10.0  82.991  0.0   7.360\n",
      "25  10.0  82.025  0.0   7.344\n",
      "26  10.0  81.619  0.0   7.243\n",
      "27  10.0  80.554  0.0   7.232\n",
      "28  10.0  80.161  0.0   7.199\n",
      "29  10.0  79.584  0.0   7.173\n",
      "30  10.0  78.662  0.0   7.145\n",
      "31  10.0  77.968  0.0   7.106\n",
      "32  10.0  77.773  0.0   7.093\n",
      "33  10.0  76.855  0.0   7.077\n",
      "34  10.0  75.958  0.0   7.045\n",
      "35  10.0  75.707  0.0   7.030\n",
      "36  10.0  74.552  0.0   6.989\n",
      "37  10.0  74.626  0.0   6.952\n",
      "38  10.0  73.655  0.0   6.787\n",
      "39  10.0  73.268  0.0   6.647\n",
      "40  10.0  72.848  0.0   6.624\n",
      "41  10.0  72.371  0.0   6.510\n",
      "42  10.0  71.693  0.0   6.454\n",
      "43  10.0  71.122  0.0   6.397\n",
      "44  10.0  70.874  0.0   6.385\n",
      "45  10.0  70.198  0.0   6.360\n",
      "46  10.0  69.532  0.0   6.233\n",
      "47  10.0  68.997  0.0   6.207\n",
      "48  10.0  68.373  0.0   6.196\n",
      "49  10.0  67.562  0.0   6.185\n",
      "50  10.0  67.036  0.0   6.050\n",
      "51  10.0  66.625  0.0   6.037\n",
      "52  10.0  65.663  0.0   6.022\n",
      "53  10.0  66.012  0.0   6.010\n",
      "54  10.0  65.212  0.0   5.992\n",
      "55  10.0  64.970  0.0   5.976\n",
      "56  10.0  64.474  0.0   5.934\n",
      "57  10.0  64.599  0.0   5.895\n",
      "58  10.0  64.214  0.0   5.868\n",
      "59  10.0  64.472  0.0   5.796\n",
      "60  10.0  64.266  0.0   5.782\n",
      "61  10.0  63.911  0.0   5.685\n",
      "62  10.0  63.622  0.0   5.666\n",
      "63  10.0  63.652  0.0   5.652\n",
      "64  10.0  63.092  0.0   5.652\n",
      "65  10.0  62.796  0.0   5.640\n",
      "66  10.0  62.193  0.0   5.622\n",
      "67  10.0  62.310  0.0   5.615\n",
      "68  10.0  61.791  0.0   5.621\n",
      "69  10.0  60.975  0.0   5.604\n",
      "70  10.0  60.763  0.0   5.596\n",
      "71  10.0  61.115  0.0   5.580\n",
      "72  10.0  60.439  0.0   5.569\n",
      "73  10.0  60.623  0.0   5.577\n",
      "74  10.0  59.913  0.0   5.563\n",
      "75  10.0  59.965  0.0   5.538\n",
      "76  10.0  59.309  0.0   5.528\n",
      "77  10.0  59.414  0.0   5.483\n",
      "78  10.0  59.753  0.0   5.459\n",
      "79  10.0  59.137  0.0   5.455\n",
      "80  10.0  59.498  0.0   5.432\n",
      "81  10.0  59.176  0.0   5.433\n",
      "82  10.0  59.117  0.0   5.430\n",
      "83  10.0  59.297  0.0   5.429\n",
      "84  10.0  58.448  0.0   5.397\n",
      "85  10.0  58.399  0.0   5.390\n",
      "86  10.0  58.055  0.0   5.403\n",
      "87  10.0  57.868  0.0   5.387\n",
      "88  10.0  57.745  0.0   5.371\n",
      "89  10.0  57.643  0.0   5.360\n",
      "90  10.0  57.183  0.0   5.336\n",
      "91  10.0  56.865  0.0   5.324\n",
      "92  10.0  57.066  0.0   5.325\n",
      "93  10.0  56.893  0.0   5.323\n",
      "94  10.0  56.954  0.0   5.325\n",
      "95  10.0  56.281  0.0   5.359\n",
      "96  10.0  56.434  0.0   5.294\n",
      "97  10.0  56.053  0.0   5.288\n",
      "98  10.0  55.876  0.0   5.309\n",
      "99  10.0  55.700  0.0   5.284\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tr acc =  10.0\n",
      "Max va acc =  10.0\n"
     ]
    }
   ],
   "source": [
    "tr_acc = result_df_tr_all.values[:,0].squeeze()\n",
    "va_acc = result_df_va_all.values[:,0].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_acc, color='orange', label='train acc')\n",
    "plt.plot(va_acc, color='red', label='validataion acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Max tr acc = \", np.max(tr_acc))\n",
    "print(\"Max va acc = \", np.max(va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_mse = result_df_tr_all.values[:,3].squeeze()\n",
    "tr_spr_50 = 100*result_df_tr_all.values[:,4].squeeze()\n",
    "va_err = 5*result_df_va_all.values[:,-1].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_mse, color='orange', label='train mse')\n",
    "plt.plot(tr_spr_50, color='red', label='tr spr*100')\n",
    "plt.plot(va_err, color='blue', label='va_err*5')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
