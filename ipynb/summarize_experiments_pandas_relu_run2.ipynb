{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib as impL\n",
    "sys.path.insert(1,'/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/vae_torch')\n",
    "sys.path.insert(1,'/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery')\n",
    "import vae_torch_model as vtm\n",
    "import vae_torch as vt\n",
    "#from data_classes import khs_dataset_v2\n",
    "import vae_scripts as vs\n",
    "import sae_torch as st\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import vae_utils as vu\n",
    "import pandas as pd\n",
    "import helperFuncs as funcH\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_err(experiments_folder, exp_base_name,cf_int,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=1):\n",
    "    ae_fold_name = os.path.join(experiments_folder, exp_base_name + str(cf_int).zfill(z_fill_int))\n",
    "    ae_f_name = os.path.join(ae_fold_name, ae_f_name_base)\n",
    "    vfz = np.load(ae_f_name, allow_pickle=True)\n",
    "    loss_log_dict = {}\n",
    "    n = 0\n",
    "    loss_log_dict[data_log_key] = vfz.item().get(data_log_key)\n",
    "    if loss_log_dict[data_log_key] is None:\n",
    "        print(\"cf(\"+str(cf_int)+\") --> loss_log_dict\"+str(data_log_key)+\"] is none\")\n",
    "        return None, None, None\n",
    "    n = len(loss_log_dict[data_log_key])\n",
    "    if verbose>0:\n",
    "        print(str(cf_int), ', ', data_log_key, \" - log is loaded with len: \", n)\n",
    "    if loss_key not in loss_log_dict[data_log_key][0].keys():\n",
    "        return n, None, None\n",
    "\n",
    "    if loss_key in loss_log_dict[data_log_key][0]:\n",
    "        vec_len = len(loss_log_dict[data_log_key])\n",
    "        los_vec_cur = [loss_log_dict[data_log_key][l][loss_key] for l in range(0, vec_len)]\n",
    "        label_str = str(cf_int) + '_' + data_log_key + '_' + loss_key\n",
    "        if verbose>0:\n",
    "            print(label_str, los_vec_cur[-3:], \"\\nmax({:4.2f}),min({:4.2f})\".format(np.max(los_vec_cur), np.min(los_vec_cur)))\n",
    "        return n, np.min(los_vec_cur), np.max(los_vec_cur)\n",
    "    return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "impL.reload(vu)\n",
    "experiments_folder='/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/FM/'\n",
    "config_folder = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/configs/'\n",
    "z_fill_int=2\n",
    "loss_key='reconstruction' # sparsity, bottleneck_kmeans, bottleneck_act\n",
    "data_log_keys=['tr_te']  # ['tr_va', 'va', 'te']\n",
    "exp_base_name='exp_conv_ae_simple_is28_cf'\n",
    "ae_f_name_base='ae_ft_conv_ae_simple_is28.npy'\n",
    "#cf_int_arr=[201,202,203,204,205,206,207,208,209,210,211,212,213,214,216,217,218]\n",
    "#cf_int_arr=[201,204,205,207,213,214]\n",
    "#cf_int_arr=[201,204,205,216,217,218]\n",
    "#cf_int_arr=[220,221,222,223,224,225,226,227]\n",
    "cf_int_arr=np.asarray(range(220,249), dtype=int)\n",
    "df1 = pd.DataFrame(index=cf_int_arr, columns=['spMethod','spW','spR','kl_div','bact','sigm','logsm','lact','rcErr','lr','rcRed'])\n",
    "df2 = pd.DataFrame(index=cf_int_arr, columns=['n','bActMin','bActMax','bErrMin','bErrMax','kmMin','kmMax','rErrMax','rErrMin'])\n",
    "df3 = pd.DataFrame(index=cf_int_arr, columns=['n','bActMin','bActMax','bErrMin','bErrMax','kmMin','kmMax','rErrMax','rErrMin'])\n",
    "df4 = pd.DataFrame(index=cf_int_arr, columns=['kl_div','bact','sigm','logsm','lr', 'n','bActMax','bErrMin','bErrDif','kmMax','rErrDif'])\n",
    "for i in range(0,len(cf_int_arr)):\n",
    "    cf = cf_int_arr[i]\n",
    "    #load model yaml as config\n",
    "    config_file = os.path.join(config_folder, 'conf_autoencoder_'+str(cf)+'.yaml')\n",
    "    CONF_PARAMS_ = funcH.CustomConfigParser(config_file=config_file)\n",
    "    df1.iloc[i]['spW'] = float(CONF_PARAMS_.MODEL.SPARSITY_WEIGHT)\n",
    "    if df1.iloc[i]['spW'] > 0:\n",
    "        df1.iloc[i]['spMethod'] = CONF_PARAMS_.MODEL.SPARSITY_ERROR\n",
    "        df1.iloc[i]['spR'] = CONF_PARAMS_.MODEL.SPARSITY_REDUCTION\n",
    "    else:\n",
    "        df1.iloc[i]['spW'] = None\n",
    "    df1.iloc[i]['kl_div'] = CONF_PARAMS_.MODEL.KL_DIV_RHO if 'kl_' in str(CONF_PARAMS_.MODEL.SPARSITY_ERROR) else None\n",
    "    df4.iloc[i]['kl_div'] = df1.iloc[i]['kl_div']\n",
    "    try:\n",
    "        df1.iloc[i]['bact'] = (CONF_PARAMS_.MODEL.LAYERS.encoder.l04_act).replace('type: ','').replace(',dim:','')\n",
    "        df4.iloc[i]['bact'] = df1.iloc[i]['bact']\n",
    "    except:\n",
    "        pass\n",
    "    df1.iloc[i]['sigm'] = CONF_PARAMS_.MODEL.KL_SIGMOID\n",
    "    df4.iloc[i]['sigm'] = df1.iloc[i]['sigm']\n",
    "    df1.iloc[i]['logsm'] = CONF_PARAMS_.MODEL.KL_LOGSOFTMAX\n",
    "    df4.iloc[i]['logsm'] = df1.iloc[i]['logsm']\n",
    "    try:\n",
    "        df1.iloc[i]['lact'] = CONF_PARAMS_.MODEL.LAYERS.decoder.l01_act.replace('type: ','')\n",
    "    except:\n",
    "        pass\n",
    "    df1.iloc[i]['rcErr'] = CONF_PARAMS_.MODEL.RECONSTRUCTION_ERROR_FUNCTION\n",
    "    df1.iloc[i]['lr'] = CONF_PARAMS_.MODEL.LEARNING_RATE\n",
    "    df4.iloc[i]['lr'] = df1.iloc[i]['lr']\n",
    "    df1.iloc[i]['rcRed'] = CONF_PARAMS_.MODEL.RECONSTRUCTION_ERROR_REDUCTION\n",
    "    \n",
    "    try:\n",
    "        data_log_key = 'tr_te'\n",
    "        loss_key = 'reconstruction' # reconstruction bottleneck_kmeans bottleneck_act sparsity\n",
    "        n, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df2.iloc[i]['n'] = n\n",
    "        df4.iloc[i]['n'] = df2.iloc[i]['n']\n",
    "\n",
    "        df2.iloc[i]['rErrMin'] = mn\n",
    "        df2.iloc[i]['rErrMax'] = mx\n",
    "        df4.iloc[i]['rErrDif'] = df2.iloc[i]['rErrMax']-df2.iloc[i]['rErrMin']\n",
    "            \n",
    "        loss_key = 'bottleneck_kmeans' # bottleneck_act sparsity\n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df2.iloc[i]['kmMin'] = mn\n",
    "        df2.iloc[i]['kmMax'] = mx\n",
    "\n",
    "        loss_key = 'bottleneck_act' #  sparsity\n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df2.iloc[i]['bActMin'] = mn\n",
    "        df2.iloc[i]['bActMax'] = mx if mx!=mn else '_n*c_'\n",
    "        df4.iloc[i]['bActMax'] = df2.iloc[i]['bActMax']\n",
    "\n",
    "        loss_key = 'sparsity' #  \n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df2.iloc[i]['bErrMin'] = mn\n",
    "        df2.iloc[i]['bErrMax'] = mx if mx!=mn else '_n*c_'\n",
    "        df4.iloc[i]['bErrMin'] = df2.iloc[i]['bErrMin']\n",
    "\n",
    "        try:\n",
    "            df4.iloc[i]['bErrDif'] = df2.iloc[i]['bErrMax']-df2.iloc[i]['bErrMin']\n",
    "        except:\n",
    "            df4.iloc[i]['bErrDif'] = 0\n",
    "        data_log_key = 'te'\n",
    "        loss_key = 'reconstruction' # reconstruction bottleneck_kmeans bottleneck_act sparsity\n",
    "        n, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df3.iloc[i]['n'] = n\n",
    "\n",
    "        df3.iloc[i]['rErrMin'] = mn\n",
    "        df3.iloc[i]['rErrMax'] = mx\n",
    "\n",
    "        loss_key = 'bottleneck_kmeans' # bottleneck_act sparsity\n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df3.iloc[i]['kmMin'] = mn\n",
    "        df3.iloc[i]['kmMax'] = mx\n",
    "        df4.iloc[i]['kmMax'] = df2.iloc[i]['kmMax']\n",
    "\n",
    "        loss_key = 'bottleneck_act' #  sparsity\n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df3.iloc[i]['bActMin'] = mn\n",
    "        df3.iloc[i]['bActMax'] = mx if mx!=mn else '_n*c_'\n",
    "\n",
    "        loss_key = 'sparsity' #  \n",
    "        _, mn, mx = get_acc_err(experiments_folder, exp_base_name,cf,ae_f_name_base,data_log_key,loss_key,z_fill_int=3,verbose=0)\n",
    "        df3.iloc[i]['bErrMin'] = mn\n",
    "        df3.iloc[i]['bErrMax'] = mx if mx!=mn else '_n*c_'\n",
    "    except:\n",
    "        print(\"no data available for d3 - \", cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments explanations\n",
      "          spMethod    spW        spR  kl_div  bact   sigm  logsm lact rcErr      lr rcRed\n",
      "220  kl_divergence  0.001  batchmean  0.0001  ReLu   True   True  NaN   MSE    0.01  mean\n",
      "221  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE    0.01  mean\n",
      "222  kl_divergence  0.001  batchmean  0.0001  ReLu  False  False  NaN   MSE    0.01  mean\n",
      "223  kl_divergence  0.001  batchmean  0.0001  ReLu  False   True  NaN   MSE    0.01  mean\n",
      "224  kl_divergence  0.001  batchmean  0.0001   NaN   True   True  NaN   MSE    0.01  mean\n",
      "225  kl_divergence  0.001  batchmean  0.0001   NaN   True  False  NaN   MSE    0.01  mean\n",
      "226  kl_divergence  0.001  batchmean  0.0001   NaN  False  False  NaN   MSE    0.01  mean\n",
      "227  kl_divergence  0.001  batchmean  0.0001   NaN  False   True  NaN   MSE    0.01  mean\n",
      "228  kl_divergence  0.001  batchmean  0.0001  ReLu   True   True  NaN   MSE   0.001  mean\n",
      "229  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE   0.001  mean\n",
      "230  kl_divergence  0.001  batchmean  0.0001  ReLu  False  False  NaN   MSE   0.001  mean\n",
      "231  kl_divergence  0.001  batchmean  0.0001  ReLu  False   True  NaN   MSE   0.001  mean\n",
      "232  kl_divergence  0.001  batchmean  0.0001   NaN   True   True  NaN   MSE   0.001  mean\n",
      "233  kl_divergence  0.001  batchmean  0.0001   NaN   True  False  NaN   MSE   0.001  mean\n",
      "234  kl_divergence  0.001  batchmean  0.0001   NaN  False  False  NaN   MSE   0.001  mean\n",
      "235  kl_divergence  0.001  batchmean  0.0001   NaN  False   True  NaN   MSE   0.001  mean\n",
      "236  kl_divergence  0.001  batchmean  0.0001  ReLu   True   True  NaN   MSE  0.0001  mean\n",
      "237  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE  0.0001  mean\n",
      "238  kl_divergence  0.001  batchmean  0.0001  ReLu  False  False  NaN   MSE  0.0001  mean\n",
      "239  kl_divergence  0.001  batchmean  0.0001  ReLu  False   True  NaN   MSE  0.0001  mean\n",
      "240  kl_divergence  0.001  batchmean  0.0001   NaN   True   True  NaN   MSE  0.0001  mean\n",
      "241  kl_divergence  0.001  batchmean  0.0001   NaN   True  False  NaN   MSE  0.0001  mean\n",
      "242  kl_divergence  0.001  batchmean  0.0001   NaN  False  False  NaN   MSE  0.0001  mean\n",
      "243  kl_divergence  0.001  batchmean  0.0001   NaN  False   True  NaN   MSE  0.0001  mean\n",
      "244  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE  0.0001  mean\n",
      "245  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE  0.0001  mean\n",
      "246  kl_divergence  0.001  batchmean  0.0001  ReLu   True  False  NaN   MSE  0.0001  mean\n",
      "247  kl_divergence  0.001        sum  0.0001  ReLu   True  False  NaN   MSE  0.0001  mean\n",
      "248  kl_divergence  0.001        sum  0.0001  ReLu   True   True  NaN   MSE  0.0001  mean\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.precision\", 2)\n",
    "print('experiments explanations')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_te dataset results\n",
      "       n bActMin bActMax     bErrMin  bErrMax   kmMin   kmMax rErrMax rErrMin\n",
      "220   10      10   _n*c_     0.20336  0.30914      10  19.812  50.796  47.029\n",
      "221   10      10   _n*c_     -1874.5  -1871.6    8.56  13.008  50.082  47.497\n",
      "222   10      10   _n*c_     -1705.2  -1696.6      10   13.02  53.554  48.151\n",
      "223   10      10   _n*c_      3.1483   5.3453   8.075   34.23  50.265  47.605\n",
      "224   10      10   _n*c_     0.33957  0.39402      10  16.293  50.158  47.569\n",
      "225   10      10   _n*c_     -1872.2  -1869.4      10  17.693  51.232  47.326\n",
      "226   10      10   _n*c_     -1697.2  -1687.7  5.8517  15.805  51.149  47.193\n",
      "227   10      10   _n*c_      5.4157   6.1237      10  20.632  51.185  47.148\n",
      "228   10      10   _n*c_      1.6792   6.3684  15.497  21.088  39.204   38.27\n",
      "229   10      10   _n*c_       -2008  -1960.1  14.718  20.472  39.469  38.468\n",
      "230   10      10   _n*c_ -8.8827e+12  -2864.2  16.375  20.825  96.826  38.334\n",
      "231   10      10  16.915 -2.5379e-05   55.112  14.588  21.348  39.267  37.444\n",
      "232   10      10   _n*c_      12.116   17.597    18.1  21.708  39.199  38.142\n",
      "233   10      10   _n*c_     -2006.5  -1876.7  16.597  22.057  39.658  37.037\n",
      "234   10      10  12.483 -1.2647e+14  -2965.4  15.852  20.593  96.826  37.794\n",
      "235   10      10  18.575 -1.9639e-05   242.91  15.363  20.772  39.443  38.481\n",
      "236   10      10   _n*c_      6.2903   7.5886   16.32  21.037  54.814  39.408\n",
      "237   10      10   _n*c_     -1978.1  -1917.9  15.577  20.503  54.863  38.971\n",
      "238   10      10   _n*c_     -3013.6  -1985.5  16.063  22.305  54.879  39.218\n",
      "239   10      10   _n*c_      35.047   202.78  17.283   21.34  54.758  38.887\n",
      "240   10      10   _n*c_      13.976   16.882  16.798   20.71  54.096  38.851\n",
      "241   10      10   _n*c_     -1920.6  -1845.6  17.348  21.345  54.073  39.273\n",
      "242   10      10   _n*c_     -3564.7  -1610.3  15.903  20.382  54.471  39.031\n",
      "243   10      10   _n*c_      183.39   252.04  16.712  21.313  54.857  38.849\n",
      "244   10      10   _n*c_     -245.64  -241.11  16.018  22.435  175.23   122.9\n",
      "245  500   14.31  31.188     -427.88  -414.09  32.313  57.857  111.67  24.956\n",
      "246  500  15.552  28.868     -6540.4  -6385.9  34.862  58.475  108.08  25.027\n",
      "247  700  18.542  34.215      -13321   -12946  34.988   55.04  105.07  25.999\n",
      "248  700  17.565   37.96      30.292   1081.9  38.312  65.963  98.586  26.455\n"
     ]
    }
   ],
   "source": [
    "print('tr_te dataset results')\n",
    "pd.set_option(\"display.precision\", 5)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te dataset results\n",
      "       n bActMin bActMax     bErrMin   bErrMax  kmMin  kmMax rErrMax rErrMin\n",
      "220   10      10   _n*c_    0.034255  0.052072     10  23.89  8.5156  7.8816\n",
      "221   10      10   _n*c_     -315.75   -315.25     10  12.88  8.3941  7.9609\n",
      "222   10      10   _n*c_     -287.22   -285.79     10  14.61  8.9803  8.0696\n",
      "223   10      10   _n*c_      0.5303   0.90038     10   29.8  8.4276  7.9799\n",
      "224   10      10   _n*c_    0.057198  0.066369     10  27.17  8.4094  7.9729\n",
      "225   10      10   _n*c_     -315.36   -314.89     10  20.18   8.586  7.9339\n",
      "226   10      10   _n*c_     -285.88   -284.28     10   15.8  8.5754  7.9101\n",
      "227   10      10   _n*c_     0.91223    1.0315     10  25.09  8.5766  7.9016\n",
      "228   10      10   _n*c_     0.28382    1.0741  15.77  22.33  6.5801  6.4221\n",
      "229   10      10   _n*c_     -338.26   -330.19  14.79  19.74  6.6235  6.4551\n",
      "230   10      10   _n*c_ -1.4967e+12   -482.42   15.5   21.2  16.269  6.4339\n",
      "231   10      10    21.8 -4.4564e-06    9.2733   15.8  20.46  6.5893  6.2846\n",
      "232   10      10   _n*c_      2.0427    2.9648   14.4  20.53  6.5798  6.4017\n",
      "233   10      10   _n*c_     -337.99   -316.13  16.08  21.69  6.6554  6.2161\n",
      "234   10      10    12.4 -2.1311e+13   -499.48  14.86  21.07  16.269  6.3423\n",
      "235   10      10   14.58  -3.254e-06    40.878  14.86   21.1  6.6204  6.4567\n",
      "236   10      10   _n*c_      1.0601    1.2795  14.36  20.05  9.2038   6.614\n",
      "237   10      10   _n*c_     -333.21   -323.06  17.28  20.68   9.212    6.54\n",
      "238   10      10   _n*c_     -507.63   -334.46  15.04  18.77  9.2144  6.5809\n",
      "239   10      10   _n*c_      5.8987    34.112  17.72  21.26  9.1941  6.5261\n",
      "240   10      10   _n*c_      2.3538    2.8447   15.5  21.92  9.0819  6.5199\n",
      "241   10      10   _n*c_     -323.53   -310.88  16.59  22.02  9.0781  6.5912\n",
      "242   10      10   _n*c_     -600.44   -271.24  16.83  21.17  9.1445  6.5507\n",
      "243   10      10   _n*c_      30.878    42.414  15.53  21.61  9.2096  6.5203\n",
      "244   10      10   _n*c_     -41.008   -40.251  16.21  20.11  29.185  20.432\n",
      "245  500   16.46   33.67     -71.431   -69.133  35.84  56.14  18.607  4.4783\n",
      "246  500   16.78   23.44     -1091.8     -1066  37.48  60.67  18.017  4.5796\n",
      "247  700   15.11   30.13     -2220.2   -2157.9  37.98  54.56  17.515  4.7493\n",
      "248  700   11.18      39      5.0336    180.14   38.5  65.97  16.446  4.7972\n"
     ]
    }
   ],
   "source": [
    "print('te dataset results')\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picky results\n",
      "     kl_div  bact   sigm  logsm      lr    n bActMax     bErrMin     bErrDif   kmMax  rErrDif\n",
      "220  0.0001  ReLu   True   True    0.01   10   _n*c_     0.20336     0.10578  19.812    3.767\n",
      "221  0.0001  ReLu   True  False    0.01   10   _n*c_     -1874.5      2.9479  13.008   2.5853\n",
      "222  0.0001  ReLu  False  False    0.01   10   _n*c_     -1705.2      8.5145   13.02   5.4032\n",
      "223  0.0001  ReLu  False   True    0.01   10   _n*c_      3.1483       2.197   34.23   2.6604\n",
      "224  0.0001   NaN   True   True    0.01   10   _n*c_     0.33957    0.054449  16.293   2.5886\n",
      "225  0.0001   NaN   True  False    0.01   10   _n*c_     -1872.2      2.7629  17.693   3.9059\n",
      "226  0.0001   NaN  False  False    0.01   10   _n*c_     -1697.2      9.4812  15.805   3.9562\n",
      "227  0.0001   NaN  False   True    0.01   10   _n*c_      5.4157     0.70804  20.632    4.037\n",
      "228  0.0001  ReLu   True   True   0.001   10   _n*c_      1.6792      4.6892  21.088  0.93429\n",
      "229  0.0001  ReLu   True  False   0.001   10   _n*c_       -2008      47.892  20.472   1.0013\n",
      "230  0.0001  ReLu  False  False   0.001   10   _n*c_ -8.8827e+12  8.8827e+12  20.825   58.492\n",
      "231  0.0001  ReLu  False   True   0.001   10  16.915 -2.5379e-05      55.112  21.348   1.8235\n",
      "232  0.0001   NaN   True   True   0.001   10   _n*c_      12.116      5.4805  21.708   1.0568\n",
      "233  0.0001   NaN   True  False   0.001   10   _n*c_     -2006.5      129.72  22.057    2.621\n",
      "234  0.0001   NaN  False  False   0.001   10  12.483 -1.2647e+14  1.2647e+14  20.593   59.032\n",
      "235  0.0001   NaN  False   True   0.001   10  18.575 -1.9639e-05      242.91  20.772  0.96169\n",
      "236  0.0001  ReLu   True   True  0.0001   10   _n*c_      6.2903      1.2983  21.037   15.406\n",
      "237  0.0001  ReLu   True  False  0.0001   10   _n*c_     -1978.1       60.22  20.503   15.892\n",
      "238  0.0001  ReLu  False  False  0.0001   10   _n*c_     -3013.6      1028.1  22.305   15.661\n",
      "239  0.0001  ReLu  False   True  0.0001   10   _n*c_      35.047      167.73   21.34   15.871\n",
      "240  0.0001   NaN   True   True  0.0001   10   _n*c_      13.976      2.9059   20.71   15.245\n",
      "241  0.0001   NaN   True  False  0.0001   10   _n*c_     -1920.6      75.033  21.345   14.801\n",
      "242  0.0001   NaN  False  False  0.0001   10   _n*c_     -3564.7      1954.4  20.382    15.44\n",
      "243  0.0001   NaN  False   True  0.0001   10   _n*c_      183.39      68.646  21.313   16.008\n",
      "244  0.0001  ReLu   True  False  0.0001   10   _n*c_     -245.64      4.5331  22.435   52.334\n",
      "245  0.0001  ReLu   True  False  0.0001  500  31.188     -427.88      13.788  57.857   86.712\n",
      "246  0.0001  ReLu   True  False  0.0001  500  28.868     -6540.4      154.51  58.475   83.048\n",
      "247  0.0001  ReLu   True  False  0.0001  700  34.215      -13321      374.33   55.04   79.072\n",
      "248  0.0001  ReLu   True   True  0.0001  700   37.96      30.292      1051.6  65.963   72.131\n"
     ]
    }
   ],
   "source": [
    "print('picky results')\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
