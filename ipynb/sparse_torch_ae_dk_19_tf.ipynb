{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:  1.1.0\n",
      "torch:  1.6.0\n",
      "numpy:  1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "import pandas as pd\n",
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"torch: \", torch.__version__)\n",
    "print(\"numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsubuntu_khs_dir = /home/wsubuntu/GitHub/keyhandshapediscovery\n",
      "wsubuntu_data_path = /media/wsubuntu/SSD_Data/DataPath\n",
      "wsubuntu_experiment_path = /media/wsubuntu/SSD_Data/vaesae_experiments\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "def get_var_by_comp_name(variableName):\n",
    "    curCompName = socket.gethostname()\n",
    "    retVal = None\n",
    "    if variableName == 'khs_dir':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/home/wsubuntu/GitHub/keyhandshapediscovery'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'data_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/Datasets'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/DataPath'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'experiment_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/SPARSE_TORCH'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/vaesae_experiments'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "        \n",
    "    print(curCompName + '_' + variableName, '=',  retVal)\n",
    "    if retVal is None:\n",
    "        os.error(5)\n",
    "    return retVal\n",
    "\n",
    "khs_dir = get_var_by_comp_name('khs_dir')\n",
    "data_path = get_var_by_comp_name('data_path')\n",
    "experiment_path = get_var_by_comp_name('experiment_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, khs_dir)\n",
    "import helperFuncs as funcH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 19\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'batchmean','sum'\n",
    "SIGMOID_ACT=True\n",
    "APPLY_LOG_SOFTMAX=False\n",
    "MSE_PLUS_MINUS='+'\n",
    "APPLY_SPARSITY_TO='bottleneck' #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 100  # args['epochs']\n",
    "reg_param = 0.1  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": data_path,\n",
    "    \"experiment\": os.path.join(experiment_path, 'sparse_torch_ae_' + str(EXPERIMENT_ID).zfill(3)),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseAutoencoder - loss_type(cre), device(cpu)\n"
     ]
    }
   ],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=32)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    "        print(\"SparseAutoencoder - loss_type(\" + loss_type +\"), device(\" + self.device + \")\")\n",
    "\n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        if self.loss_type=='cre':\n",
    "            bottleneck = self.enc5(x) \n",
    "        else:\n",
    "            bottleneck = F.relu(self.enc5(x))  \n",
    "        \n",
    "        return bottleneck\n",
    "        \n",
    "    def decode(self, bottleneck):\n",
    "        # decoding\n",
    "        if self.loss_type=='cre':\n",
    "            x = F.relu(self.dec1(F.relu(bottleneck)))\n",
    "        else:\n",
    "            x = F.relu(self.dec1(bottleneck))\n",
    "        \n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x)) \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encode(x)\n",
    "        x = self.decode(bottleneck)\n",
    "        return x, bottleneck\n",
    "\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    rho_val = 1/bt.size(1)\n",
    "    rho_mat = torch.tensor([rho_val] * np.ones(bt.size()), dtype=torch.float32).to(device)\n",
    "    #https://discuss.pytorch.org/t/kl-divergence-produces-negative-values/16791/13\n",
    "    #KLDLoss(p, q), sum(q) needs to equal one\n",
    "    #p = log_softmax(tensor)\n",
    "    loss_ret_1 = F.kl_div(F.log_softmax(bt, dim=1).to(device), rho_mat, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct and apply_log_softmax:  \n",
    "        if print_info:\n",
    "            print(\"1-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    elif sigmoidAct and not apply_log_softmax:     \n",
    "        if print_info:\n",
    "            print(\"2-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(bt.to(device), preds)    \n",
    "    elif not sigmoidAct and apply_log_softmax:\n",
    "        if print_info:\n",
    "            print(\"3-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bottleneck, dim=1).to(device), preds)    \n",
    "    else:#nothing\n",
    "        if print_info:\n",
    "            print(\"4-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(bottleneck.to(device), preds)\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy_old(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct:\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    else:\n",
    "        bt = bottleneck    \n",
    "    _, preds = torch.max(bt, 1)\n",
    "    loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss\n",
    "\n",
    "def sparse_loss_bottleneck(bottleneck, print_info, loss_type):\n",
    "    loss = 0\n",
    "    #if print_info:\n",
    "        #print(i, ' shape=', values.shape)\n",
    "    if loss_type=='l1':\n",
    "        loss += loss_l1(bottleneck)\n",
    "    if loss_type=='l2':\n",
    "        loss += loss_l2(bottleneck)\n",
    "    if loss_type=='kl':\n",
    "        loss += kl_divergence(bottleneck, reduction=LOSS_REDUCTION)\n",
    "    if loss_type=='cre':\n",
    "        loss += loss_crossentropy(bottleneck, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "    if print_info:\n",
    "        print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            if APPLY_SPARSITY_TO=='all':\n",
    "                sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            elif APPLY_SPARSITY_TO=='bottleneck': #all\n",
    "                sp_loss = sparse_loss_bottleneck(bottleneck, print_losses_fit, model.loss_type)\n",
    "            else:\n",
    "                os.exit(4)\n",
    "                \n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            \n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "                \n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_ws :: \n",
      "EXPERIMENT_ID:  19\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  True\n",
      "APPLY_LOG_SOFTMAX :  False\n",
      "APPLY_SPARSITY_TO :  bottleneck\n",
      "total loss = mse_loss + reg_param * sp_loss\n",
      "*****\n",
      " Epoch 0 of 100\n",
      "TrEpoch(000) - 2- True False\n",
      "cre tensor(3.4240, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.4240310192108154\n",
      "\n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  92.225 -189.058  197.346  4827.657  680.112\n",
      "ValEpoch(000) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  89.787 -182.877  30.054\n",
      "*****\n",
      " Epoch 1 of 100\n",
      "TrEpoch(001) - \n",
      "     acc      bmx      bmn      mse       spr      run\n",
      "0  10.0  168.907 -312.373  168.458  4722.798  640.737\n",
      "ValEpoch(001) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  164.902 -302.205  25.971\n",
      "*****\n",
      " Epoch 2 of 100\n",
      "TrEpoch(002) - \n",
      "     acc      bmx      bmn      mse     spr      run\n",
      "0  10.0  174.432 -316.937  150.784  4722.4  623.024\n",
      "ValEpoch(002) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  151.153 -272.989  24.037\n",
      "*****\n",
      " Epoch 3 of 100\n",
      "TrEpoch(003) - \n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  146.81 -268.846  140.516  4722.368  612.752\n",
      "ValEpoch(003) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  126.842 -229.728  23.055\n",
      "*****\n",
      " Epoch 4 of 100\n",
      "TrEpoch(004) - \n",
      "     acc      bmx      bmn      mse       spr      run\n",
      "0  10.0  129.443 -238.105  135.747  4722.321  607.979\n",
      "ValEpoch(004) - \n",
      "     acc      bmx    bmn    run\n",
      "0  10.0  110.511 -202.7  22.35\n",
      "*****\n",
      " Epoch 5 of 100\n",
      "TrEpoch(005) - \n",
      "     acc      bmx      bmn      mse       spr      run\n",
      "0  10.0  110.626 -224.732  132.683  4722.233  604.907\n",
      "ValEpoch(005) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  102.805 -207.912  22.011\n",
      "*****\n",
      " Epoch 6 of 100\n",
      "TrEpoch(006) - 2- True False\n",
      "cre tensor(2.5185, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5185375213623047\n",
      "\n",
      "     acc      bmx      bmn      mse       spr      run\n",
      "0  10.0  102.918 -218.264  129.028  4722.132  601.241\n",
      "ValEpoch(006) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  95.338 -204.94  21.263\n",
      "*****\n",
      " Epoch 7 of 100\n",
      "TrEpoch(007) - \n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  97.235 -217.961  126.539  4722.129  598.752\n",
      "ValEpoch(007) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  85.646 -180.045  20.991\n",
      "*****\n",
      " Epoch 8 of 100\n",
      "TrEpoch(008) - \n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  89.925 -203.423  123.797  4722.137  596.011\n",
      "ValEpoch(008) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  84.644 -188.591  20.332\n",
      "*****\n",
      " Epoch 9 of 100\n",
      "TrEpoch(009) - \n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  86.669 -221.042  120.761  4722.113  592.973\n",
      "ValEpoch(009) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  79.996 -196.021  20.156\n",
      "*****\n",
      " Epoch 10 of 100\n",
      "TrEpoch(010) - \n",
      "     acc     bmx      bmn      mse       spr     run\n",
      "0  10.0  85.997 -220.549  118.533  4722.162  590.75\n",
      "ValEpoch(010) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  83.257 -218.229  19.672\n",
      "*****\n",
      " Epoch 11 of 100\n",
      "TrEpoch(011) - 2- True False\n",
      "cre tensor(2.5182, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5181570053100586\n",
      "\n",
      "     acc    bmx      bmn      mse       spr      run\n",
      "0  10.0  86.48 -240.653  117.132  4722.189  589.351\n",
      "ValEpoch(011) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  84.535 -221.944  19.538\n",
      "*****\n",
      " Epoch 12 of 100\n",
      "TrEpoch(012) - \n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  86.271 -239.334  116.321  4722.311  588.552\n",
      "ValEpoch(012) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  79.887 -206.261  19.443\n",
      "*****\n",
      " Epoch 13 of 100\n",
      "TrEpoch(013) - \n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  85.883 -257.564  115.294  4722.314  587.526\n",
      "ValEpoch(013) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  84.677 -233.302  19.184\n",
      "*****\n",
      " Epoch 14 of 100\n",
      "TrEpoch(014) - \n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  89.588 -266.816  113.861  4722.265  586.087\n",
      "ValEpoch(014) - \n",
      "     acc   bmx      bmn     run\n",
      "0  10.0  88.8 -255.005  18.904\n",
      "*****\n",
      " Epoch 15 of 100\n",
      "TrEpoch(015) - \n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  92.335 -273.012  112.809  4722.254  585.035\n",
      "ValEpoch(015) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  92.418 -272.825  19.062\n",
      "*****\n",
      " Epoch 16 of 100\n",
      "TrEpoch(016) - 2- True False\n",
      "cre tensor(2.5196, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5196409225463867\n",
      "\n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  95.706 -304.432  112.475  4722.231  584.698\n",
      "ValEpoch(016) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  92.958 -278.553  18.743\n",
      "*****\n",
      " Epoch 17 of 100\n",
      "TrEpoch(017) - \n",
      "     acc    bmx      bmn      mse       spr      run\n",
      "0  10.0  95.29 -289.415  111.346  4722.203  583.566\n",
      "ValEpoch(017) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  87.708 -248.437  18.712\n",
      "*****\n",
      " Epoch 18 of 100\n",
      "TrEpoch(018) - \n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  93.198 -283.979  110.864  4722.234  583.088\n",
      "ValEpoch(018) - \n",
      "     acc     bmx     bmn     run\n",
      "0  10.0  95.071 -287.66  18.491\n",
      "*****\n",
      " Epoch 19 of 100\n",
      "TrEpoch(019) - \n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  93.627 -299.544  109.923  4722.203  582.143\n",
      "ValEpoch(019) - \n",
      "     acc    bmx      bmn     run\n",
      "0  10.0  92.27 -276.804  18.184\n",
      "*****\n",
      " Epoch 20 of 100\n",
      "TrEpoch(020) - \n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  96.966 -293.486  107.906  4722.252  580.131\n",
      "ValEpoch(020) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  99.436 -284.487  18.015\n",
      "*****\n",
      " Epoch 21 of 100\n",
      "TrEpoch(021) - 2- True False\n",
      "cre tensor(2.5182, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.51823091506958\n",
      "\n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  99.874 -305.453  106.948  4722.256  579.173\n",
      "ValEpoch(021) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  104.512 -309.176  17.891\n",
      "*****\n",
      " Epoch 22 of 100\n",
      "TrEpoch(022) - \n",
      "     acc     bmx      bmn     mse       spr      run\n",
      "0  10.0  98.841 -307.014  106.52  4722.318  578.752\n",
      "ValEpoch(022) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  102.412 -284.729  17.803\n",
      "*****\n",
      " Epoch 23 of 100\n",
      "TrEpoch(023) - \n",
      "     acc      bmx     bmn      mse       spr      run\n",
      "0  10.0  100.778 -299.66  106.053  4722.295  578.282\n",
      "ValEpoch(023) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  103.575 -288.746  17.657\n",
      "*****\n",
      " Epoch 24 of 100\n",
      "TrEpoch(024) - \n",
      "     acc      bmx      bmn      mse       spr      run\n",
      "0  10.0  105.482 -298.083  105.277  4722.377  577.515\n",
      "ValEpoch(024) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  102.038 -280.593  17.508\n",
      "*****\n",
      " Epoch 25 of 100\n",
      "TrEpoch(025) - \n",
      "     acc      bmx      bmn      mse       spr      run\n",
      "0  10.0  106.354 -315.441  104.269  4722.341  576.503\n",
      "ValEpoch(025) - \n",
      "     acc      bmx      bmn   run\n",
      "0  10.0  102.658 -287.343  17.5\n",
      "*****\n",
      " Epoch 26 of 100\n",
      "TrEpoch(026) - 2- True False\n",
      "cre tensor(2.5201, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.520129442214966\n",
      "\n",
      "     acc      bmx      bmn      mse       spr      run\n",
      "0  10.0  107.764 -310.898  103.248  4722.328  575.481\n",
      "ValEpoch(026) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  109.192 -303.422  17.259\n",
      "*****\n",
      " Epoch 27 of 100\n",
      "TrEpoch(027) - \n",
      "     acc    bmx      bmn      mse      spr      run\n",
      "0  10.0  110.4 -312.318  102.404  4722.33  574.637\n",
      "ValEpoch(027) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  116.874 -316.426  17.277\n",
      "*****\n",
      " Epoch 28 of 100\n",
      "TrEpoch(028) - \n",
      "     acc      bmx      bmn      mse       spr      run\n",
      "0  10.0  114.677 -323.034  101.898  4722.373  574.135\n",
      "ValEpoch(028) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  115.943 -321.196  17.364\n",
      "*****\n",
      " Epoch 29 of 100\n",
      "TrEpoch(029) - \n",
      "     acc      bmx      bmn      mse       spr      run\n",
      "0  10.0  114.652 -334.451  101.407  4722.303  573.637\n",
      "ValEpoch(029) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  114.108 -318.47  17.031\n",
      "*****\n",
      " Epoch 30 of 100\n",
      "TrEpoch(030) - \n",
      "     acc      bmx      bmn      mse       spr      run\n",
      "0  10.0  113.196 -328.781  100.867  4722.395  573.107\n",
      "ValEpoch(030) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  116.683 -300.469  16.867\n",
      "*****\n",
      " Epoch 31 of 100\n",
      "TrEpoch(031) - 2- True False\n",
      "cre tensor(2.5190, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5190482139587402\n",
      "\n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  114.942 -322.977  99.873  4722.439  572.117\n",
      "ValEpoch(031) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  122.254 -316.839  16.64\n",
      "*****\n",
      " Epoch 32 of 100\n",
      "TrEpoch(032) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  118.602 -327.045  98.882  4722.417  571.124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValEpoch(032) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  118.588 -304.097  16.532\n",
      "*****\n",
      " Epoch 33 of 100\n",
      "TrEpoch(033) - \n",
      "     acc      bmx      bmn    mse       spr      run\n",
      "0  10.0  119.904 -315.764  98.68  4722.426  570.922\n",
      "ValEpoch(033) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  124.021 -309.014  16.517\n",
      "*****\n",
      " Epoch 34 of 100\n",
      "TrEpoch(034) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  123.284 -331.407  98.009  4722.454  570.255\n",
      "ValEpoch(034) - \n",
      "     acc    bmx      bmn     run\n",
      "0  10.0  128.1 -337.372  16.262\n",
      "*****\n",
      " Epoch 35 of 100\n",
      "TrEpoch(035) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  120.893 -328.093  96.753  4722.406  568.993\n",
      "ValEpoch(035) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  123.504 -299.453  16.167\n",
      "*****\n",
      " Epoch 36 of 100\n",
      "TrEpoch(036) - 2- True False\n",
      "cre tensor(2.5184, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5184285640716553\n",
      "\n",
      "     acc     bmx      bmn     mse       spr      run\n",
      "0  10.0  125.33 -312.364  95.722  4722.427  567.964\n",
      "ValEpoch(036) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  123.181 -297.733  16.032\n",
      "*****\n",
      " Epoch 37 of 100\n",
      "TrEpoch(037) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  124.775 -317.436  94.595  4722.493  566.844\n",
      "ValEpoch(037) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  118.475 -297.202  16.057\n",
      "*****\n",
      " Epoch 38 of 100\n",
      "TrEpoch(038) - \n",
      "     acc     bmx      bmn     mse       spr      run\n",
      "0  10.0  123.57 -312.652  94.462  4722.447  566.706\n",
      "ValEpoch(038) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  131.294 -318.532  15.963\n",
      "*****\n",
      " Epoch 39 of 100\n",
      "TrEpoch(039) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  129.025 -324.738  93.967  4722.461  566.213\n",
      "ValEpoch(039) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  130.58 -315.466  15.658\n",
      "*****\n",
      " Epoch 40 of 100\n",
      "TrEpoch(040) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  128.972 -333.656  93.158  4722.435  565.401\n",
      "ValEpoch(040) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  128.625 -324.981  15.881\n",
      "*****\n",
      " Epoch 41 of 100\n",
      "TrEpoch(041) - 2- True False\n",
      "cre tensor(2.5186, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.518592119216919\n",
      "\n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  131.039 -340.303  93.252  4722.413  565.494\n",
      "ValEpoch(041) - \n",
      "     acc    bmx      bmn   run\n",
      "0  10.0  130.6 -333.608  15.7\n",
      "*****\n",
      " Epoch 42 of 100\n",
      "TrEpoch(042) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  132.411 -353.861  93.557  4722.405  565.797\n",
      "ValEpoch(042) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  134.443 -331.512  15.877\n",
      "*****\n",
      " Epoch 43 of 100\n",
      "TrEpoch(043) - \n",
      "     acc     bmx      bmn     mse       spr      run\n",
      "0  10.0  135.73 -344.033  92.531  4722.397  564.771\n",
      "ValEpoch(043) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  129.123 -318.277  15.402\n",
      "*****\n",
      " Epoch 44 of 100\n",
      "TrEpoch(044) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  143.808 -348.745  92.322  4722.432  564.565\n",
      "ValEpoch(044) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  139.247 -342.187  15.605\n",
      "*****\n",
      " Epoch 45 of 100\n",
      "TrEpoch(045) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  138.593 -341.088  92.355  4722.435  564.599\n",
      "ValEpoch(045) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  142.326 -327.688  15.539\n",
      "*****\n",
      " Epoch 46 of 100\n",
      "TrEpoch(046) - 2- True False\n",
      "cre tensor(2.5186, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5186009407043457\n",
      "\n",
      "     acc     bmx      bmn    mse       spr      run\n",
      "0  10.0  137.75 -346.215  92.17  4722.432  564.413\n",
      "ValEpoch(046) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  139.465 -332.824  15.378\n",
      "*****\n",
      " Epoch 47 of 100\n",
      "TrEpoch(047) - \n",
      "     acc      bmx      bmn     mse       spr     run\n",
      "0  10.0  134.878 -337.225  91.502  4722.471  563.75\n",
      "ValEpoch(047) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  136.565 -312.46  15.297\n",
      "*****\n",
      " Epoch 48 of 100\n",
      "TrEpoch(048) - \n",
      "     acc     bmx      bmn     mse       spr      run\n",
      "0  10.0  144.14 -324.602  91.166  4722.515  563.417\n",
      "ValEpoch(048) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  144.666 -326.392  15.34\n",
      "*****\n",
      " Epoch 49 of 100\n",
      "TrEpoch(049) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  139.123 -325.233  90.806  4722.448  563.051\n",
      "ValEpoch(049) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  133.627 -312.31  15.411\n",
      "*****\n",
      " Epoch 50 of 100\n",
      "TrEpoch(050) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  141.165 -324.528  90.592  4722.437  562.835\n",
      "ValEpoch(050) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  137.947 -307.226  15.531\n",
      "*****\n",
      " Epoch 51 of 100\n",
      "TrEpoch(051) - 2- True False\n",
      "cre tensor(2.5184, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5183839797973633\n",
      "\n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  140.683 -331.208  90.469  4722.396  562.709\n",
      "ValEpoch(051) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  139.252 -310.35  15.157\n",
      "*****\n",
      " Epoch 52 of 100\n",
      "TrEpoch(052) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  146.137 -327.969  89.639  4722.471  561.886\n",
      "ValEpoch(052) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  145.45 -326.616  15.558\n",
      "*****\n",
      " Epoch 53 of 100\n",
      "TrEpoch(053) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  145.892 -340.478  89.473  4722.483  561.721\n",
      "ValEpoch(053) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  140.573 -303.043  15.038\n",
      "*****\n",
      " Epoch 54 of 100\n",
      "TrEpoch(054) - \n",
      "     acc     bmx      bmn     mse      spr      run\n",
      "0  10.0  145.21 -323.849  89.267  4722.45  561.512\n",
      "ValEpoch(054) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  131.899 -282.971  15.095\n",
      "*****\n",
      " Epoch 55 of 100\n",
      "TrEpoch(055) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  142.602 -317.569  89.445  4722.434  561.688\n",
      "ValEpoch(055) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  143.013 -307.805  14.915\n",
      "*****\n",
      " Epoch 56 of 100\n",
      "TrEpoch(056) - 2- True False\n",
      "cre tensor(2.5183, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5183093547821045\n",
      "\n",
      "     acc      bmx     bmn     mse       spr      run\n",
      "0  10.0  144.531 -318.96  88.313  4722.492  560.562\n",
      "ValEpoch(056) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  155.579 -334.182  14.99\n",
      "*****\n",
      " Epoch 57 of 100\n",
      "TrEpoch(057) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  149.528 -338.141  88.392  4722.446  560.637\n",
      "ValEpoch(057) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  146.152 -311.876  15.127\n",
      "*****\n",
      " Epoch 58 of 100\n",
      "TrEpoch(058) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  146.172 -316.829  88.059  4722.422  560.301\n",
      "ValEpoch(058) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  152.463 -324.559  15.048\n",
      "*****\n",
      " Epoch 59 of 100\n",
      "TrEpoch(059) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  153.856 -330.702  87.632  4722.449  559.877\n",
      "ValEpoch(059) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  150.858 -320.374  14.798\n",
      "*****\n",
      " Epoch 60 of 100\n",
      "TrEpoch(060) - \n",
      "     acc     bmx      bmn     mse       spr      run\n",
      "0  10.0  168.05 -365.626  88.415  4722.487  560.663\n",
      "ValEpoch(060) - \n",
      "     acc      bmx    bmn     run\n",
      "0  10.0  158.374 -339.4  14.775\n",
      "*****\n",
      " Epoch 61 of 100\n",
      "TrEpoch(061) - 2- True False\n",
      "cre tensor(2.5184, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5183968544006348\n",
      "\n",
      "     acc      bmx      bmn     mse       spr     run\n",
      "0  10.0  157.794 -354.523  87.478  4722.521  559.73\n",
      "ValEpoch(061) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  154.782 -321.004  14.834\n",
      "*****\n",
      " Epoch 62 of 100\n",
      "TrEpoch(062) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  151.967 -313.885  87.102  4722.492  559.351\n",
      "ValEpoch(062) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  143.307 -295.148  14.671\n",
      "*****\n",
      " Epoch 63 of 100\n",
      "TrEpoch(063) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  147.698 -304.883  87.052  4722.505  559.303\n",
      "ValEpoch(063) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  127.252 -262.546  14.934\n",
      "*****\n",
      " Epoch 64 of 100\n",
      "TrEpoch(064) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  148.539 -299.483  86.255  4722.523  558.507\n",
      "ValEpoch(064) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  141.583 -280.988  14.633\n",
      "*****\n",
      " Epoch 65 of 100\n",
      "TrEpoch(065) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  152.435 -313.532  86.007  4722.444  558.252\n",
      "ValEpoch(065) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  150.158 -304.568  14.441\n",
      "*****\n",
      " Epoch 66 of 100\n",
      "TrEpoch(066) - 2- True False\n",
      "cre tensor(2.5184, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.51835560798645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     acc     bmx      bmn     mse       spr      run\n",
      "0  10.0  150.75 -308.615  85.271  4722.472  557.518\n",
      "ValEpoch(066) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  146.127 -298.145  14.344\n",
      "*****\n",
      " Epoch 67 of 100\n",
      "TrEpoch(067) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  152.679 -317.002  84.843  4722.437  557.087\n",
      "ValEpoch(067) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  140.684 -297.011  14.424\n",
      "*****\n",
      " Epoch 68 of 100\n",
      "TrEpoch(068) - \n",
      "     acc      bmx      bmn   mse       spr      run\n",
      "0  10.0  150.137 -312.926  84.6  4722.443  556.844\n",
      "ValEpoch(068) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  149.464 -302.484  14.383\n",
      "*****\n",
      " Epoch 69 of 100\n",
      "TrEpoch(069) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  154.108 -304.556  83.544  4722.441  555.788\n",
      "ValEpoch(069) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  141.539 -277.887  14.244\n",
      "*****\n",
      " Epoch 70 of 100\n",
      "TrEpoch(070) - \n",
      "     acc     bmx      bmn     mse       spr      run\n",
      "0  10.0  151.83 -309.093  83.421  4722.425  555.664\n",
      "ValEpoch(070) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  145.758 -288.875  14.152\n",
      "*****\n",
      " Epoch 71 of 100\n",
      "TrEpoch(071) - 2- True False\n",
      "cre tensor(2.5189, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5189309120178223\n",
      "\n",
      "     acc     bmx      bmn     mse       spr      run\n",
      "0  10.0  159.66 -311.134  83.863  4722.437  556.107\n",
      "ValEpoch(071) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  142.587 -277.664  14.171\n",
      "*****\n",
      " Epoch 72 of 100\n",
      "TrEpoch(072) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  151.141 -297.712  83.838  4722.497  556.088\n",
      "ValEpoch(072) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  145.932 -280.74  14.27\n",
      "*****\n",
      " Epoch 73 of 100\n",
      "TrEpoch(073) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  150.004 -285.191  83.458  4722.535  555.711\n",
      "ValEpoch(073) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  134.493 -258.867  14.171\n",
      "*****\n",
      " Epoch 74 of 100\n",
      "TrEpoch(074) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  148.718 -280.928  83.056  4722.503  555.306\n",
      "ValEpoch(074) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  145.482 -279.198  13.948\n",
      "*****\n",
      " Epoch 75 of 100\n",
      "TrEpoch(075) - \n",
      "     acc      bmx      bmn     mse      spr      run\n",
      "0  10.0  155.062 -292.132  82.971  4722.44  555.215\n",
      "ValEpoch(075) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  151.189 -291.609  14.047\n",
      "*****\n",
      " Epoch 76 of 100\n",
      "TrEpoch(076) - 2- True False\n",
      "cre tensor(2.5182, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5182175636291504\n",
      "\n",
      "     acc     bmx      bmn     mse       spr      run\n",
      "0  10.0  149.74 -287.297  82.653  4722.431  554.896\n",
      "ValEpoch(076) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  146.874 -281.001  13.79\n",
      "*****\n",
      " Epoch 77 of 100\n",
      "TrEpoch(077) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  145.469 -280.755  81.949  4722.485  554.198\n",
      "ValEpoch(077) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  139.268 -267.987  13.791\n",
      "*****\n",
      " Epoch 78 of 100\n",
      "TrEpoch(078) - \n",
      "     acc      bmx      bmn   mse      spr      run\n",
      "0  10.0  145.674 -273.475  81.7  4722.51  553.951\n",
      "ValEpoch(078) - \n",
      "     acc    bmx      bmn     run\n",
      "0  10.0  131.3 -244.581  14.156\n",
      "*****\n",
      " Epoch 79 of 100\n",
      "TrEpoch(079) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  144.155 -268.274  81.713  4722.517  553.965\n",
      "ValEpoch(079) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  141.956 -263.62  13.704\n",
      "*****\n",
      " Epoch 80 of 100\n",
      "TrEpoch(080) - \n",
      "     acc      bmx     bmn     mse       spr      run\n",
      "0  10.0  141.363 -269.09  81.687  4722.519  553.939\n",
      "ValEpoch(080) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  139.919 -258.524  13.675\n",
      "*****\n",
      " Epoch 81 of 100\n",
      "TrEpoch(081) - 2- True False\n",
      "cre tensor(2.5198, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.519761562347412\n",
      "\n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  143.463 -265.484  81.248  4722.558  553.503\n",
      "ValEpoch(081) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  128.958 -239.443  13.695\n",
      "*****\n",
      " Epoch 82 of 100\n",
      "TrEpoch(082) - \n",
      "     acc      bmx      bmn    mse      spr      run\n",
      "0  10.0  144.796 -269.461  80.43  4722.51  552.681\n",
      "ValEpoch(082) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  145.834 -270.482  13.557\n",
      "*****\n",
      " Epoch 83 of 100\n",
      "TrEpoch(083) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  149.312 -274.534  80.455  4722.475  552.702\n",
      "ValEpoch(083) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  145.652 -272.821  13.959\n",
      "*****\n",
      " Epoch 84 of 100\n",
      "TrEpoch(084) - \n",
      "     acc      bmx     bmn     mse       spr      run\n",
      "0  10.0  145.821 -273.15  80.398  4722.464  552.645\n",
      "ValEpoch(084) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  141.154 -255.891  13.54\n",
      "*****\n",
      " Epoch 85 of 100\n",
      "TrEpoch(085) - \n",
      "     acc     bmx      bmn     mse      spr      run\n",
      "0  10.0  146.61 -266.097  80.268  4722.48  552.516\n",
      "ValEpoch(085) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  137.788 -255.769  13.464\n",
      "*****\n",
      " Epoch 86 of 100\n",
      "TrEpoch(086) - 2- True False\n",
      "cre tensor(2.5186, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.518641471862793\n",
      "\n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  142.194 -268.418  80.103  4722.436  552.347\n",
      "ValEpoch(086) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  142.129 -259.017  13.583\n",
      "*****\n",
      " Epoch 87 of 100\n",
      "TrEpoch(087) - \n",
      "     acc      bmx     bmn    mse      spr      run\n",
      "0  10.0  148.536 -276.16  79.83  4722.47  552.077\n",
      "ValEpoch(087) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  146.982 -269.731  13.604\n",
      "*****\n",
      " Epoch 88 of 100\n",
      "TrEpoch(088) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  148.094 -268.598  80.338  4722.572  552.595\n",
      "ValEpoch(088) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  131.52 -238.882  13.436\n",
      "*****\n",
      " Epoch 89 of 100\n",
      "TrEpoch(089) - \n",
      "     acc      bmx      bmn     mse       spr     run\n",
      "0  10.0  141.203 -258.135  79.806  4722.641  552.07\n",
      "ValEpoch(089) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  129.619 -233.598  13.383\n",
      "*****\n",
      " Epoch 90 of 100\n",
      "TrEpoch(090) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  137.996 -250.292  78.957  4722.677  551.225\n",
      "ValEpoch(090) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  128.665 -230.421  13.132\n",
      "*****\n",
      " Epoch 91 of 100\n",
      "TrEpoch(091) - 2- True False\n",
      "cre tensor(2.5186, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.51859712600708\n",
      "\n",
      "     acc      bmx     bmn     mse       spr      run\n",
      "0  10.0  152.141 -274.27  78.518  4722.611  550.779\n",
      "ValEpoch(091) - \n",
      "     acc    bmx      bmn     run\n",
      "0  10.0  147.8 -261.519  13.092\n",
      "*****\n",
      " Epoch 92 of 100\n",
      "TrEpoch(092) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  145.326 -261.421  77.881  4722.503  550.132\n",
      "ValEpoch(092) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  148.796 -266.896  13.138\n",
      "*****\n",
      " Epoch 93 of 100\n",
      "TrEpoch(093) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  146.816 -263.062  77.657  4722.457  549.903\n",
      "ValEpoch(093) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  136.083 -240.178  13.212\n",
      "*****\n",
      " Epoch 94 of 100\n",
      "TrEpoch(094) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  145.567 -256.395  77.914  4722.537  550.168\n",
      "ValEpoch(094) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  142.108 -249.151  13.155\n",
      "*****\n",
      " Epoch 95 of 100\n",
      "TrEpoch(095) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  147.371 -258.047  77.345  4722.623  549.607\n",
      "ValEpoch(095) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  140.134 -247.034  13.002\n",
      "*****\n",
      " Epoch 96 of 100\n",
      "TrEpoch(096) - 2- True False\n",
      "cre tensor(2.5187, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.518707275390625\n",
      "\n",
      "     acc      bmx      bmn     mse      spr      run\n",
      "0  10.0  140.711 -250.055  77.203  4722.54  549.457\n",
      "ValEpoch(096) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  131.291 -233.969  13.011\n",
      "*****\n",
      " Epoch 97 of 100\n",
      "TrEpoch(097) - \n",
      "     acc      bmx      bmn     mse       spr    run\n",
      "0  10.0  146.833 -259.497  77.151  4722.489  549.4\n",
      "ValEpoch(097) - \n",
      "     acc      bmx     bmn     run\n",
      "0  10.0  148.677 -261.43  13.347\n",
      "*****\n",
      " Epoch 98 of 100\n",
      "TrEpoch(098) - \n",
      "     acc     bmx     bmn     mse       spr      run\n",
      "0  10.0  147.32 -261.29  77.226  4722.555  549.482\n",
      "ValEpoch(098) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  140.931 -248.469  13.03\n",
      "*****\n",
      " Epoch 99 of 100\n",
      "TrEpoch(099) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  148.328 -261.622  76.921  4722.533  549.174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValEpoch(099) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  145.362 -251.997  13.022\n",
      "1.61e+02 minutes\n"
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_ws :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"APPLY_LOG_SOFTMAX : \", APPLY_LOG_SOFTMAX)\n",
    "print(\"APPLY_SPARSITY_TO : \", APPLY_SPARSITY_TO)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param * sp_loss\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc      bmx      bmn      mse       spr      run\n",
      "0   10.0   92.225 -189.058  197.346  4827.657  680.112\n",
      "1   10.0  168.907 -312.373  168.458  4722.798  640.737\n",
      "2   10.0  174.432 -316.937  150.784  4722.400  623.024\n",
      "3   10.0  146.810 -268.846  140.516  4722.368  612.752\n",
      "4   10.0  129.443 -238.105  135.747  4722.321  607.979\n",
      "5   10.0  110.626 -224.732  132.683  4722.233  604.907\n",
      "6   10.0  102.918 -218.264  129.028  4722.132  601.241\n",
      "7   10.0   97.235 -217.961  126.539  4722.129  598.752\n",
      "8   10.0   89.925 -203.423  123.797  4722.137  596.011\n",
      "9   10.0   86.669 -221.042  120.761  4722.113  592.973\n",
      "10  10.0   85.997 -220.549  118.533  4722.162  590.750\n",
      "11  10.0   86.480 -240.653  117.132  4722.189  589.351\n",
      "12  10.0   86.271 -239.334  116.321  4722.311  588.552\n",
      "13  10.0   85.883 -257.564  115.294  4722.314  587.526\n",
      "14  10.0   89.588 -266.816  113.861  4722.265  586.087\n",
      "15  10.0   92.335 -273.012  112.809  4722.254  585.035\n",
      "16  10.0   95.706 -304.432  112.475  4722.231  584.698\n",
      "17  10.0   95.290 -289.415  111.346  4722.203  583.566\n",
      "18  10.0   93.198 -283.979  110.864  4722.234  583.088\n",
      "19  10.0   93.627 -299.544  109.923  4722.203  582.143\n",
      "20  10.0   96.966 -293.486  107.906  4722.252  580.131\n",
      "21  10.0   99.874 -305.453  106.948  4722.256  579.173\n",
      "22  10.0   98.841 -307.014  106.520  4722.318  578.752\n",
      "23  10.0  100.778 -299.660  106.053  4722.295  578.282\n",
      "24  10.0  105.482 -298.083  105.277  4722.377  577.515\n",
      "25  10.0  106.354 -315.441  104.269  4722.341  576.503\n",
      "26  10.0  107.764 -310.898  103.248  4722.328  575.481\n",
      "27  10.0  110.400 -312.318  102.404  4722.330  574.637\n",
      "28  10.0  114.677 -323.034  101.898  4722.373  574.135\n",
      "29  10.0  114.652 -334.451  101.407  4722.303  573.637\n",
      "30  10.0  113.196 -328.781  100.867  4722.395  573.107\n",
      "31  10.0  114.942 -322.977   99.873  4722.439  572.117\n",
      "32  10.0  118.602 -327.045   98.882  4722.417  571.124\n",
      "33  10.0  119.904 -315.764   98.680  4722.426  570.922\n",
      "34  10.0  123.284 -331.407   98.009  4722.454  570.255\n",
      "35  10.0  120.893 -328.093   96.753  4722.406  568.993\n",
      "36  10.0  125.330 -312.364   95.722  4722.427  567.964\n",
      "37  10.0  124.775 -317.436   94.595  4722.493  566.844\n",
      "38  10.0  123.570 -312.652   94.462  4722.447  566.706\n",
      "39  10.0  129.025 -324.738   93.967  4722.461  566.213\n",
      "40  10.0  128.972 -333.656   93.158  4722.435  565.401\n",
      "41  10.0  131.039 -340.303   93.252  4722.413  565.494\n",
      "42  10.0  132.411 -353.861   93.557  4722.405  565.797\n",
      "43  10.0  135.730 -344.033   92.531  4722.397  564.771\n",
      "44  10.0  143.808 -348.745   92.322  4722.432  564.565\n",
      "45  10.0  138.593 -341.088   92.355  4722.435  564.599\n",
      "46  10.0  137.750 -346.215   92.170  4722.432  564.413\n",
      "47  10.0  134.878 -337.225   91.502  4722.471  563.750\n",
      "48  10.0  144.140 -324.602   91.166  4722.515  563.417\n",
      "49  10.0  139.123 -325.233   90.806  4722.448  563.051\n",
      "50  10.0  141.165 -324.528   90.592  4722.437  562.835\n",
      "51  10.0  140.683 -331.208   90.469  4722.396  562.709\n",
      "52  10.0  146.137 -327.969   89.639  4722.471  561.886\n",
      "53  10.0  145.892 -340.478   89.473  4722.483  561.721\n",
      "54  10.0  145.210 -323.849   89.267  4722.450  561.512\n",
      "55  10.0  142.602 -317.569   89.445  4722.434  561.688\n",
      "56  10.0  144.531 -318.960   88.313  4722.492  560.562\n",
      "57  10.0  149.528 -338.141   88.392  4722.446  560.637\n",
      "58  10.0  146.172 -316.829   88.059  4722.422  560.301\n",
      "59  10.0  153.856 -330.702   87.632  4722.449  559.877\n",
      "60  10.0  168.050 -365.626   88.415  4722.487  560.663\n",
      "61  10.0  157.794 -354.523   87.478  4722.521  559.730\n",
      "62  10.0  151.967 -313.885   87.102  4722.492  559.351\n",
      "63  10.0  147.698 -304.883   87.052  4722.505  559.303\n",
      "64  10.0  148.539 -299.483   86.255  4722.523  558.507\n",
      "65  10.0  152.435 -313.532   86.007  4722.444  558.252\n",
      "66  10.0  150.750 -308.615   85.271  4722.472  557.518\n",
      "67  10.0  152.679 -317.002   84.843  4722.437  557.087\n",
      "68  10.0  150.137 -312.926   84.600  4722.443  556.844\n",
      "69  10.0  154.108 -304.556   83.544  4722.441  555.788\n",
      "70  10.0  151.830 -309.093   83.421  4722.425  555.664\n",
      "71  10.0  159.660 -311.134   83.863  4722.437  556.107\n",
      "72  10.0  151.141 -297.712   83.838  4722.497  556.088\n",
      "73  10.0  150.004 -285.191   83.458  4722.535  555.711\n",
      "74  10.0  148.718 -280.928   83.056  4722.503  555.306\n",
      "75  10.0  155.062 -292.132   82.971  4722.440  555.215\n",
      "76  10.0  149.740 -287.297   82.653  4722.431  554.896\n",
      "77  10.0  145.469 -280.755   81.949  4722.485  554.198\n",
      "78  10.0  145.674 -273.475   81.700  4722.510  553.951\n",
      "79  10.0  144.155 -268.274   81.713  4722.517  553.965\n",
      "80  10.0  141.363 -269.090   81.687  4722.519  553.939\n",
      "81  10.0  143.463 -265.484   81.248  4722.558  553.503\n",
      "82  10.0  144.796 -269.461   80.430  4722.510  552.681\n",
      "83  10.0  149.312 -274.534   80.455  4722.475  552.702\n",
      "84  10.0  145.821 -273.150   80.398  4722.464  552.645\n",
      "85  10.0  146.610 -266.097   80.268  4722.480  552.516\n",
      "86  10.0  142.194 -268.418   80.103  4722.436  552.347\n",
      "87  10.0  148.536 -276.160   79.830  4722.470  552.077\n",
      "88  10.0  148.094 -268.598   80.338  4722.572  552.595\n",
      "89  10.0  141.203 -258.135   79.806  4722.641  552.070\n",
      "90  10.0  137.996 -250.292   78.957  4722.677  551.225\n",
      "91  10.0  152.141 -274.270   78.518  4722.611  550.779\n",
      "92  10.0  145.326 -261.421   77.881  4722.503  550.132\n",
      "93  10.0  146.816 -263.062   77.657  4722.457  549.903\n",
      "94  10.0  145.567 -256.395   77.914  4722.537  550.168\n",
      "95  10.0  147.371 -258.047   77.345  4722.623  549.607\n",
      "96  10.0  140.711 -250.055   77.203  4722.540  549.457\n",
      "97  10.0  146.833 -259.497   77.151  4722.489  549.400\n",
      "98  10.0  147.320 -261.290   77.226  4722.555  549.482\n",
      "99  10.0  148.328 -261.622   76.921  4722.533  549.174\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc      bmx      bmn     run\n",
      "0   10.0   89.787 -182.877  30.054\n",
      "1   10.0  164.902 -302.205  25.971\n",
      "2   10.0  151.153 -272.989  24.037\n",
      "3   10.0  126.842 -229.728  23.055\n",
      "4   10.0  110.511 -202.700  22.350\n",
      "5   10.0  102.805 -207.912  22.011\n",
      "6   10.0   95.338 -204.940  21.263\n",
      "7   10.0   85.646 -180.045  20.991\n",
      "8   10.0   84.644 -188.591  20.332\n",
      "9   10.0   79.996 -196.021  20.156\n",
      "10  10.0   83.257 -218.229  19.672\n",
      "11  10.0   84.535 -221.944  19.538\n",
      "12  10.0   79.887 -206.261  19.443\n",
      "13  10.0   84.677 -233.302  19.184\n",
      "14  10.0   88.800 -255.005  18.904\n",
      "15  10.0   92.418 -272.825  19.062\n",
      "16  10.0   92.958 -278.553  18.743\n",
      "17  10.0   87.708 -248.437  18.712\n",
      "18  10.0   95.071 -287.660  18.491\n",
      "19  10.0   92.270 -276.804  18.184\n",
      "20  10.0   99.436 -284.487  18.015\n",
      "21  10.0  104.512 -309.176  17.891\n",
      "22  10.0  102.412 -284.729  17.803\n",
      "23  10.0  103.575 -288.746  17.657\n",
      "24  10.0  102.038 -280.593  17.508\n",
      "25  10.0  102.658 -287.343  17.500\n",
      "26  10.0  109.192 -303.422  17.259\n",
      "27  10.0  116.874 -316.426  17.277\n",
      "28  10.0  115.943 -321.196  17.364\n",
      "29  10.0  114.108 -318.470  17.031\n",
      "30  10.0  116.683 -300.469  16.867\n",
      "31  10.0  122.254 -316.839  16.640\n",
      "32  10.0  118.588 -304.097  16.532\n",
      "33  10.0  124.021 -309.014  16.517\n",
      "34  10.0  128.100 -337.372  16.262\n",
      "35  10.0  123.504 -299.453  16.167\n",
      "36  10.0  123.181 -297.733  16.032\n",
      "37  10.0  118.475 -297.202  16.057\n",
      "38  10.0  131.294 -318.532  15.963\n",
      "39  10.0  130.580 -315.466  15.658\n",
      "40  10.0  128.625 -324.981  15.881\n",
      "41  10.0  130.600 -333.608  15.700\n",
      "42  10.0  134.443 -331.512  15.877\n",
      "43  10.0  129.123 -318.277  15.402\n",
      "44  10.0  139.247 -342.187  15.605\n",
      "45  10.0  142.326 -327.688  15.539\n",
      "46  10.0  139.465 -332.824  15.378\n",
      "47  10.0  136.565 -312.460  15.297\n",
      "48  10.0  144.666 -326.392  15.340\n",
      "49  10.0  133.627 -312.310  15.411\n",
      "50  10.0  137.947 -307.226  15.531\n",
      "51  10.0  139.252 -310.350  15.157\n",
      "52  10.0  145.450 -326.616  15.558\n",
      "53  10.0  140.573 -303.043  15.038\n",
      "54  10.0  131.899 -282.971  15.095\n",
      "55  10.0  143.013 -307.805  14.915\n",
      "56  10.0  155.579 -334.182  14.990\n",
      "57  10.0  146.152 -311.876  15.127\n",
      "58  10.0  152.463 -324.559  15.048\n",
      "59  10.0  150.858 -320.374  14.798\n",
      "60  10.0  158.374 -339.400  14.775\n",
      "61  10.0  154.782 -321.004  14.834\n",
      "62  10.0  143.307 -295.148  14.671\n",
      "63  10.0  127.252 -262.546  14.934\n",
      "64  10.0  141.583 -280.988  14.633\n",
      "65  10.0  150.158 -304.568  14.441\n",
      "66  10.0  146.127 -298.145  14.344\n",
      "67  10.0  140.684 -297.011  14.424\n",
      "68  10.0  149.464 -302.484  14.383\n",
      "69  10.0  141.539 -277.887  14.244\n",
      "70  10.0  145.758 -288.875  14.152\n",
      "71  10.0  142.587 -277.664  14.171\n",
      "72  10.0  145.932 -280.740  14.270\n",
      "73  10.0  134.493 -258.867  14.171\n",
      "74  10.0  145.482 -279.198  13.948\n",
      "75  10.0  151.189 -291.609  14.047\n",
      "76  10.0  146.874 -281.001  13.790\n",
      "77  10.0  139.268 -267.987  13.791\n",
      "78  10.0  131.300 -244.581  14.156\n",
      "79  10.0  141.956 -263.620  13.704\n",
      "80  10.0  139.919 -258.524  13.675\n",
      "81  10.0  128.958 -239.443  13.695\n",
      "82  10.0  145.834 -270.482  13.557\n",
      "83  10.0  145.652 -272.821  13.959\n",
      "84  10.0  141.154 -255.891  13.540\n",
      "85  10.0  137.788 -255.769  13.464\n",
      "86  10.0  142.129 -259.017  13.583\n",
      "87  10.0  146.982 -269.731  13.604\n",
      "88  10.0  131.520 -238.882  13.436\n",
      "89  10.0  129.619 -233.598  13.383\n",
      "90  10.0  128.665 -230.421  13.132\n",
      "91  10.0  147.800 -261.519  13.092\n",
      "92  10.0  148.796 -266.896  13.138\n",
      "93  10.0  136.083 -240.178  13.212\n",
      "94  10.0  142.108 -249.151  13.155\n",
      "95  10.0  140.134 -247.034  13.002\n",
      "96  10.0  131.291 -233.969  13.011\n",
      "97  10.0  148.677 -261.430  13.347\n",
      "98  10.0  140.931 -248.469  13.030\n",
      "99  10.0  145.362 -251.997  13.022\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tr acc =  10.0\n",
      "Max va acc =  10.0\n"
     ]
    }
   ],
   "source": [
    "tr_acc = result_df_tr_all.values[:,0].squeeze()\n",
    "va_acc = result_df_va_all.values[:,0].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_acc, color='orange', label='train acc')\n",
    "plt.plot(va_acc, color='red', label='validataion acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Max tr acc = \", np.max(tr_acc))\n",
    "print(\"Max va acc = \", np.max(va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_mse = result_df_tr_all.values[:,3].squeeze()\n",
    "tr_spr_50 = 100*result_df_tr_all.values[:,4].squeeze()\n",
    "va_err = 5*result_df_va_all.values[:,-1].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_mse, color='orange', label='train mse')\n",
    "plt.plot(tr_spr_50, color='red', label='tr spr*100')\n",
    "plt.plot(va_err, color='blue', label='va_err*5')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
