{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas:  1.1.0\n",
      "torch:  1.6.0\n",
      "numpy:  1.19.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "matplotlib.style.use('ggplot')\n",
    "import sys, importlib as impL\n",
    "import pandas as pd\n",
    "print(\"pandas: \", pd.__version__)\n",
    "print(\"torch: \", torch.__version__)\n",
    "print(\"numpy: \", np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsubuntu_khs_dir = /home/wsubuntu/GitHub/keyhandshapediscovery\n",
      "wsubuntu_data_path = /media/wsubuntu/SSD_Data/DataPath\n",
      "wsubuntu_experiment_path = /media/wsubuntu/SSD_Data/vaesae_experiments\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "def get_var_by_comp_name(variableName):\n",
    "    curCompName = socket.gethostname()\n",
    "    retVal = None\n",
    "    if variableName == 'khs_dir':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/home/wsubuntu/GitHub/keyhandshapediscovery'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'data_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/Datasets'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/DataPath'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "    if variableName == 'experiment_path':\n",
    "        if curCompName == 'doga-MSISSD':\n",
    "            base_dir = '/mnt/USB_HDD_1TB/GitHub/keyhandshapediscovery/experiments/SPARSE_TORCH'  # for bogazici kasa\n",
    "        elif curCompName == 'WsUbuntu05' or curCompName == 'wsubuntu':\n",
    "            base_dir = '/media/wsubuntu/SSD_Data/vaesae_experiments'  # for WS Doga DHO\n",
    "        elif curCompName == 'doga-msi-ubu':\n",
    "            base_dir = None  # for laptop\n",
    "        retVal = base_dir\n",
    "        \n",
    "    print(curCompName + '_' + variableName, '=',  retVal)\n",
    "    if retVal is None:\n",
    "        os.error(5)\n",
    "    return retVal\n",
    "\n",
    "khs_dir = get_var_by_comp_name('khs_dir')\n",
    "data_path = get_var_by_comp_name('data_path')\n",
    "experiment_path = get_var_by_comp_name('experiment_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(1, khs_dir)\n",
    "import helperFuncs as funcH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_ID = 31\n",
    "LOSS_TYPE='cre'\n",
    "LOSS_REDUCTION='mean' #'batchmean','sum'\n",
    "SIGMOID_ACT=True\n",
    "APPLY_LOG_SOFTMAX=False\n",
    "MSE_PLUS_MINUS='+'\n",
    "APPLY_SPARSITY_TO='bottleneck' #all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottleneck_acc(bottleneck_vec, lab_vec):\n",
    "    pred_vec = np.argmax(bottleneck_vec.T, axis=0).T.squeeze()\n",
    "    centroid_info_pdf = funcH.get_cluster_centroids(bottleneck_vec, pred_vec, kluster_centers=None, verbose=0)\n",
    "    _confMat_preds, kluster2Classes, kr_pdf, weightedPurity, cnmxh_perc = funcH.countPredictionsForConfusionMat(lab_vec, pred_vec, centroid_info_pdf=centroid_info_pdf, labelNames=None)\n",
    "    sampleCount = np.sum(np.sum(_confMat_preds))\n",
    "    acc = 100 * np.sum(np.diag(_confMat_preds)) / sampleCount\n",
    "    bmx, bmn = np.max(bottleneck_vec), np.min(bottleneck_vec)\n",
    "    return acc, bmx, bmn\n",
    "\n",
    "funcH.setPandasDisplayOpts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Argument Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add sparsity regularization: yes\n"
     ]
    }
   ],
   "source": [
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument('-e', '--epochs', type=int, default=10, help='number of epochs to train our network for')\n",
    "#ap.add_argument('-l', '--reg_param', type=float, default=0.001, help='regularization parameter `lambda`')\n",
    "#ap.add_argument('-sc', '--add_sparse', type=str, default='yes', help='whether to add sparsity contraint or not')\n",
    "#args = vars(ap.parse_args())\n",
    "epochs = 31  # args['epochs']\n",
    "reg_param = 0.1  # args['reg_param']\n",
    "add_sparsity = 'yes'  # args['add_sparse']\n",
    "learning_rate = 1e-4\n",
    "batch_size = 32\n",
    "print(f\"Add sparsity regularization: {add_sparsity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here I will change the data loader per my need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# get the computation device\n",
    "def get_device():\n",
    "    return 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "FOLDERS = {\n",
    "    \"data\": data_path,\n",
    "    \"experiment\": os.path.join(experiment_path, 'sparse_torch_ae_' + str(EXPERIMENT_ID).zfill(3)),\n",
    "}\n",
    "FOLDERS[\"model_save\"] = os.path.join(FOLDERS[\"experiment\"], \"model\")\n",
    "FOLDERS[\"decoder_image_path_tr\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_tr\")\n",
    "FOLDERS[\"decoder_image_path_va\"] = os.path.join(FOLDERS[\"experiment\"], \"output_images_va\")\n",
    "funcH.createDirIfNotExist(FOLDERS[\"model_save\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_tr\"])\n",
    "funcH.createDirIfNotExist(FOLDERS[\"decoder_image_path_va\"])\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=True, \n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root=FOLDERS[\"data\"],\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    " \n",
    "# trainloader\n",
    "trainloader = DataLoader(\n",
    "    trainset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "#testloader\n",
    "testloader = DataLoader(\n",
    "    testset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseAutoencoder - loss_type(cre), device(cpu)\n"
     ]
    }
   ],
   "source": [
    "# define the autoencoder model\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(self, loss_type):\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    " \n",
    "        # encoder\n",
    "        self.enc1 = nn.Linear(in_features=784, out_features=256)\n",
    "        self.enc2 = nn.Linear(in_features=256, out_features=128)\n",
    "        self.enc3 = nn.Linear(in_features=128, out_features=64)\n",
    "        self.enc4 = nn.Linear(in_features=64, out_features=32)\n",
    "        self.enc5 = nn.Linear(in_features=32, out_features=32)\n",
    " \n",
    "        # decoder \n",
    "        self.dec1 = nn.Linear(in_features=32, out_features=32)\n",
    "        self.dec2 = nn.Linear(in_features=32, out_features=64)\n",
    "        self.dec3 = nn.Linear(in_features=64, out_features=128)\n",
    "        self.dec4 = nn.Linear(in_features=128, out_features=256)\n",
    "        self.dec5 = nn.Linear(in_features=256, out_features=784)\n",
    "        \n",
    "        self.loss_type=loss_type\n",
    "        self.device = get_device()\n",
    "        print(\"SparseAutoencoder - loss_type(\" + loss_type +\"), device(\" + self.device + \")\")\n",
    "\n",
    "    def encode(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = F.relu(self.enc3(x))\n",
    "        x = F.relu(self.enc4(x))\n",
    "        if self.loss_type=='cre':\n",
    "            bottleneck = self.enc5(x) \n",
    "        else:\n",
    "            bottleneck = F.relu(self.enc5(x))  \n",
    "        \n",
    "        return bottleneck\n",
    "        \n",
    "    def decode(self, bottleneck):\n",
    "        # decoding\n",
    "        x = F.relu(self.dec1(bottleneck))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = F.relu(self.dec3(x))\n",
    "        x = F.relu(self.dec4(x))\n",
    "        x = F.relu(self.dec5(x)) \n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bottleneck = self.encode(x)\n",
    "        x = self.decode(bottleneck)\n",
    "        return x, bottleneck\n",
    "\n",
    "model = SparseAutoencoder(loss_type=LOSS_TYPE).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "criterion = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=32, bias=True)\n",
      "Linear(in_features=32, out_features=64, bias=True)\n",
      "Linear(in_features=64, out_features=128, bias=True)\n",
      "Linear(in_features=128, out_features=256, bias=True)\n",
      "Linear(in_features=256, out_features=784, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the layers as a list\n",
    "model_children = list(model.children())\n",
    "[print(i) for i in model_children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_l1(bottleneck):\n",
    "    return torch.mean(torch.abs(bottleneck))\n",
    "\n",
    "def loss_l2(bottleneck):\n",
    "    return torch.mean(torch.pow(bottleneck, torch.tensor(2.0).to(device))).sqrt()\n",
    "\n",
    "def kl_divergence(bottleneck, reduction):\n",
    "    bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    rho_val = 1/bt.size(1)\n",
    "    rho_mat = torch.tensor([rho_val] * np.ones(bt.size()), dtype=torch.float32).to(device)\n",
    "    #https://discuss.pytorch.org/t/kl-divergence-produces-negative-values/16791/13\n",
    "    #KLDLoss(p, q), sum(q) needs to equal one\n",
    "    #p = log_softmax(tensor)\n",
    "    loss_ret_1 = F.kl_div(F.log_softmax(bt, dim=1).to(device), rho_mat, reduction=reduction)\n",
    "    # torch.sum(rho * torch.log(rho / bottleneck) + (1 - rho) * torch.log((1 - rho) / (1 - bottleneck)))\n",
    "    return loss_ret_1\n",
    "\n",
    "\n",
    "def loss_crossentropy(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct and apply_log_softmax:  \n",
    "        if print_info:\n",
    "            print(\"1-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    elif sigmoidAct and not apply_log_softmax:     \n",
    "        if print_info:\n",
    "            print(\"2-\",sigmoidAct,apply_log_softmax)\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "        _, preds = torch.max(bt, 1)\n",
    "        loss_ret_1 = loss_fun(bt.to(device), preds)    \n",
    "    elif not sigmoidAct and apply_log_softmax:\n",
    "        if print_info:\n",
    "            print(\"3-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(F.log_softmax(bottleneck, dim=1).to(device), preds)    \n",
    "    else:#nothing\n",
    "        if print_info:\n",
    "            print(\"4-\",sigmoidAct,apply_log_softmax)\n",
    "        _, preds = torch.max(bottleneck, 1)\n",
    "        loss_ret_1 = loss_fun(bottleneck.to(device), preds)\n",
    "    return loss_ret_1\n",
    "\n",
    "def loss_crossentropy_old(bottleneck, sigmoidAct, reduction, apply_log_softmax, print_info):\n",
    "    loss_fun = torch.nn.CrossEntropyLoss(reduction=reduction)\n",
    "    if sigmoidAct:\n",
    "        bt = torch.sigmoid(bottleneck)  # sigmoid because we need the probability distributions\n",
    "    else:\n",
    "        bt = bottleneck    \n",
    "    _, preds = torch.max(bt, 1)\n",
    "    loss_ret_1 = loss_fun(F.log_softmax(bt, dim=1).to(device), preds)    \n",
    "    return loss_ret_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the sparse loss function\n",
    "def sparse_loss(autoencoder, images, print_info, loss_type):\n",
    "    loss = 0\n",
    "    values = images\n",
    "    for i in range(len(model_children)):\n",
    "        values = F.relu((model_children[i](values)))\n",
    "        #if print_info:\n",
    "            #print(i, ' shape=', values.shape)\n",
    "        if loss_type=='l1':\n",
    "            loss += loss_l1(values)\n",
    "        if loss_type=='l2':\n",
    "            loss += loss_l2(values)\n",
    "        if loss_type=='kl':\n",
    "            loss += kl_divergence(values, reduction=LOSS_REDUCTION)\n",
    "        if loss_type=='cre':\n",
    "            loss += loss_crossentropy(values, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "        if print_info:\n",
    "            print(loss_type,loss)\n",
    "    return loss\n",
    "\n",
    "def sparse_loss_bottleneck(bottleneck, print_info, loss_type):\n",
    "    loss = 0\n",
    "    #if print_info:\n",
    "        #print(i, ' shape=', values.shape)\n",
    "    if loss_type=='l1':\n",
    "        loss += loss_l1(bottleneck)\n",
    "    if loss_type=='l2':\n",
    "        loss += loss_l2(bottleneck)\n",
    "    if loss_type=='kl':\n",
    "        loss += kl_divergence(bottleneck, reduction=LOSS_REDUCTION)\n",
    "    if loss_type=='cre':\n",
    "        loss += loss_crossentropy(bottleneck, sigmoidAct=SIGMOID_ACT, reduction=LOSS_REDUCTION, apply_log_softmax=APPLY_LOG_SOFTMAX, print_info=print_info)\n",
    "    if print_info:\n",
    "        print(loss_type,loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_decoded_image(img, name):\n",
    "    img = img.view(img.size(0), 1, 28, 28)\n",
    "    save_image(img, name)\n",
    "\n",
    "# define the training function\n",
    "def fit(model, dataloader, epoch, print_losses_fit):\n",
    "    print('TrEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    sparsity_loss_sum = 0\n",
    "    mse_sum = 0\n",
    "       \n",
    "    for data in dataloader:\n",
    "        img, lb = data\n",
    "        lab_vec.append(lb)\n",
    "        \n",
    "        img = img.to(device)\n",
    "        img = img.view(img.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, bottleneck = model(img)\n",
    "        bottleneck_vec.append(bottleneck)\n",
    "        mse_loss = criterion(outputs, img)\n",
    "        mse_sum += mse_loss.item()\n",
    "        #if print_losses_fit:\n",
    "            #print(\"mse_loss:\", mse_loss.to('cpu'))\n",
    "            #print(\"bottleneck:\", bottleneck.to('cpu'))\n",
    "        if add_sparsity == 'yes':\n",
    "            if APPLY_SPARSITY_TO=='all':\n",
    "                sp_loss = sparse_loss(model, img, print_losses_fit, model.loss_type)\n",
    "            elif APPLY_SPARSITY_TO=='bottleneck': #all\n",
    "                sp_loss = sparse_loss_bottleneck(bottleneck, print_losses_fit, model.loss_type)\n",
    "            else:\n",
    "                os.exit(4)\n",
    "                \n",
    "            sparsity_loss_sum += sp_loss.item()\n",
    "            \n",
    "            # add the sparsity penalty\n",
    "            if print_losses_fit:\n",
    "                print(\"sp_loss:\", sparsity_loss_sum)\n",
    "                \n",
    "            if MSE_PLUS_MINUS=='-':\n",
    "                loss = mse_loss - reg_param * sp_loss\n",
    "            elif MSE_PLUS_MINUS=='+':\n",
    "                loss = mse_loss + reg_param * sp_loss\n",
    "        else:\n",
    "            loss = mse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        print_losses_fit = False\n",
    "    \n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "    #print(\"tr bottleneck accuracy=\", acc, \", max=\", bmx, \", min=\", bmn, \", sparsity_loss_sum=\", sparsity_loss_sum)\n",
    "  \n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, mse_sum, sparsity_loss_sum, running_loss]]), columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "    #print(df.iloc[0]['mse']) #'acc','bmx','bmn','mse','spr','run'\n",
    "    print(\"\\n\",result_df)\n",
    "    if epoch % 2 == 0:\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_tr\"], \"train\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_decoded_image(outputs.cpu().data, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the validation function\n",
    "def validate(model, dataloader, epoch, print_losses_fit):\n",
    "    print('ValEpoch({:03d}) - '.format(epoch), end='')\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    lab_vec = []\n",
    "    bottleneck_vec = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            img, lb = data\n",
    "            lab_vec.append(lb)\n",
    "            img = img.to(device)\n",
    "            img = img.view(img.size(0), -1)\n",
    "            outputs, bottleneck = model(img)\n",
    "            bottleneck_vec.append(bottleneck)\n",
    "            loss = criterion(outputs, img)\n",
    "            running_loss += loss.item()\n",
    "    # save the reconstructed images every 5 epochs\n",
    "    lab_vec = np.asarray(torch.cat(lab_vec).to(torch.device('cpu')))\n",
    "    bottleneck_vec = np.asarray(torch.cat(bottleneck_vec).to(torch.device('cpu')).detach().numpy())\n",
    "    acc, bmx, bmn = calc_bottleneck_acc(bottleneck_vec, lab_vec)\n",
    "\n",
    "    result_df = pd.DataFrame(np.array([[acc, bmx, bmn, running_loss]]), columns=['acc','bmx','bmn','run'])\n",
    "    print(\"\\n\",result_df)\n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        outputs = outputs.view(outputs.size(0), 1, 28, 28).cpu().data\n",
    "        difn = os.path.join(FOLDERS[\"decoder_image_path_va\"], \"reconstruction\"+str(epoch).zfill(3)+\".png\")\n",
    "        save_image(outputs, difn)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stae_ws :: \n",
      "EXPERIMENT_ID:  31\n",
      "LOSS_TYPE :  cre\n",
      "LOSS_REDUCTION :  mean\n",
      "SIGMOID_ACT :  True\n",
      "APPLY_LOG_SOFTMAX :  False\n",
      "APPLY_SPARSITY_TO :  bottleneck\n",
      "total loss = mse_loss + reg_param * sp_loss\n",
      "change from 19 - network has no relu in decoders first line\n",
      "*****\n",
      " Epoch 0 of 31\n",
      "TrEpoch(000) - 2- True False\n",
      "cre tensor(3.4189, grad_fn=<AddBackward0>)\n",
      "sp_loss: 3.418874740600586\n",
      "\n",
      "     acc     bmx      bmn      mse       spr      run\n",
      "0  10.0  115.18 -116.044  151.237  4817.257  632.963\n",
      "ValEpoch(000) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  112.352 -113.306  18.249\n",
      "*****\n",
      " Epoch 1 of 31\n",
      "TrEpoch(001) - \n",
      "     acc      bmx      bmn      mse       spr     run\n",
      "0  10.0  118.115 -118.515  100.752  4721.783  572.93\n",
      "ValEpoch(001) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  113.857 -112.986  15.404\n",
      "*****\n",
      " Epoch 2 of 31\n",
      "TrEpoch(002) - \n",
      "     acc      bmx      bmn     mse       spr     run\n",
      "0  10.0  116.507 -115.683  82.777  4721.625  554.94\n",
      "ValEpoch(002) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  110.69 -110.058  12.991\n",
      "*****\n",
      " Epoch 3 of 31\n",
      "TrEpoch(003) - \n",
      "     acc     bmx      bmn     mse       spr      run\n",
      "0  10.0  115.85 -114.615  76.019  4721.613  548.181\n",
      "ValEpoch(003) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  106.64 -105.639  12.418\n",
      "*****\n",
      " Epoch 4 of 31\n",
      "TrEpoch(004) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  109.913 -108.865  71.744  4721.605  543.905\n",
      "ValEpoch(004) - \n",
      "     acc    bmx      bmn     run\n",
      "0  10.0  103.5 -102.689  11.469\n",
      "*****\n",
      " Epoch 5 of 31\n",
      "TrEpoch(005) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  108.386 -106.006  65.513  4721.566  537.669\n",
      "ValEpoch(005) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  105.03 -104.524  10.563\n",
      "*****\n",
      " Epoch 6 of 31\n",
      "TrEpoch(006) - 2- True False\n",
      "cre tensor(2.5181, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5180628299713135\n",
      "\n",
      "     acc      bmx    bmn     mse       spr      run\n",
      "0  10.0  110.022 -107.5  62.091  4721.537  534.244\n",
      "ValEpoch(006) - \n",
      "     acc     bmx      bmn     run\n",
      "0  10.0  107.07 -104.922  10.249\n",
      "*****\n",
      " Epoch 7 of 31\n",
      "TrEpoch(007) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  109.213 -106.322  60.619  4721.532  532.772\n",
      "ValEpoch(007) - \n",
      "     acc      bmx      bmn     run\n",
      "0  10.0  105.569 -103.021  10.072\n",
      "*****\n",
      " Epoch 8 of 31\n",
      "TrEpoch(008) - \n",
      "     acc      bmx      bmn   mse       spr      run\n",
      "0  10.0  108.052 -104.746  59.7  4721.546  531.854\n",
      "ValEpoch(008) - \n",
      "     acc      bmx      bmn    run\n",
      "0  10.0  104.194 -100.785  9.934\n",
      "*****\n",
      " Epoch 9 of 31\n",
      "TrEpoch(009) - \n",
      "     acc      bmx      bmn     mse       spr      run\n",
      "0  10.0  107.637 -103.057  58.388  4721.547  530.542\n",
      "ValEpoch(009) - \n",
      "     acc      bmx     bmn   run\n",
      "0  10.0  101.649 -97.839  9.63\n",
      "*****\n",
      " Epoch 10 of 31\n",
      "TrEpoch(010) - \n",
      "     acc      bmx     bmn     mse       spr      run\n",
      "0  10.0  105.006 -99.994  56.876  4721.554  529.031\n",
      "ValEpoch(010) - \n",
      "     acc      bmx     bmn    run\n",
      "0  10.0  100.954 -95.878  9.463\n",
      "*****\n",
      " Epoch 11 of 31\n",
      "TrEpoch(011) - 2- True False\n",
      "cre tensor(2.5181, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5180814266204834\n",
      "\n",
      "     acc      bmx     bmn     mse       spr      run\n",
      "0  10.0  104.289 -99.019  55.412  4721.552  527.567\n",
      "ValEpoch(011) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  99.965 -95.146  8.927\n",
      "*****\n",
      " Epoch 12 of 31\n",
      "TrEpoch(012) - \n",
      "     acc      bmx     bmn     mse       spr      run\n",
      "0  10.0  103.983 -98.031  52.581  4721.553  524.737\n",
      "ValEpoch(012) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  99.299 -94.566  8.778\n",
      "*****\n",
      " Epoch 13 of 31\n",
      "TrEpoch(013) - \n",
      "     acc      bmx     bmn     mse       spr      run\n",
      "0  10.0  103.669 -97.272  51.939  4721.549  524.094\n",
      "ValEpoch(013) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  98.192 -93.394  8.639\n",
      "*****\n",
      " Epoch 14 of 31\n",
      "TrEpoch(014) - \n",
      "     acc      bmx     bmn     mse       spr     run\n",
      "0  10.0  101.022 -94.701  50.896  4721.541  523.05\n",
      "ValEpoch(014) - \n",
      "     acc     bmx    bmn    run\n",
      "0  10.0  96.775 -91.92  8.461\n",
      "*****\n",
      " Epoch 15 of 31\n",
      "TrEpoch(015) - \n",
      "     acc      bmx     bmn     mse       spr      run\n",
      "0  10.0  100.975 -93.528  50.148  4721.537  522.302\n",
      "ValEpoch(015) - \n",
      "     acc     bmx    bmn   run\n",
      "0  10.0  96.078 -90.42  8.39\n",
      "*****\n",
      " Epoch 16 of 31\n",
      "TrEpoch(016) - 2- True False\n",
      "cre tensor(2.5182, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.5181820392608643\n",
      "\n",
      "     acc     bmx     bmn     mse       spr      run\n",
      "0  10.0  99.629 -92.097  49.615  4721.531  521.768\n",
      "ValEpoch(016) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  95.325 -88.965  8.246\n",
      "*****\n",
      " Epoch 17 of 31\n",
      "TrEpoch(017) - \n",
      "     acc     bmx     bmn     mse      spr      run\n",
      "0  10.0  98.235 -90.378  48.844  4721.53  520.997\n",
      "ValEpoch(017) - \n",
      "     acc     bmx    bmn    run\n",
      "0  10.0  93.405 -86.85  8.198\n",
      "*****\n",
      " Epoch 18 of 31\n",
      "TrEpoch(018) - \n",
      "     acc     bmx     bmn     mse       spr      run\n",
      "0  10.0  97.252 -88.113  48.525  4721.529  520.678\n",
      "ValEpoch(018) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  92.799 -85.466  8.135\n",
      "*****\n",
      " Epoch 19 of 31\n",
      "TrEpoch(019) - \n",
      "     acc     bmx     bmn     mse       spr      run\n",
      "0  10.0  95.995 -87.104  47.566  4721.528  519.719\n",
      "ValEpoch(019) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  91.785 -84.123  7.945\n",
      "*****\n",
      " Epoch 20 of 31\n",
      "TrEpoch(020) - \n",
      "     acc     bmx     bmn     mse       spr      run\n",
      "0  10.0  96.089 -86.355  46.647  4721.522  518.799\n",
      "ValEpoch(020) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  89.884 -82.424  7.792\n",
      "*****\n",
      " Epoch 21 of 31\n",
      "TrEpoch(021) - 2- True False\n",
      "cre tensor(2.5183, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.518336296081543\n",
      "\n",
      "     acc     bmx     bmn     mse       spr     run\n",
      "0  10.0  93.578 -84.837  46.108  4721.526  518.26\n",
      "ValEpoch(021) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  88.666 -81.278  7.718\n",
      "*****\n",
      " Epoch 22 of 31\n",
      "TrEpoch(022) - \n",
      "     acc     bmx     bmn     mse       spr      run\n",
      "0  10.0  91.836 -84.154  45.555  4721.522  517.707\n",
      "ValEpoch(022) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  87.916 -80.619  7.602\n",
      "*****\n",
      " Epoch 23 of 31\n",
      "TrEpoch(023) - \n",
      "     acc     bmx     bmn     mse       spr      run\n",
      "0  10.0  91.626 -84.575  45.031  4721.511  517.182\n",
      "ValEpoch(023) - \n",
      "     acc    bmx     bmn    run\n",
      "0  10.0  86.91 -81.433  7.548\n",
      "*****\n",
      " Epoch 24 of 31\n",
      "TrEpoch(024) - \n",
      "     acc     bmx    bmn     mse       spr      run\n",
      "0  10.0  91.568 -84.91  44.666  4721.503  516.816\n",
      "ValEpoch(024) - \n",
      "     acc     bmx     bmn   run\n",
      "0  10.0  85.961 -81.484  7.48\n",
      "*****\n",
      " Epoch 25 of 31\n",
      "TrEpoch(025) - \n",
      "     acc     bmx     bmn     mse       spr      run\n",
      "0  10.0  89.095 -85.558  44.371  4721.501  516.522\n",
      "ValEpoch(025) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  84.943 -82.039  7.446\n",
      "*****\n",
      " Epoch 26 of 31\n",
      "TrEpoch(026) - 2- True False\n",
      "cre tensor(2.5181, grad_fn=<AddBackward0>)\n",
      "sp_loss: 2.518054962158203\n",
      "\n",
      "     acc     bmx    bmn     mse       spr      run\n",
      "0  10.0  88.695 -85.77  44.074  4721.492  516.224\n",
      "ValEpoch(026) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  84.146 -82.057  7.392\n",
      "*****\n",
      " Epoch 27 of 31\n",
      "TrEpoch(027) - \n",
      "     acc     bmx     bmn     mse       spr      run\n",
      "0  10.0  87.349 -85.228  43.822  4721.493  515.972\n",
      "ValEpoch(027) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  81.865 -81.089  7.348\n",
      "*****\n",
      " Epoch 28 of 31\n",
      "TrEpoch(028) - \n",
      "     acc     bmx     bmn     mse       spr      run\n",
      "0  10.0  85.734 -85.089  43.526  4721.492  515.675\n",
      "ValEpoch(028) - \n",
      "     acc    bmx     bmn    run\n",
      "0  10.0  81.06 -81.423  7.295\n",
      "*****\n",
      " Epoch 29 of 31\n",
      "TrEpoch(029) - \n",
      "     acc    bmx     bmn     mse       spr      run\n",
      "0  10.0  84.62 -84.701  43.175  4721.488  515.324\n",
      "ValEpoch(029) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  80.075 -81.876  7.237\n",
      "*****\n",
      " Epoch 30 of 31\n",
      "TrEpoch(030) - \n",
      "     acc     bmx     bmn     mse       spr      run\n",
      "0  10.0  83.834 -85.748  42.099  4721.486  514.247\n",
      "ValEpoch(030) - \n",
      "     acc     bmx     bmn    run\n",
      "0  10.0  79.726 -82.493  7.046\n",
      "12.3 minutes\n"
     ]
    }
   ],
   "source": [
    "# train and validate the autoencoder neural network\n",
    "start = time.time()\n",
    "print_losses_fit = True\n",
    "\n",
    "train_loss = []\n",
    "trn_spars_loss = []\n",
    "trn_bot_acc = []\n",
    "val_loss = []\n",
    "val_bot_acc = []\n",
    "\n",
    "result_df_tr_all = pd.DataFrame(columns=['acc','bmx','bmn','mse','spr','run'])\n",
    "result_df_va_all = pd.DataFrame(columns=['acc','bmx','bmn','run'])\n",
    "\n",
    "print(\"stae_ws :: \")\n",
    "print(\"EXPERIMENT_ID: \", EXPERIMENT_ID)\n",
    "print(\"LOSS_TYPE : \", LOSS_TYPE)\n",
    "print(\"LOSS_REDUCTION : \", LOSS_REDUCTION)\n",
    "print(\"SIGMOID_ACT : \", SIGMOID_ACT)\n",
    "print(\"APPLY_LOG_SOFTMAX : \", APPLY_LOG_SOFTMAX)\n",
    "print(\"APPLY_SPARSITY_TO : \", APPLY_SPARSITY_TO)\n",
    "print(\"total loss = mse_loss \" + MSE_PLUS_MINUS + \" reg_param * sp_loss\")\n",
    "print(\"change from 19 - network has no relu in decoders first line\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"*****\\n Epoch {epoch} of {epochs}\")\n",
    "    result_df_tr = fit(model, trainloader, epoch, print_losses_fit)\n",
    "    result_df_va = validate(model, testloader, epoch, print_losses_fit)\n",
    "    print_losses_fit = epoch%5==0 and epoch>0\n",
    "    result_df_tr_all = result_df_tr_all.append(result_df_tr, ignore_index=True)\n",
    "    result_df_va_all = result_df_va_all.append(result_df_va, ignore_index=True)\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(f\"{(end-start)/60:.3} minutes\")\n",
    "# save the trained model\n",
    "\n",
    "mofn = os.path.join(FOLDERS[\"model_save\"], \"sparse_ae_\"+str(epoch).zfill(3)+\".pth\")\n",
    "torch.save(model.state_dict(), mofn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc      bmx      bmn      mse       spr      run\n",
      "0   10.0  115.180 -116.044  151.237  4817.257  632.963\n",
      "1   10.0  118.115 -118.515  100.752  4721.783  572.930\n",
      "2   10.0  116.507 -115.683   82.777  4721.625  554.940\n",
      "3   10.0  115.850 -114.615   76.019  4721.613  548.181\n",
      "4   10.0  109.913 -108.865   71.744  4721.605  543.905\n",
      "5   10.0  108.386 -106.006   65.513  4721.566  537.669\n",
      "6   10.0  110.022 -107.500   62.091  4721.537  534.244\n",
      "7   10.0  109.213 -106.322   60.619  4721.532  532.772\n",
      "8   10.0  108.052 -104.746   59.700  4721.546  531.854\n",
      "9   10.0  107.637 -103.057   58.388  4721.547  530.542\n",
      "10  10.0  105.006  -99.994   56.876  4721.554  529.031\n",
      "11  10.0  104.289  -99.019   55.412  4721.552  527.567\n",
      "12  10.0  103.983  -98.031   52.581  4721.553  524.737\n",
      "13  10.0  103.669  -97.272   51.939  4721.549  524.094\n",
      "14  10.0  101.022  -94.701   50.896  4721.541  523.050\n",
      "15  10.0  100.975  -93.528   50.148  4721.537  522.302\n",
      "16  10.0   99.629  -92.097   49.615  4721.531  521.768\n",
      "17  10.0   98.235  -90.378   48.844  4721.530  520.997\n",
      "18  10.0   97.252  -88.113   48.525  4721.529  520.678\n",
      "19  10.0   95.995  -87.104   47.566  4721.528  519.719\n",
      "20  10.0   96.089  -86.355   46.647  4721.522  518.799\n",
      "21  10.0   93.578  -84.837   46.108  4721.526  518.260\n",
      "22  10.0   91.836  -84.154   45.555  4721.522  517.707\n",
      "23  10.0   91.626  -84.575   45.031  4721.511  517.182\n",
      "24  10.0   91.568  -84.910   44.666  4721.503  516.816\n",
      "25  10.0   89.095  -85.558   44.371  4721.501  516.522\n",
      "26  10.0   88.695  -85.770   44.074  4721.492  516.224\n",
      "27  10.0   87.349  -85.228   43.822  4721.493  515.972\n",
      "28  10.0   85.734  -85.089   43.526  4721.492  515.675\n",
      "29  10.0   84.620  -84.701   43.175  4721.488  515.324\n",
      "30  10.0   83.834  -85.748   42.099  4721.486  514.247\n"
     ]
    }
   ],
   "source": [
    "print(result_df_tr_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     acc      bmx      bmn     run\n",
      "0   10.0  112.352 -113.306  18.249\n",
      "1   10.0  113.857 -112.986  15.404\n",
      "2   10.0  110.690 -110.058  12.991\n",
      "3   10.0  106.640 -105.639  12.418\n",
      "4   10.0  103.500 -102.689  11.469\n",
      "5   10.0  105.030 -104.524  10.563\n",
      "6   10.0  107.070 -104.922  10.249\n",
      "7   10.0  105.569 -103.021  10.072\n",
      "8   10.0  104.194 -100.785   9.934\n",
      "9   10.0  101.649  -97.839   9.630\n",
      "10  10.0  100.954  -95.878   9.463\n",
      "11  10.0   99.965  -95.146   8.927\n",
      "12  10.0   99.299  -94.566   8.778\n",
      "13  10.0   98.192  -93.394   8.639\n",
      "14  10.0   96.775  -91.920   8.461\n",
      "15  10.0   96.078  -90.420   8.390\n",
      "16  10.0   95.325  -88.965   8.246\n",
      "17  10.0   93.405  -86.850   8.198\n",
      "18  10.0   92.799  -85.466   8.135\n",
      "19  10.0   91.785  -84.123   7.945\n",
      "20  10.0   89.884  -82.424   7.792\n",
      "21  10.0   88.666  -81.278   7.718\n",
      "22  10.0   87.916  -80.619   7.602\n",
      "23  10.0   86.910  -81.433   7.548\n",
      "24  10.0   85.961  -81.484   7.480\n",
      "25  10.0   84.943  -82.039   7.446\n",
      "26  10.0   84.146  -82.057   7.392\n",
      "27  10.0   81.865  -81.089   7.348\n",
      "28  10.0   81.060  -81.423   7.295\n",
      "29  10.0   80.075  -81.876   7.237\n",
      "30  10.0   79.726  -82.493   7.046\n"
     ]
    }
   ],
   "source": [
    "print(result_df_va_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tr acc =  10.0\n",
      "Max va acc =  10.0\n"
     ]
    }
   ],
   "source": [
    "tr_acc = result_df_tr_all.values[:,0].squeeze()\n",
    "va_acc = result_df_va_all.values[:,0].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_acc, color='orange', label='train acc')\n",
    "plt.plot(va_acc, color='red', label='validataion acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Max tr acc = \", np.max(tr_acc))\n",
    "print(\"Max va acc = \", np.max(va_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tr_mse = result_df_tr_all.values[:,3].squeeze()\n",
    "tr_spr_50 = 100*result_df_tr_all.values[:,4].squeeze()\n",
    "va_err = 5*result_df_va_all.values[:,-1].squeeze()\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(tr_mse, color='orange', label='train mse')\n",
    "plt.plot(tr_spr_50, color='red', label='tr spr*100')\n",
    "plt.plot(va_err, color='blue', label='va_err*5')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
